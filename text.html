            <p><a id="Albanian-header"></a></p>
            <h3 id="albanian">Albanian</h3>
            <h4 id="detecting-abusive-albanian">Detecting Abusive Albanian</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2107.13592">https://arxiv.org/abs/2107.13592</a>
                </li>
                <li>Link to data: <a
                        href="https://doi.org/10.6084/m9.figshare.19333298.v1">https://doi.org/10.6084/m9.figshare.19333298.v1</a>
                </li>
                <li>Task description: Hierarchical (offensive/not; untargeted/targeted; person/group/other)</li>
                <li>Details of task: Detect and categorise abusive language in social media data</li>
                <li>Size of dataset: 11 874</li>
                <li>Percentage abusive: 13.2%</li>
                <li>Language: Albanian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Instagram, Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Nurce, E., Keci, J., Derczynski, L., 2021. Detecting Abusive Albanian. arXiv:2107.13592
                </li>
                <li>Dataset reader: 🤗 <a href="https://huggingface.co/datasets/strombergnlp/shaj">strombergnlp/shaj</a>
                </li>
            </ul>

            <p><a id="Arabic-header"></a></p>
            <h3 id="arabic">Arabic</h3>
            <h4 id="are-they-our-brothers-analysis-and-detection-of-religious-hate-speech-in-the-arabic-twittersphere">
                Are They our Brothers? Analysis and Detection of Religious Hate Speech in the Arabic Twittersphere</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://ieeexplore.ieee.org/document/8508247">https://ieeexplore.ieee.org/document/8508247</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/nuhaalbadi/Arabic_hatespeech">https://github.com/nuhaalbadi/Arabic_hatespeech</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Religious subcategories</li>
                <li>Size of dataset: 6,136</li>
                <li>Percentage abusive: 0.45</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Albadi, N., Kurdi, M. and Mishra, S., 2018. Are they Our Brothers? Analysis and Detection
                    of Religious Hate Speech in the Arabic Twittersphere. In: International Conference on Advances in
                    Social Networks Analysis and Mining. Barcelona, Spain: IEEE, pp.69-76.</li>
            </ul>

            <h4 id="multilingual-and-multi-aspect-hate-speech-analysis-arabic">Multilingual and Multi-Aspect Hate Speech
                Analysis (Arabic)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1908.11049">https://arxiv.org/abs/1908.11049</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HKUST-KnowComp/MLMA_hate_speech">https://github.com/HKUST-KnowComp/MLMA_hate_speech</a>
                </li>
                <li>Task description: Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target
                    Attribute, Target Group, How annotators felt on seeing the tweet.</li>
                <li>Details of task: Gender, Sexual orientation, Religion, Disability</li>
                <li>Size of dataset: 3,353</li>
                <li>Percentage abusive: 0.64</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and
                    Multi-Aspect Hate Speech Analysis. ArXiv,.</li>
            </ul>

            <h4 id="l-hsab-a-levantine-twitter-dataset-for-hate-speech-and-abusive-language">L-HSAB: A Levantine Twitter
                Dataset for Hate Speech and Abusive Language</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W19-3512">https://www.aclweb.org/anthology/W19-3512</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/Hala-Mulki/L-HSAB-First-Arabic-Levantine-HateSpeech-Dataset">https://github.com/Hala-Mulki/L-HSAB-First-Arabic-Levantine-HateSpeech-Dataset</a>
                </li>
                <li>Task description: Ternary (Hate, Abusive, Normal)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 5,846</li>
                <li>Percentage abusive: 0.38</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Mulki, H., Haddad, H., Bechikh, C. and Alshabani, H., 2019. L-HSAB: A Levantine Twitter
                    Dataset for Hate Speech and Abusive Language. In: Proceedings of the Third Workshop on Abusive
                    Language Online. Florence, Italy: Association for Computational Linguistics, pp.111-118.</li>
            </ul>

            <h4 id="abusive-language-detection-on-arabic-social-media-twitter">Abusive Language Detection on Arabic
                Social Media (Twitter)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W17-3008">https://www.aclweb.org/anthology/W17-3008</a>
                </li>
                <li>Link to data: <a
                        href="http://alt.qcri.org/~hmubarak/offensive/TweetClassification-Summary.xlsx">http://alt.qcri.org/~hmubarak/offensive/TweetClassification-Summary.xlsx</a>
                </li>
                <li>Task description: Ternary (Obscene, Offensive but not obscene, Clean)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 1,100</li>
                <li>Percentage abusive: 0.59</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Mubarak, H., Darwish, K. and Magdy, W., 2017. Abusive Language Detection on Arabic Social
                    Media. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver, Canada:
                    Association for Computational Linguistics, pp.52-56.</li>
                <li>Dataset reader: 🤗 <a
                        href="https://huggingface.co/datasets/strombergnlp/offenseval_2020">strombergnlp/offenseval_2020</a>
                </li>
            </ul>

            <h4 id="abusive-language-detection-on-arabic-social-media-al-jazeera">Abusive Language Detection on Arabic
                Social Media (Al Jazeera)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W17-3008">https://www.aclweb.org/anthology/W17-3008</a>
                </li>
                <li>Link to data: <a
                        href="http://alt.qcri.org/~hmubarak/offensive/AJCommentsClassification-CF.xlsx">http://alt.qcri.org/~hmubarak/offensive/AJCommentsClassification-CF.xlsx</a>
                </li>
                <li>Task description: Ternary (Obscene, Offensive but not obscene, Clean)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 32,000</li>
                <li>Percentage abusive: 0.81</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: AlJazeera</li>
                <li>Medium: Text</li>
                <li>Reference: Mubarak, H., Darwish, K. and Magdy, W., 2017. Abusive Language Detection on Arabic Social
                    Media. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver, Canada:
                    Association for Computational Linguistics, pp.52-56.</li>
            </ul>

            <h4 id="dataset-construction-for-the-detection-of-anti-social-behaviour-in-online-communication-in-arabic">
                Dataset Construction for the Detection of Anti-Social Behaviour in Online Communication in Arabic</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.sciencedirect.com/science/article/pii/S1877050918321756">https://www.sciencedirect.com/science/article/pii/S1877050918321756</a>
                </li>
                <li>Link to data: <a
                        href="https://onedrive.live.com/?authkey=!ACDXj_ZNcZPqzy0&amp;id=6EF6951FBF8217F9!105&amp;cid=6EF6951FBF8217F9">https://onedrive.live.com/?authkey=!ACDXj_ZNcZPqzy0&amp;id=6EF6951FBF8217F9!105&amp;cid=6EF6951FBF8217F9</a>
                </li>
                <li>Task description: Binary (Offensive, Not)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 15,050</li>
                <li>Percentage abusive: 0.39</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: YouTube</li>
                <li>Medium: Text</li>
                <li>Reference: Alakrot, A., Murray, L. and Nikolov, N., 2018. Dataset Construction for the Detection of
                    Anti-Social Behaviour in Online Communication in Arabic. Procedia Computer Science, 142, pp.174-181.
                </li>
            </ul>

            <p><a id="Bengali-header"></a></p>
            <h3 id="bengali">Bengali</h3>
            <h4 id="hate-speech-detection-in-the-bengali-language-a-dataset-and-its-baseline-evaluation">Hate Speech
                Detection in the Bengali language: A Dataset and its Baseline Evaluation</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2012.09686.pdf">https://arxiv.org/pdf/2012.09686.pdf</a></li>
                <li>Link to data: <a
                        href="https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset">https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset</a>
                </li>
                <li>Task description: Binary (hateful, not)</li>
                <li>Details of task: Several categories: sports, entertainment, crime, religion, politics, celebrity and
                    meme</li>
                <li>Size of dataset: 30,000</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Bengali</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Romim, N., Ahmed, M., Talukder, H., &amp; Islam, M. S. (2021). Hate speech detection in
                    the bengali language: A dataset and its baseline evaluation. In Proceedings of International Joint
                    Conference on Advances in Computational Intelligence (pp. 457-468). Springer, Singapore.</li>
            </ul>

            <p><a id="Chinese-header"></a></p>
            <h3 id="chinese">Chinese</h3>
            <h4 id="swsr-a-chinese-dataset-and-lexicon-for-online-sexism-detection">SWSR: A Chinese Dataset and Lexicon
                for Online Sexism Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.sciencedirect.com/science/article/abs/pii/S2468696421000604#fn1">https://www.sciencedirect.com/science/article/abs/pii/S2468696421000604#fn1</a>
                </li>
                <li>Link to data: <a
                        href="https://doi.org/10.5281/zenodo.4773875">https://doi.org/10.5281/zenodo.4773875</a></li>
                <li>Task description: Binary (Sexist, Non-sexist), Categories of sexism (Stereotype based on Appearance,
                    Stereotype based on Cultural Background, MicroAggression, and Sexual Offense), Target of sexism
                    (Individual or Generic)</li>
                <li>Details of task: Sexism detection on social media in Chinese</li>
                <li>Size of dataset: 8,969 comments from 1,527 weibos</li>
                <li>Percentage abusive: 34.5%</li>
                <li>Language: Chinese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Sina Weibo</li>
                <li>Medium: Text</li>
                <li>Reference: Aiqi Jiang, Xiaohan Yang, Yang Liu, Arkaitz Zubiaga, SWSR: A Chinese dataset and lexicon
                    for online sexism detection, Online Social Networks and Media, Volume 27, 2022, 100182, ISSN
                    2468-6964.</li>
            </ul>

            <p><a id="Croatian-header"></a></p>
            <h3 id="croatian">Croatian</h3>
            <h4 id="datasets-of-slovene-and-croatian-moderated-news-comments">Datasets of Slovene and Croatian Moderated
                News Comments</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5116">https://www.aclweb.org/anthology/W18-5116</a>
                </li>
                <li>Link to data: <a href="http://hdl.handle.net/11356/1202">http://hdl.handle.net/11356/1202</a></li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 17,000,000</li>
                <li>Percentage abusive: 0.02</li>
                <li>Language: Croatian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: 24sata website</li>
                <li>Medium: Text</li>
                <li>Reference: Ljubešić, N., Erjavec, T. and Fišer, D., 2018. Datasets of Slovene and Croatian Moderated
                    News Comments. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2). Brussels,
                    Belgium: Association for Computational Linguistics, pp.124-131.</li>
            </ul>

            <h4 id="automating-news-comment-moderation-with-limited-resources-benchmarking-in-croatian-and-estonian">
                Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf">https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://www.clarin.si/repository/xmlui/handle/11356/1399">https://www.clarin.si/repository/xmlui/handle/11356/1399</a>
                </li>
                <li>Task description: Multi-class based on Different rules</li>
                <li>Details of task: Flagged content performmed by the real newspaper moderators</li>
                <li>Size of dataset: 21M</li>
                <li>Percentage abusive: 7.8%</li>
                <li>Language: Croatian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Newspaper comments</li>
                <li>Medium: Text</li>
                <li>Reference: Ravi Shekhar, Marko Pranjić, Senja Pollak, Andraž Pelicon, Matthew Purver (2020).
                    Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian.
                    Journal for Language Technology and Computational Linguistics (JLCL).</li>
            </ul>

            <p><a id="Danish-header"></a></p>
            <h3 id="danish">Danish</h3>
            <h4 id="offensive-language-and-hate-speech-detection-for-danish">Offensive Language and Hate Speech
                Detection for Danish</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.derczynski.com/papers/danish_hsd.pdf">http://www.derczynski.com/papers/danish_hsd.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://sites.google.com/site/offensevalsharedtask/home">https://figshare.com/articles/Danish_Hate_Speech_Abusive_Language_data/12220805</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,
                    Not), Within Target (Individual, Group, Other)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 3,600</li>
                <li>Percentage abusive: 0.12</li>
                <li>Language: Danish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter, Reddit, newspaper comments</li>
                <li>Medium: Text</li>
                <li>Reference: Sigurbergsson, G. and Derczynski, L., 2019. Offensive Language and Hate Speech Detection
                    for Danish. ArXiv.</li>
                <li>Dataset reader: 🤗 <a href="https://huggingface.co/datasets/DDSC/dkhate">DDSC/dkhate</a></li>
            </ul>

            <h4 id="bajer-misogyny-in-danish">BAJER: Misogyny in Danish</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.acl-long.247/">https://aclanthology.org/2021.acl-long.247/</a>
                </li>
                <li>Link to data: <a
                        href="https://docs.google.com/forms/d/e/1FAIpQLSfUKb7ZTKd01syaNkAW5GDfCSkaVsJlom06g_mJdWUkUikVHA/viewform">request
                        here</a></li>
                <li>Task description: Hierarchy of abusive content labels including subcategories of misogyny</li>
                <li>Details of task: “Misogyny detection on social media in Danish”</li>
                <li>Size of dataset: 27.9K comments</li>
                <li>Percentage abusive: 7% misogynistic, 27% abusive (i.e. 20% abusive but not misogyny)</li>
                <li>Language: Danish</li>
                <li>Level of annotation: Social media post / comment</li>
                <li>Platform: Twitter, Facebook, Reddit</li>
                <li>Medium: text</li>
                <li>Reference: Zeinert, Inie, &amp; Derczynski, 2021. “Annotating Online Misogyny”. Proceedings of the
                    59th Annual Meeting of the Association for Computational Linguistics and the 11th International
                    Joint Conference on Natural Language Processing, ACL</li>
                <li>Dataset reader: 🤗 <a
                        href="https://huggingface.co/datasets/strombergnlp/bajer_danish_misogyny">strombergnlp/bajer_danish_misogyny</a>
                </li>
            </ul>

            <p><a id="Dutch-header"></a></p>
            <h3 id="dutch">Dutch</h3>
            <h4 id="the-dutch-abusive-language-corpus-v10-dalc-v10">The Dutch Abusive Language Corpus v1.0 (DALC v1.0)
            </h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.woah-1.6.pdf">https://aclanthology.org/2021.woah-1.6.pdf</a>
                    - link to the documentation and/or a data statement about the data</li>
                <li>Link to data: <a href="https://github.com/tommasoc80/DALC">https://github.com/tommasoc80/DALC</a>
                </li>
                <li>Task description: Multilayered (explicitness and target) for abusive language</li>
                <li>Details of task: Abusive language detection in social media in Dutch</li>
                <li>Size of dataset: 8,156 tweets</li>
                <li>Percentage abusive: 15.06% explicitly abusive; 8.09% implicitly abusive</li>
                <li>Language: Dutch</li>
                <li>Level of annotation: tweets</li>
                <li>Platform: Twitter</li>
                <li>Medium: text</li>
                <li>Reference: Caselli, T., Schelhaas, A., Weultjes, M., Leistra, F., van der Veen, H., Timmerman, G.,
                    and Nissim, M. 2021. “DALC: the Dutch Abusive Language Corpus”. Proceedings of the 5th Workshop on
                    Online Abuse and Harms (WOAH 2021), ACL.</li>
            </ul>

            <p><a id="English-header"></a></p>
            <h3 id="english">English</h3>

            <h4 id="convabuse">ConvAbuse</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.emnlp-main.587/">https://aclanthology.org/2021.emnlp-main.587/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/amandacurry/convabuse">https://github.com/amandacurry/convabuse</a>
                </li>
                <li>Task description: Hierarchical: 1. <em>Abuse binary</em>, <em>Abuse severity</em> 1,0,-1,-2,-3; 2.
                    <em>Directedness</em> explicit, implicit <em>Target</em> group, individual–system,
                    individual–3rd party, <em>Type</em> general, sexist, sexual harassment, homophobic, racist,
                    transphobic, ableist,
                    intellectual</li>
                <li>Details of task: Abuse detection in conversational AI</li>
                <li>Size of dataset: 4,185</li>
                <li>Percentage abusive: c. 20%</li>
                <li>Language: English</li>
                <li>Level of annotation: utterance (with conversational context)</li>
                <li>Platform: Carbonbot on Facebook Messenger and E.L.I.Z.A. chatbots</li>
                <li>Medium: text</li>
                <li>Reference: Curry, A. C., Abercrombie, G., &amp; Rieser, V. 2021. ConvAbuse: Data, Analysis, and
                    Benchmarks for Nuanced Detection in Conversational AI. In Proceedings of the 2021 Conference on
                    Empirical Methods in Natural Language Processing (pp. 7388-7403).</li>
            </ul>

            <h4 id="measuring-hate-speech">Measuring Hate Speech</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2009.10277">https://arxiv.org/abs/2009.10277</a>
                </li>
                <li>Link to data: <a
                        href="https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech">https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech</a>
                </li>
                <li>Task description: 10 ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status,
                    violence, dehumanization, genocide, attack/defense, hate speech), which are debiased and aggregated
                    into a continuous hate speech severity score (hate_speech_score) that includes a region for
                    counterspeech &amp; supportive speeech. Includes 8 target identity groups (race/ethnicity, religion,
                    national origin/citizenship, gender, sexual orientation, age, disability, political ideology) and 42
                    identity subgroups.</li>
                <li>Details of task: Hate speech measurement on social media in English</li>
                <li>Size of dataset: 39,565 comments annotated by 7,912 annotators on 10 ordinal labels, for 1,355,560
                    total labels.</li>
                <li>Percentage abusive: 25% - however this dichotomization is not in the spirit of the paper/dataset
                </li>
                <li>Language: English</li>
                <li>Level of annotation: Social media comment</li>
                <li>Platform: Twitter, Reddit, YouTube</li>
                <li>Medium: Text</li>
                <li>Reference: Kennedy, C. J., Bacon, G., Sahn, A., &amp; von Vacano, C. (2020). Constructing interval
                    variables via faceted Rasch measurement and multitask deep learning: a hate speech application.
                    arXiv preprint arXiv:2009.10277.</li>
            </ul>

            <h4 id="learning-from-the-worst-dynamically-generated-hate-speech-dataset">Learning From the Worst
                (Dynamically generated hate speech dataset)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.acl-long.132/">https://aclanthology.org/2021.acl-long.132/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset">https://github.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset</a>
                </li>
                <li>Task description: Multi-category hate speech detection</li>
                <li>Details of task: Hate detection with fine-grained labels for the type and target of hate. Generated
                    over 4 rounds of human-and-model-in-the-loop adversarial data generation. Collected through <a
                        href="https://dynabench.org/tasks/5#overall">Dynabench</a>.</li>
                <li>Size of dataset: 41,255</li>
                <li>Percentage abusive: 54%</li>
                <li>Language: English</li>
                <li>Level of annotation: posts</li>
                <li>Platform: Synthetically generated by humans to mimic real-world social media posts</li>
                <li>Medium: text</li>
                <li>Reference: Vidgen, B., Thurush, T., Waseem, Z., Kiela, D., 2021. Learning from the worst:
                    dynamically generated datasets to improve online hate detection. In Proceedings of the 59th Meeting
                    of the Association for Computational Lingusitics (pp. 1667-1682).</li>
            </ul>

            <h4 id="the-call-me-sexist-but-sexism-dataset">The ‘Call me sexist, but’ sexism dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://ojs.aaai.org/index.php/ICWSM/article/view/18085/17888">https://ojs.aaai.org/index.php/ICWSM/article/view/18085/17888</a>
                </li>
                <li>Link to data: <a href="https://doi.org/10.7802/2251">https://doi.org/10.7802/2251</a></li>
                <li>Task description: Sexism detection based on content and phrasing</li>
                <li>Details of task: Sexism detection on English social media data informed by survey items measuring
                    sexist attitudes and adversarial examples</li>
                <li>Size of dataset: 6325</li>
                <li>Percentage abusive: 28%</li>
                <li>Language: English</li>
                <li>Level of annotation: tweets and survey items</li>
                <li>Platform: Twitter, Social Psychology scales</li>
                <li>Medium: text</li>
                <li>Reference: Samory, M., Sen, I., Kohne, J., Flöck, F. and Wagner, C., 2021, May. Call me sexist,
                    but…: Revisiting sexism detection using psychological scales and adversarial samples. In Intl AAAI
                    Conf. Web and Social Media (pp. 573-584).</li>
            </ul>

            <h4
                id="hate-towards-the-political-opponent-a-twitter-corpus-study-of-the-2020-us-elections-on-the-basis-of-offensive-speech-and-stance-detection__">
                Hate Towards the Political Opponent: A Twitter Corpus Study of the 2020 US Elections on the Basis of
                Offensive Speech and Stance Detection__</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.wassa-1.18/">https://aclanthology.org/2021.wassa-1.18/</a>
                </li>
                <li>Link to data: <a
                        href="https://www.ims.uni-stuttgart.de/data/stance_hof_us2020">https://www.ims.uni-stuttgart.de/data/stance_hof_us2020</a>
                </li>
                <li>Task description: Hate / Offensive or neither</li>
                <li>Details of task: Data collected to be Twitter by supporters of Trump
                    or Biden</li>
                <li>Size of dataset: 3,000</li>
                <li>Percentage abusive: 12%</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Lara Grimminger and Roman Klinger (2020): Hate Towards the Political Opponent: A Twitter
                    Corpus Study of the 2020 US Elections on the Basis of Offensive Speech and Stance Detection. 11th
                    Workshop on Computational Approaches to Subjectivity, Sentiment &amp; Social Media Analysis
                    (collocated with EACL 2021).</li>
            </ul>

            <h4 id="abuseeval-v10">AbuseEval v1.0</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.760.pdf">http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.760.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/tommasoc80/AbuseEval">https://github.com/tommasoc80/AbuseEval</a></li>
                <li>Task description: Explicitness annotation of offensive and abusive content</li>
                <li>Details of task: Enriched versions of the OffensEval/OLID dataset with the distinction of
                    explicit/implicit offensive messages and the new dimension for abusive messages. Labels for
                    offensive language: EXPLICIT, IMPLICT, NOT; Labels for abusive language: EXPLICIT, IMPLICT, NOTABU
                </li>
                <li>Size of dataset: 14,100</li>
                <li>Percentage abusive: 20.75%</li>
                <li>Language: English</li>
                <li>Level of annotation: tweets</li>
                <li>Platform: Twitter</li>
                <li>Medium: text</li>
                <li>Reference: Caselli, T., Basile, V., Jelena, M., Inga, K., and Michael, G. 2020. “I feel offended,
                    don’t be abusive! implicit/explicit messages in offensive and abusive language”. The 12th Language
                    Resources and Evaluation Conference (pp. 6193-6202). European Language Resources Association.</li>
            </ul>

            <h4 id="do-you-really-want-to-hurt-me-predicting-abusive-swearing-in-social-media">Do You Really Want to
                Hurt Me? Predicting Abusive Swearing in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.lrec-1.765.pdf">https://www.aclweb.org/anthology/2020.lrec-1.765.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/dadangewp/SWAD-Repository">https://github.com/dadangewp/SWAD-Repository</a>
                </li>
                <li>Task description: Binary (abusive swear word, non-abusive swear word)</li>
                <li>Details of task: Abusive swearing</li>
                <li>Size of dataset: 1,511 swear words (1675 tweets)</li>
                <li>Percentage abusive: 0.41% (word level), 0.51% (post level)</li>
                <li>Language: English</li>
                <li>Level of annotation: Words</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Pamungkas, E. W., Basile, V., &amp; Patti, V. (2020). Do you really want to hurt me?
                    predicting abusive swearing in social media. In The 12th Language Resources and Evaluation
                    Conference (pp. 6237-6246). European Language Resources Association.</li>
            </ul>

            <h4 id="multimodal-meme-dataset-multioff-for-identifying-offensive-content-in-image-and-text">Multimodal
                Meme Dataset (MultiOFF) for Identifying Offensive Content in Image and Text</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.trac-1.6.pdf">https://www.aclweb.org/anthology/2020.trac-1.6.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text">https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text</a>
                </li>
                <li>Task description: Binary (offensive, non-offensive)</li>
                <li>Details of task: Hate per se (related to 2016 U.S. presidential election)</li>
                <li>Size of dataset: 743</li>
                <li>Percentage abusive: 0.41%</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Kaggle, Reddit, Facebook, Twitter and Instagram</li>
                <li>Medium: Text and Images/memes</li>
                <li>Reference: Suryawanshi, S., Chakravarthi, B. R., Arcan, M., &amp; Buitelaar, P. (2020, May).
                    Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text. In
                    Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying (pp. 32-41).</li>
            </ul>

            <h4
                id="hatemoji-a-test-suite-and-adversarially-generated-dataset-for-benchmarking-and-detecting-emoji-based-hate">
                Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based
                Hate</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2108.05921">https://arxiv.org/abs/2108.05921</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HannahKirk/Hatemoji">https://github.com/HannahKirk/Hatemoji</a></li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not Hate), Within Hate (Type, Target)
                </li>
                <li>Details of task: Hate speech detection for text statements including emoji, consisting of a
                    checklist-based test suite (HatemojiCheck) and an adversarially-generated dataset (HatemojiBuild)
                </li>
                <li>Size of dataset: HatemojiCheck = 3,930; HatemojiBuild = 5,912.</li>
                <li>Percentage abusive: HatemojiCheck = 69%, HatemojiBuild = 50%</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Synthetically-Generated</li>
                <li>Medium: Text with emoji</li>
                <li>Reference: Kirk, H. R., Vidgen, B., Röttger, P., Thrush, T., &amp; Hale, S. A. 2021. Hatemoji: A
                    test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate.
                    arXiv preprint arXiv:2108.05921.</li>
            </ul>

            <h4 id="hatecheck-functional-tests-for-hate-speech-detection-models">HateCheck: Functional Tests for Hate
                Speech Detection Models</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2012.15606.pdf">https://arxiv.org/pdf/2012.15606.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/paul-rottger/hatecheck-data">https://github.com/paul-rottger/hatecheck-data</a>
                </li>
                <li>Task description: Binary (Hate, Not Hate), 7 Targets Within Hate (Women, Trans people, Black people,
                    Gay people, Disabled people, Muslims, Immigrants)</li>
                <li>Details of task: A checklist of functional tests to evaluate hate speech detection models.</li>
                <li>Size of dataset: 3,728</li>
                <li>Percentage abusive: 68%</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Synthetically-Generated</li>
                <li>Medium: Text</li>
                <li>Reference: Röttger, P., Vidgen, B., Nguyen, D., Waseem, Z., Margetts, H. and Pierrehumbert, J.,
                    2020. Hatecheck: Functional tests for hate speech detection models. arXiv preprint arXiv:2012.15606.
                </li>
            </ul>

            <h4 id="semeval-2021-task-5-toxic-spans-detection">Semeval-2021 Task 5: Toxic Spans Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.semeval-1.6.pdf">https://aclanthology.org/2021.semeval-1.6.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ipavlopoulos/toxic_spans">https://github.com/ipavlopoulos/toxic_spans</a>
                </li>
                <li>Task description: Binary toxic spans (toxic, non-toxic) &amp; reading comprehension</li>
                <li>Details of task: Predict the spans of toxic posts that were responsible for the toxic label of the
                    posts.</li>
                <li>Size of dataset: 10,629</li>
                <li>Percentage abusive: 0.56</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Civil Comments</li>
                <li>Medium: Text</li>
                <li>Reference: Pavlopoulos, J., Sorensen, J., Laugier, L., &amp; Androutsopoulos, I. (2021, August).
                    Semeval-2021 task 5: Toxic spans detection. In Proceedings of the 15th International Workshop on
                    Semantic Evaluation (SemEval-2021) (pp. 59-69).</li>
            </ul>

            <h4
                id="human-in-the-loop-for-data-collection-a-multi-target-counter-narrative-dataset-to-fight-online-hate-speech">
                Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate
                Speech</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.acl-long.250.pdf">https://aclanthology.org/2021.acl-long.250.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (hateful, not)</li>
                <li>Details of task: race, religion, country of origin, sexual orientation, disability, gender</li>
                <li>Size of dataset: 5,003</li>
                <li>Percentage abusive: 1</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Semi-synthetic text</li>
                <li>Medium: Text</li>
                <li>Reference: Margherita Fanton, Helena Bonaldi, Serra Sinem Tekiroğlu, Marco Guerini Human-in-the-Loop
                    for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech In
                    Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics: Long
                    Papers.</li>
            </ul>

            <h4 id="hatexplain-a-benchmark-dataset-for-explainable-hate-speech-detection">HateXplain: A Benchmark
                Dataset for Explainable Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2012.10289">https://arxiv.org/abs/2012.10289</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/punyajoy/HateXplain">https://github.com/punyajoy/HateXplain</a></li>
                <li>Task description: Level of hate (hate, offensive or normal), on target groups (race, religion,
                    gender, sexual orientation, miscellaneous), and rationales</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 20,148</li>
                <li>Percentage abusive: 0.57</li>
                <li>Language: English</li>
                <li>Level of annotation: Words, phrases, posts</li>
                <li>Platform: Twitter and Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Mathew, B., Saha, P., Yimam, S. M., Biemann, C., Goyal, P., &amp; Mukherjee, A. (2021,
                    May). HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection. In Proceedings of the
                    AAAI Conference on Artificial Intelligence (Vol. 35, No. 17, pp. 14867-14875).</li>
            </ul>

            <h4 id="alone-a-dataset-for-toxic-behavior-among-adolescents-on-twitter">ALONE: A Dataset for Toxic Behavior
                among Adolescents on Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2008.06465.pdf">https://arxiv.org/pdf/2008.06465.pdf</a></li>
                <li>Link to data: Data made available upon request, please email Ugur Kursuncu ugur@gsu.edu and
                    thilini@sc.edu thilini@sc.edu.</li>
                <li>Task description: Binary (Toxic, Non-Toxic)</li>
                <li>Details of task: Annotates interactions (Tweets and their replies), and assigns keywords describing
                    use of emojis, URL content and images.</li>
                <li>Size of dataset: 688</li>
                <li>Percentage abusive: 0.17</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Twitter</li>
                <li>Medium: Multimodal (text, images, emojis, metadata)</li>
                <li>Reference: Wijesiriwardene, T., Inan, H., Kursuncu, U., Gaur, M., Shalin, V., Thirunarayan, K.,
                    Sheth, A. and Arpinar, I., 2020, Arxiv.</li>
            </ul>

            <h4 id="towards-a-comprehensive-taxonomy-and-large-scale-annotated-corpus-for-online-slur-usage">Towards a
                Comprehensive Taxonomy and Large-Scale Annotated Corpus for Online Slur Usage</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.alw-1.17.pdf">https://www.aclweb.org/anthology/2020.alw-1.17.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/networkdynamics/slur-corpus">https://github.com/networkdynamics/slur-corpus</a>
                </li>
                <li>Task description: 4 primary categories (derogatory, appropriate, non-derogatory/non-appropriate,
                    homonyms, noise)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 39,811</li>
                <li>Percentage abusive: 0.52</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Kurrek, J., Saleem, H. M., &amp; Ruths, D. (2020, November). Towards a comprehensive
                    taxonomy and large-scale annotated corpus for online slur usage. In Proceedings of the Fourth
                    Workshop on Online Abuse and Harms (pp. 138-149).</li>
            </ul>

            <h4 id="multimodal-meme-dataset-multioff-for-identifying-offensive-content-in-image-and-text-1">Multimodal
                Meme Dataset (MultiOFF) for Identifying Offensive Content in Image and Text</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.trac-1.6.pdf">https://www.aclweb.org/anthology/2020.trac-1.6.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://www.aclweb.org/anthology/2020.trac-1.6.pdf">https://www.aclweb.org/anthology/2020.trac-1.6.pdf</a>
                </li>
                <li>Task description: Binary (offensive, non-offensive)</li>
                <li>Details of task: Hate per se (related to 2016 U.S. presidential election)</li>
                <li>Size of dataset: 743</li>
                <li>Percentage abusive: 0.41</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Kaggle, Reddit, Facebook, Twitter and Instagram</li>
                <li>Medium: Text and Images/memes</li>
                <li>Reference: Suryawanshi, S., Chakravarthi, B. R., Arcan, M., &amp; Buitelaar, P. (2020, May).
                    Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text. In
                    Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying (pp. 32-41).</li>
            </ul>

            <h4 id="predicting-the-type-and-target-of-offensive-posts-in-social-media">Predicting the Type and Target of
                Offensive Posts in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/N19-1144.pdf">https://aclanthology.org/N19-1144.pdf</a></li>
                <li>Link to data: <a
                        href="https://scholar.harvard.edu/malmasi/olid">https://scholar.harvard.edu/malmasi/olid</a>
                </li>
                <li>Task description: Branching structure of tasks. A: offensive / not, B: targeted insult / untargeted,
                    C: individual, group, other.</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 14,100</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., &amp; Kumar, R. (2019,
                    June). Predicting the Type and Target of Offensive Posts in Social Media. In Proceedings of the 2019
                    Conference of the North American Chapter of the Association for Computational Linguistics: Human
                    Language Technologies, Volume 1 (Long and Short Papers) (pp. 1415-1420).</li>
            </ul>

            <h4 id="nuanced-metrics-for-measuring-unintended-bias-with-real-data-for-text-classification">Nuanced
                metrics for measuring unintended bias with real data for text classification</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1903.04561.pdf">https://arxiv.org/pdf/1903.04561.pdf</a></li>
                <li>Link to data: <a
                        href="https://www.tensorflow.org/datasets/catalog/civil_comments">https://www.tensorflow.org/datasets/catalog/civil_comments</a>
                </li>
                <li>Task description: Toxicity (severe, obscene, threat, insult, identity attack, sexual explicit), and
                    several identity attributes (e.g., gender, religion and race)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 1,804,875</li>
                <li>Percentage abusive: 0.8</li>
                <li>Language: English</li>
                <li>Level of annotation: Comments/posts</li>
                <li>Platform: Civil Comments</li>
                <li>Medium: Text</li>
                <li>Reference: Borkan, D., Dixon, L., Sorensen, J., Thain, N., &amp; Vasserman, L. (2019, May). Nuanced
                    metrics for measuring unintended bias with real data for text classification. In Companion
                    proceedings of the 2019 world wide web conference (pp. 491-500).</li>
            </ul>

            <h4 id="introducing-cad-the-contextual-abuse-dataset">Introducing CAD: the Contextual Abuse Dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.naacl-main.182.pdf">https://aclanthology.org/2021.naacl-main.182.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://zenodo.org/record/4881008#.Ye6OwhP7R6o">https://zenodo.org/record/4881008#.Ye6OwhP7R6o</a>
                </li>
                <li>Task description: Contextually abusive language, person-directed + group-directed</li>
                <li>Details of task: Primary categories (secondary categories): Abusive + Identity-directed
                    (derogation/animosity/threatening/glorification/dehumanization), Abusive + Person-directed
                    (derogation/animosity/threatening/glorification/dehumanization), Abusive + Affiliation directed
                    (abuse to them/abuse about them), Counter Speech (against identity-directed abuse/against
                    affiliation-directed abuse/against person-directed abuse), Non-hateful Slurs and Neutral.</li>
                <li>Size of dataset: 25,000</li>
                <li>Percentage abusive: Affiliation-directed, 6%; Identity-directed, 13%; Person-directed, 5%</li>
                <li>Language: English</li>
                <li>Level of annotation: Conversation thread</li>
                <li>Platform: Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Vidgen, B., Nguyen, D., Margetts, H., Rossini, P., and Troble, R., Introducing CAD: the
                    Contextual Abuse Dataset, 2021, In: Proceedings of the 2021 Conference of the North American Chapter
                    of the Association for Computational Linguistics: Human Language Technologies, pp.2289–2303</li>
            </ul>

            <h4 id="automated-hate-speech-detection-and-the-problem-of-offensive-language">Automated Hate Speech
                Detection and the Problem of Offensive Language</h4>
            <ul>
                <li>Link to publication: [https://ojs.aaai.org/index.php/ICWSM/article/view/14955)</li>
                <li>Link to data: <a
                        href="https://github.com/t-davidson/hate-speech-and-offensive-language">https://github.com/t-davidson/hate-speech-and-offensive-language</a>
                </li>
                <li>Task description: Hierarchy (Hate, Offensive, Neither)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 24,802</li>
                <li>Percentage abusive: 0.06</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Davidson, T., Warmsley, D., Macy, M., &amp; Weber, I. 2017. Automated Hate Speech
                    Detection and the Problem of Offensive Language. Proceedings of the International AAAI Conference on
                    Web and Social Media, 11(1), 512-515.</li>
            </ul>

            <h4 id="hate-speech-dataset-from-a-white-supremacy-forum">Hate Speech Dataset from a White Supremacy Forum
            </h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5102.pdf">https://www.aclweb.org/anthology/W18-5102.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/Vicomtech/hate-speech-dataset">https://github.com/Vicomtech/hate-speech-dataset</a>
                </li>
                <li>Task description: Ternary (Hate, Relation, Not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 9,916</li>
                <li>Percentage abusive: 0.11</li>
                <li>Language: English</li>
                <li>Level of annotation: Sentence - with context of the converstaional thread taken into account</li>
                <li>Platform: Stormfront</li>
                <li>Medium: Text</li>
                <li>Reference: de Gibert, O., Perez, N., García-Pablos, A., and Cuadros, M., 2018. Hate Speech Dataset
                    from a White Supremacy Forum. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2).
                    Brussels, Belgium: Association for Computational Linguistics, pp.11-20.</li>
            </ul>

            <h4 id="hateful-symbols-or-hateful-people-predictive-features-for-hate-speech-detection-on-twitter">Hateful
                Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/N16-2013">https://www.aclweb.org/anthology/N16-2013</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ZeerakW/hatespeech">https://github.com/ZeerakW/hatespeech</a></li>
                <li>Task description: 3-topic (Sexist, Racist, Not)</li>
                <li>Details of task: Racism, Sexism</li>
                <li>Size of dataset: 16,914</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Waseem, Z. and Horvy, D., 2016. Hateful Symbols or Hateful People? Predictive Features
                    for Hate Speech Detection on Twitter. In: Proceedings of the NAACL Student Research Workshop. San
                    Diego, California: Association for Computational Linguistics, pp.88-93.</li>
            </ul>

            <h4 id="detecting-online-hate-speech-using-context-aware-models">Detecting Online Hate Speech Using Context
                Aware Models</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1710.07395.pdf">https://arxiv.org/pdf/1710.07395.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/sjtuprog/fox-news-comments">https://github.com/sjtuprog/fox-news-comments</a>
                </li>
                <li>Task description: Binary (Hate / not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 1528</li>
                <li>Percentage abusive: 0.28</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Fox News</li>
                <li>Medium: Text</li>
                <li>Reference: Gao, L. and Huang, R., 2018. Detecting Online Hate Speech Using Context Aware Models.
                    ArXiv,.</li>
            </ul>

            <h4 id="the-gab-hate-corpus-a-collection-of-27k-posts-annotated-for-hate-speech">The Gab Hate Corpus: A
                collection of 27k posts annotated for hate speech</h4>
            <ul>
                <li>Link to publication: <a href="https://psyarxiv.com/hqjxn/">https://psyarxiv.com/hqjxn/</a></li>
                <li>Link to data: <a href="https://osf.io/edua3/">https://osf.io/edua3/</a></li>
                <li>Task description: Binary (Hate vs. Offensive/Vulgarity), Binary (Assault on human Dignity/Call for
                    Violence – sub task on message delivery, binary: explicit/implicit), Multinomial classification:
                    Identity based hate (race/ethnicity, nationality/regionalism/xenophobia, gender, religion/belief
                    system, sexual orientation, ideology, political identification/party, mental/physical health)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 27,665</li>
                <li>Percentage abusive: 0.09 Hate, 0.06 Offensive/Vulgar</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Kennedy, B., Araria, M., Mostafazadeh Davani, A., Yeh, L., Omrani, A., Kim, Y., Koombs,
                    K., Havaldar, S., Portillo-Wightman, G., Gonzalez, E., Hoover, J., Azatain, A., Hussain, A., Lara,
                    A., Olmos, G., Omary, A., Park, C., Wang, C., Wang, X., Zhang, Y. and Dehghani, M., 2018, The Gab
                    Hate Corpus: A collection of 27k posts annotated for hate speech. PsyArXiv.</li>
            </ul>

            <h4 id="are-you-a-racist-or-am-i-seeing-things-annotator-influence-on-hate-speech-detection-on-twitter">Are
                You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://pdfs.semanticscholar.org/3eeb/b7907a9b94f8d65f969f63b76ff5f643f6d3.pdf">https://pdfs.semanticscholar.org/3eeb/b7907a9b94f8d65f969f63b76ff5f643f6d3.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ZeerakW/hatespeech">https://github.com/ZeerakW/hatespeech</a></li>
                <li>Task description: Multi-topic (Sexist, Racist, Neither, Both)</li>
                <li>Details of task: Racism, Sexism</li>
                <li>Size of dataset: 4,033</li>
                <li>Percentage abusive: 0.16</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Waseem, Z., 2016. Are You a Racist or Am I Seeing Things? Annotator Influence on Hate
                    Speech Detection on Twitter. In: Proceedings of 2016 EMNLP Workshop on Natural Language Processing
                    and Computational Social Science. Copenhagen, Denmark: Association for Computational Linguistics,
                    pp.138-142.</li>
            </ul>

            <h4
                id="when-does-a-compliment-become-sexist-analysis-and-classification-of-ambivalent-sexism-using-twitter-data">
                When Does a Compliment Become Sexist? Analysis and Classification of Ambivalent Sexism Using Twitter
                Data</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://pdfs.semanticscholar.org/225f/f8a6a562bbb64b22cebfcd3288c6b930d1ef.pdf">https://pdfs.semanticscholar.org/225f/f8a6a562bbb64b22cebfcd3288c6b930d1ef.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/AkshitaJha/NLP_CSS_2017">https://github.com/AkshitaJha/NLP_CSS_2017</a>
                </li>
                <li>Task description: Hierarchy of Sexism (Benevolent sexism, Hostile sexism, None)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 712</li>
                <li>Percentage abusive: 1</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Jha, A. and Mamidi, R., 2017. When does a Compliment become Sexist? Analysis and
                    Classification of Ambivalent Sexism using Twitter Data. In: Proceedings of the Second Workshop on
                    Natural Language Processing and Computational Social Science. Vancouver, Canada: Association for
                    Computational Linguistics, pp.7-16.</li>
            </ul>

            <h4 id="overview-of-the-task-on-automatic-misogyny-identification-at-ibereval-2018-english">Overview of the
                Task on Automatic Misogyny Identification at IberEval 2018 (English)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2150/overview-AMI.pdf">http://ceur-ws.org/Vol-2150/overview-AMI.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://amiibereval2018.wordpress.com/important-dates/data/">https://amiibereval2018.wordpress.com/im
                        nt-dates/data/</a></li>
                <li>Task description: Binary (misogyny / not), 5 categories (stereotype, dominance, derailing, sexual
                    harassment, discredit), target of misogyny (active or passive)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 3,977</li>
                <li>Percentage abusive: 0.47</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fersini, E., Rosso, P. and Anzovino, M., 2018. Overview of the Task on Automatic Misogyny
                    Identification at IberEval 2018. In: Proceedings of the Third Workshop on Evaluation of Human
                    Language Technologies for Iberian Languages (IberEval 2018).</li>
            </ul>

            <h4
                id="conan---counter-narratives-through-nichesourcing-a-multilingual-dataset-of-responses-to-fight-online-hate-speech-english">
                CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online
                Hate Speech (English)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/P19-1271.pdf">https://www.aclweb.org/anthology/P19-1271.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (Islamophobic / not), multi-topic (Culture, Economics, Crimes, Rapism,
                    Terrorism, Women Oppression, History, Other/generic)</li>
                <li>Details of task: Islamophobia</li>
                <li>Size of dataset: 1,288</li>
                <li>Percentage abusive: 1</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Synthetic / Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives
                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:
                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,
                    Italy: Association for Computational Linguistics, pp.2819-2829.</li>
            </ul>

            <h4 id="characterizing-and-detecting-hateful-users-on-twitter">Characterizing and Detecting Hateful Users on
                Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1803.08977.pdf">https://arxiv.org/pdf/1803.08977.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/manoelhortaribeiro/HatefulUsersTwitter">https://github.com/manoelhortaribeiro/HatefulUsersTwitter</a>
                </li>
                <li>Task description: Binary (hateful/not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 4,972</li>
                <li>Percentage abusive: 0.11</li>
                <li>Language: English</li>
                <li>Level of annotation: Users</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ribeiro, M., Calais, P., Santos, Y., Almeida, V. and Meira, W., 2018. Characterizing and
                    Detecting Hateful Users on Twitter. ArXiv,.</li>
            </ul>

            <h4 id="a-benchmark-dataset-for-learning-to-intervene-in-online-hate-speech-gab">A Benchmark Dataset for
                Learning to Intervene in Online Hate Speech (Gab)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1909.04251">https://arxiv.org/abs/1909.04251</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech">https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech</a>
                </li>
                <li>Task description: Binary (hateful/not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 33,776</li>
                <li>Percentage abusive: 0.43</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts (in the context of a conversation)</li>
                <li>Platform: Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Qian, J., Bethke, A., Belding, E. and Yang Wang, W., 2019. A Benchmark Dataset for
                    Learning to Intervene in Online Hate Speech. ArXiv,.</li>
            </ul>

            <h4 id="a-benchmark-dataset-for-learning-to-intervene-in-online-hate-speech-reddit">A Benchmark Dataset for
                Learning to Intervene in Online Hate Speech (Reddit)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1909.04251">https://arxiv.org/abs/1909.04251</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech">https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech</a>
                </li>
                <li>Task description: Binary (hateful/not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 22,324</li>
                <li>Percentage abusive: 0.24</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts (with context of the converstaional thread taken into account)</li>
                <li>Platform: Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Qian, J., Bethke, A., Belding, E. and Yang Wang, W., 2019. A Benchmark Dataset for
                    Learning to Intervene in Online Hate Speech. ArXiv,.</li>
            </ul>

            <h4 id="multilingual-and-multi-aspect-hate-speech-analysis-english">Multilingual and Multi-Aspect Hate
                Speech Analysis (English)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1908.11049">https://arxiv.org/abs/1908.11049</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HKUST-KnowComp/MLMA_hate_speech">https://github.com/HKUST-KnowComp/MLMA_hate_speech</a>
                </li>
                <li>Task description: Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target
                    attribute and Target group.</li>
                <li>Details of task: Gender, Sexual orientation, Religion, Disability</li>
                <li>Size of dataset: 5,647</li>
                <li>Percentage abusive: 0.76</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and
                    Multi-Aspect Hate Speech Analysis. ArXiv,.</li>
            </ul>

            <h4 id="exploring-hate-speech-detection-in-multimodal-publications">Exploring Hate Speech Detection in
                Multimodal Publications</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1910.03814.pdf">https://arxiv.org/pdf/1910.03814.pdf</a></li>
                <li>Link to data: <a
                        href="https://drive.google.com/file/d/1S9mMhZFkntNnYdO-1dZXwF_8XIiFcmlF/view">https://drive.google.com/file/d/1S9mMhZFkntNnYdO-1dZXwF_8XIiFcmlF/view</a>
                </li>
                <li>Task description: Multimodal Hate Speech Detection, including six primary categories (No attacks to
                    any community, Racist, Sexist, Homophobic, Religion based attack, Attack to other community)</li>
                <li>Details of task: Racism, Sexism, Homophobia, Religion-based attack</li>
                <li>Size of dataset: 149,823</li>
                <li>Percentage abusive: 0.25</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text and Images/Memes</li>
                <li>Reference: Gomez, R., Gibert, J., Gomez, L. and Karatzas, D., 2020. In Proceedings of the IEEE/CVF
                    winter conference on applications of computer vision (pp. 1470-1478).</li>
            </ul>

            <h4 id="predicting-the-type-and-target-of-offensive-posts-in-social-media-1">Predicting the Type and Target
                of Offensive Posts in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1902.09666.pdf">https://arxiv.org/pdf/1902.09666.pdf</a></li>
                <li>Link to data: <a
                        href="http://competitions.codalab.org/ competitions/20011">http://competitions.codalab.org/
                        competitions/20011</a></li>
                <li>Task description: Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,
                    Not), Within Target (Individual, Group, Other)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 14,100</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N. and Kumar, R., 2019.
                    SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval).
                    ArXiv,.</li>
            </ul>

            <h4
                id="hateval-semeval-2019-task-5-multilingual-detection-of-hate-speech-against-immigrants-and-women-in-twitter-english">
                hatEval, SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in
                Twitter (English)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/S19-2007">https://www.aclweb.org/anthology/S19-2007</a>
                </li>
                <li>Link to data: <a
                        href="competitions.codalab.org/competitions/19935">http://competitions.codalab.org/competitions/19935</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),
                    Within Hate (Agressive, Not)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 13,000</li>
                <li>Percentage abusive: 0.4</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Pardo, F., Rosso, P. and
                    Sanguinetti, M., 2019. SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants
                    and Women in Twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation.
                    Minneapolis, Minnesota: Association for Computational Linguistics, pp.54-63.</li>
            </ul>

            <h4 id="peer-to-peer-hate-hate-speech-instigators-and-their-targets">Peer to Peer Hate: Hate Speech
                Instigators and Their Targets</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17905/16996">https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17905/16996</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/mayelsherif/hate_speech_icwsm18">https://github.com/mayelsherif/hate_speech_icwsm18</a>
                </li>
                <li>Task description: Binary (Hate/Not), only for tweets which have both a Hate Instigator and Hate
                    Target</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 27,330</li>
                <li>Percentage abusive: 0.98</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: ElSherief, M., Nilizadeh, S., Nguyen, D., Vigna, G. and Belding, E., 2018. Peer to Peer
                    Hate: Hate Speech Instigators and Their Targets. In: Proceedings of the Twelfth International AAAI
                    Conference on Web and Social Media (ICWSM 2018). Santa Barbara, California: University of
                    California, pp.52-61.</li>
            </ul>

            <h4
                id="overview-of-the-hasoc-track-at-fire-2019-hate-speech-and-offensive-content-identification-in-indo-european-languages">
                Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in
                Indo-European Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true">https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true</a>
                </li>
                <li>Link to data: <a
                        href="https://hasocfire.github.io/hasoc/2019/dataset.html">https://hasocfire.github.io/hasoc/2019/dataset.html</a>
                </li>
                <li>Task description: Branching structure of tasks. A: Hate / Offensive or Neither, B: Hatespeech,
                    Offensive, or Profane, C: Targeted or Untargeted</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 7,005</li>
                <li>Percentage abusive: 0.36</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.
                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information
                    Retrieval Evaluation,.</li>
            </ul>

            <h4 id="detecting-east-asian-prejudice-on-social-media">Detecting East Asian Prejudice on Social media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.alw-1.19.pdf">https://www.aclweb.org/anthology/2020.alw-1.19.pdf</a>
                </li>
                <li>Link to data: <a href="https://zenodo.org/record/3816667">https://zenodo.org/record/3816667</a></li>
                <li>Task description: Task 1: Thematic annotation (East Asia/Covid-19) Task 2: Primary category
                    annotation: 1) Hostility against an East Asian (EA) entity 2) Criticism of an East Asian entity 3)
                    Counter speech 5) Discussion of East Asian prejudice 5) Non-related. Task 3: Secondary category
                    annotation (if (1) or (2) - identifying what East Asian entity was targeted + if (1) interpersonal
                    abuse/threatening language/dehumanization).</li>
                <li>Details of task: Detecting East Asian prejudice</li>
                <li>Size of dataset: 20,000</li>
                <li>Percentage abusive: 27% (Hostility, 19.5%; Criticism, 7.2%)</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Vidgen, B., Botelho, A., Broniatowski, D., Guest, E., Hall, M., Margetts, H., Tromble,
                    R., Waseem, Z. and Hale, S., Detecting East Asian Prejudice on Social media, 2020, In: Proceedings
                    of the Fourth Workshop on Online Abuse and Harms, pp.162–172</li>
            </ul>

            <h4 id="large-scale-crowdsourcing-and-characterization-of-twitter-abusive-behavior">Large Scale
                Crowdsourcing and Characterization of Twitter Abusive Behavior</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1802.00393.pdf">https://arxiv.org/pdf/1802.00393.pdf</a></li>
                <li>Link to data: <a
                        href="https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN">https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN</a>
                </li>
                <li>Task description: Multi-thematic (Abusive, Hateful, Normal, Spam)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 80,000</li>
                <li>Percentage abusive: 0.18</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Annotation process: Very detailed information is given: multiple rounds, using a smaller 300 tweet
                    dataset for testing the schema. For the final 80k, 5 judgements per tweet. CrowdFlower</li>
                <li>Annotation agreement: 55.9% = 4/5, 36.6% = 3/5, 7.5% = 2/5</li>
                <li>Reference: Founta, A., Djouvas, C., Chatzakou, D., Leontiadis, I., Blackburn, J., Stringhini, G.,
                    Vakali, A., Sirivianos, M. and Kourtellis, N., 2018. Large Scale Crowdsourcing and Characterization
                    of Twitter Abusive Behavior. ArXiv,.</li>
            </ul>

            <h4 id="a-large-labeled-corpus-for-online-harassment-research">A Large Labeled Corpus for Online Harassment
                Research</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.cs.umd.edu/~golbeck/papers/trolling.pdf">http://www.cs.umd.edu/~golbeck/papers/trolling.pdf</a>
                </li>
                <li>Link to data: jgolbeck@umd.edu</li>
                <li>Task description: Binary (Harassment, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 35,000</li>
                <li>Percentage abusive: 0.16</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Golbeck, J., Ashktorab, Z., Banjo, R., Berlinger, A., Bhagwan, S., Buntain, C.,
                    Cheakalos, P., Geller, A., Gergory, Q., Gnanasekaran, R., Gnanasekaran, R., Hoffman, K., Hottle, J.,
                    Jienjitlert, V., Khare, S., Lau, R., Martindale, M., Naik, S., Nixon, H., Ramachandran, P., Rogers,
                    K., Rogers, L., Sarin, M., Shahane, G., Thanki, J., Vengataraman, P., Wan, Z. and Wu, D., 2017. A
                    Large Labeled Corpus for Online Harassment Research. In: Proceedings of the 2017 ACM on Web Science
                    Conference. New York: Association for Computing Machinery, pp.229-233.</li>
            </ul>

            <h4 id="ex-machina-personal-attacks-seen-at-scale-personal-attacks">Ex Machina: Personal Attacks Seen at
                Scale, Personal attacks</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1610.08914">https://arxiv.org/pdf/1610.08914</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ewulczyn/wiki-detox">https://github.com/ewulczyn/wiki-detox</a></li>
                <li>Task description: Binary (Personal attack, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 115,737</li>
                <li>Percentage abusive: 0.12</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Wikipedia</li>
                <li>Medium: Text</li>
                <li>Reference: Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.
                    ArXiv,.</li>
            </ul>

            <h4 id="ex-machina-personal-attacks-seen-at-scale-toxicity">Ex Machina: Personal Attacks Seen at Scale,
                Toxicity</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1610.08914">https://arxiv.org/pdf/1610.08914</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ewulczyn/wiki-detox">https://github.com/ewulczyn/wiki-detox</a></li>
                <li>Task description: Toxicity/healthiness judgement (-2 == very toxic, 0 == neutral, 2 == very healthy)
                </li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 100,000</li>
                <li>Percentage abusive: NA</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Wikipedia</li>
                <li>Medium: Text</li>
                <li>Reference: Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.
                    ArXiv,.</li>
            </ul>

            <h4 id="detecting-cyberbullying-in-online-communities-world-of-warcraft">Detecting cyberbullying in online
                communities (World of Warcraft)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://aisel.aisnet.org/ecis2016_rp/61/">http://aisel.aisnet.org/ecis2016_rp/61/</a></li>
                <li>Link to data: <a href="http://ub-web.de/research/">http://ub-web.de/research/</a></li>
                <li>Task description: Binary (Harassment, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 16,975</li>
                <li>Percentage abusive: 0.01</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: World of Warcraft</li>
                <li>Medium: Text</li>
                <li>Reference: Bretschneider, U. and Peters, R., 2016. Detecting Cyberbullying in Online Communities.
                    Research Papers, 61.</li>
            </ul>

            <h4 id="detecting-cyberbullying-in-online-communities-league-of-legends">Detecting cyberbullying in online
                communities (League of Legends)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://aisel.aisnet.org/ecis2016_rp/61/">http://aisel.aisnet.org/ecis2016_rp/61/</a></li>
                <li>Link to data: <a href="http://ub-web.de/research/">http://ub-web.de/research/</a></li>
                <li>Task description: Binary (Harassment, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 17,354</li>
                <li>Percentage abusive: 0.01</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: League of Legends</li>
                <li>Medium: Text</li>
                <li>Reference: Bretschneider, U. and Peters, R., 2016. Detecting Cyberbullying in Online Communities.
                    Research Papers, 61.</li>
            </ul>

            <h4 id="a-quality-type-aware-annotated-corpus-and-lexicon-for-harassment-research">A Quality Type-aware
                Annotated Corpus and Lexicon for Harassment Research</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1802.09416.pdf">https://arxiv.org/pdf/1802.09416.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/Mrezvan94/Harassment-Corpus">https://github.com/Mrezvan94/Harassment-Corpus</a>
                </li>
                <li>Task description: Multi-topic harassment detection</li>
                <li>Details of task: Racism, Sexism, Appearance-related, Intellectual, Political</li>
                <li>Size of dataset: 24,189</li>
                <li>Percentage abusive: 0.13</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Rezvan, M., Shekarpour, S., Balasuriya, L., Thirunarayan, K., Shalin, V. and Sheth, A.,
                    2018. A Quality Type-aware Annotated Corpus and Lexicon for Harassment Research. ArXiv,.</li>
            </ul>

            <h4 id="ex-machina-personal-attacks-seen-at-scale-aggression-and-friendliness">Ex Machina: Personal Attacks
                Seen at Scale, Aggression and Friendliness</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1610.08914">https://arxiv.org/pdf/1610.08914</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ewulczyn/wiki-detox">https://github.com/ewulczyn/wiki-detox</a></li>
                <li>Task description: Aggression/friendliness judgement on a 5 point scale. (-2 == very aggressive, 0 ==
                    neutral, 3 == very friendly).</li>
                <li>Details of task: Person-Directed + Group-Directed</li>
                <li>Size of dataset: 160,000</li>
                <li>Percentage abusive: NA</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Wikipedia</li>
                <li>Medium: Text</li>
                <li>Reference: Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.
                    ArXiv,.</li>
            </ul>

            <h4 id="are-chess-discussions-racist-an-adversarial-hate-speech-data-set">Are Chess Discussions Racist? An
                Adversarial Hate Speech Data Set</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2011.10280.pdf">https://arxiv.org/pdf/2011.10280.pdf</a></li>
                <li>Link to data: <a
                        href="https://www.cs.cmu.edu/~akhudabu/Chess.html">https://www.cs.cmu.edu/~akhudabu/Chess.html</a>
                </li>
                <li>Task description: Not Labeled</li>
                <li>Details of task: Racism, Misclassification</li>
                <li>Size of dataset: 1,000</li>
                <li>Percentage abusive: 0.0</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Rupak Sarkar and Ashiqur R. KhudaBukhsh, Nov. 2020. Are Chess Discussions Racist? An
                    Adversarial Hate Speech Data Set. In: The Thirty-Fifth {AAAI} Conference on Artificial Intelligence,
                    {AAAI} 2021</li>
            </ul>

            <h4 id="ethos-an-online-hate-speech-detection-dataset-binary">ETHOS: an Online Hate Speech Detection Dataset
                (Binary)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.08328.pdf">https://arxiv.org/pdf/2006.08328.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset">https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Gender, Race, National Origin, Disability, Religion, Sexual Orientation</li>
                <li>Size of dataset: 998</li>
                <li>Percentage abusive: 0.43</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube, Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Mollas, I., Chrysopoulou, Z., Karlos, S., and Tsoumakas, G., 2021. ETHOS: an Online Hate
                    Speech Detection Dataset. Complex &amp; Intelligent Systems, Jan. 2022</li>
            </ul>

            <h4 id="ethos-an-online-hate-speech-detection-dataset-multi-label">ETHOS: an Online Hate Speech Detection
                Dataset (Multi label)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.08328.pdf">https://arxiv.org/pdf/2006.08328.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset">https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset</a>
                </li>
                <li>Task description: 8 Categories (Violence, Directed/Undirected, Gender, Race, National Origin,
                    Disability, Sexual Orientation, Religion)</li>
                <li>Details of task: Gender, Race, National Origin, Disability, Religion, Sexual Orientation</li>
                <li>Size of dataset: 433</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube, Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Mollas, I., Chrysopoulou, Z., Karlos, S., and Tsoumakas, G., 2021. ETHOS: an Online Hate
                    Speech Detection Dataset. Complex &amp; Intelligent Systems, Jan. 2022</li>
            </ul>

            <h4 id="twitter-sentiment-analysis">Twitter Sentiment Analysis</h4>
            <ul>
                <li>Link to publication: NA</li>
                <li>Link to data: <a
                        href="https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech">https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Racism, Sexism</li>
                <li>Size of dataset: 31,961</li>
                <li>Percentage abusive: 0.07</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ali Toosi, Jan 2019. Twitter Sentiment Analysis</li>
            </ul>

            <h4 id="toxicity-detection-does-context-really-matter-cat-large-no-context">Toxicity Detection: Does Context
                Really Matter? CAT-LARGE (No Context)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.00998.pdf">https://arxiv.org/pdf/2006.00998.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/ipavlopoulos/context_toxicity">https://github.com/ipavlopoulos/context_toxicity</a>
                </li>
                <li>Task description: Binary (Toxic, Non-toxic)</li>
                <li>Details of task: Toxicity, Context</li>
                <li>Size of dataset: 10,000</li>
                <li>Percentage abusive: 0.006</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Wikipedia Talk Pages</li>
                <li>Medium: Text</li>
                <li>Reference: Pavlopoulos, J., Sorensen, J., Dixon, L., Thain, N., &amp; Androutsopoulos, I. (2020).
                    Toxicity Detection: Does Context Really Matter? ArXiv:2006.00998 [Cs].</li>
            </ul>

            <h4 id="toxicity-detection-does-context-really-matter-cat-large-with-context">Toxicity Detection: Does
                Context Really Matter? CAT-LARGE (With Context)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.00998.pdf">https://arxiv.org/pdf/2006.00998.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/ipavlopoulos/context_toxicity">https://github.com/ipavlopoulos/context_toxicity</a>
                </li>
                <li>Task description: Binary (Toxic, Non-toxic)</li>
                <li>Details of task: Toxicity, Context</li>
                <li>Size of dataset: 10,000</li>
                <li>Percentage abusive: 0.02</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Wikipedia Talk Pages</li>
                <li>Medium: Text</li>
                <li>Reference: Pavlopoulos, J., Sorensen, J., Dixon, L., Thain, N., &amp; Androutsopoulos, I. (2020).
                    Toxicity Detection: Does Context Really Matter? ArXiv:2006.00998 [Cs].</li>
            </ul>

            <h4
                id="anatomy-of-online-hate-developing-a-taxonomy-and-machine-learning-models-for-identifying-and-classifying-hate-in-online-news-media">
                Anatomy of Online Hate: Developing a Taxonomy and Machine Learning Models for Identifying and
                Classifying Hate in Online News Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewFile/17885/17024">https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewFile/17885/17024</a>
                </li>
                <li>Link to data: <a
                        href="https://www.dropbox.com/s/21wtzy9arc5skr8/ICWSM18%20-%20SALMINEN%20ET%20AL.xlsx?dl=0">https://www.dropbox.com/s/21wtzy9arc5skr8/ICWSM18%20-%20SALMINEN%20ET%20AL.xlsx?dl=0</a>
                </li>
                <li>Task description: Binary (Hate, Not), Multinomial classification (21 categories divided into
                    ‘hateful language’, ‘hate targets’ and ‘hate sub-targets’)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 5,143</li>
                <li>Percentage abusive: 82%</li>
                <li>Language: English</li>
                <li>Level of annotation: Comment</li>
                <li>Platform: YouTube and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Salminen, J., Almerekhi, H., Milenković, M., Jung, S., An, J., Kwak, H. and Jansen, B.,
                    2018, Anatomy of Online Hate: Developing a Taxonomy and Machine Learning Models for Identifying and
                    Classifying Hate in Online News Media, In: Proceedings of the Twelfth International AAAI Conference
                    on Web and Social Media (ICWSM 2018), pp.330-339</li>
            </ul>

            <p><a id="Estonian-header"></a></p>
            <h3 id="estonian">Estonian</h3>
            <h4 id="automating-news-comment-moderation-with-limited-resources-benchmarking-in-croatian-and-estonian-1">
                Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf">https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf</a>
                </li>
                <li>Link to data: <a href="http://hdl.handle.net/11356/1401">http://hdl.handle.net/11356/1401</a></li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content performmed by the real newspaper moderators</li>
                <li>Size of dataset: 31.5M</li>
                <li>Percentage abusive: 12.5%</li>
                <li>Language: Estonian (some in Russian also)</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Newspaper comments, Eesti Ekspress (www.ekspress.ee) website</li>
                <li>Medium: Text</li>
                <li>Reference: Ravi Shekhar, Marko Pranjić, Senja Pollak, Andraž Pelicon, Matthew Purver (2020).
                    Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian.
                    Journal for Language Technology and Computational Linguistics (JLCL).</li>
            </ul>

            <h4 id="hatexplain-a-benchmark-dataset-for-explainable-hate-speech-detection-1">HateXplain: A Benchmark
                Dataset for Explainable Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2012.10289.pdf">https://arxiv.org/pdf/2012.10289.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/punyajoy/HateXplain">https://github.com/punyajoy/HateXplain</a></li>
                <li>Task description: Binary (Hate, Not) and Three-class (Hate speech, Offensive language, None)</li>
                <li>Details of task: Hatespeech detection on social media in English, including 10 categories: African,
                    Islam, Jewish, LGBTQ, Women, Refugee, Arab, Caucasian, Hispanic, Asian</li>
                <li>Size of dataset: 20148</li>
                <li>Percentage abusive: 57%</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Mathew, B., Saha, P., Yimam, S. M., Biemann, C., Goyal, P., &amp; Mukherjee, A. (2020).
                    Hatexplain: A benchmark dataset for explainable hate speech detection. arXiv preprint
                    arXiv:2012.10289.</li>
            </ul>

            <p><a id="French-header"></a></p>
            <h3 id="french">French</h3>
            <h4
                id="conan---counter-narratives-through-nichesourcing-a-multilingual-dataset-of-responses-to-fight-online-hate-speech-french">
                CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online
                Hate Speech (French)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/P19-1271.pdf">https://www.aclweb.org/anthology/P19-1271.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (Islamophobic / not), Multi-topic (Culture, Economics, Crimes, Rapism,
                    Terrorism, Women Oppression, History, Other/generic)</li>
                <li>Details of task: Islamophobia</li>
                <li>Size of dataset: 1,719</li>
                <li>Percentage abusive: 1</li>
                <li>Language: French</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Synthetic / Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives
                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:
                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,
                    Italy: Association for Computational Linguistics, pp.2819-2829.</li>
            </ul>

            <h4 id="multilingual-and-multi-aspect-hate-speech-analysis-french">Multilingual and Multi-Aspect Hate Speech
                Analysis (French)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1908.11049">https://arxiv.org/abs/1908.11049</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HKUST-KnowComp/MLMA_hate_speech">https://github.com/HKUST-KnowComp/MLMA_hate_speech</a>
                </li>
                <li>Task description: Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target
                    Attribute, Target Group, How annotators felt on seeing the tweet.</li>
                <li>Details of task: Gender, Sexual orientation, Religion, Disability</li>
                <li>Size of dataset: 4,014</li>
                <li>Percentage abusive: 0.72</li>
                <li>Language: French</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and
                    Multi-Aspect Hate Speech Analysis. ArXiv,.</li>
            </ul>

            <p><a id="German-header"></a></p>
            <h3 id="german">German</h3>
            <h4 id="rp-mod--rp-crowd-moderator--and-crowd-annotated-german-news-comment-datasets">RP-Mod &amp; RP-Crowd:
                Moderator- and Crowd-Annotated German News Comment Datasets</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/c9e1074f5b3f9fc8ea15d152add07294-Paper-round2.pdf">https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/c9e1074f5b3f9fc8ea15d152add07294-Paper-round2.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://zenodo.org/record/5291339#.Ybr_9VkxkUE">https://zenodo.org/record/5291339#.Ybr_9VkxkUE</a>
                </li>
                <li>Task description: Binary (Offensive or Not), Multi-class/-label (sexism, racism, threats, insults,
                    profane language, meta, advertisement).</li>
                <li>Details of task: The comments originate from a large German newspaper and are annotated by
                    professional moderators (community managers). Additionally, each comment was further annotated by
                    five different crowd-workers.</li>
                <li>Size of dataset: 85,000</li>
                <li>Percentage abusive: 8.4%</li>
                <li>Language: German</li>
                <li>Level of annotation: Comments</li>
                <li>Platform: German Newspaper (Rheinische Post)</li>
                <li>Medium: Text</li>
                <li>Reference: Assenmacher, D., Niemann, M., Müller, K., Seiler, M., Riehle, D. M., &amp; Trautmann, H.
                    (2021). RP-Mod &amp; RP-Crowd: Moderator- and crowd-annotated german news comment datasets. In
                    Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmark.</li>
            </ul>

            <h4 id="measuring-the-reliability-of-hate-speech-annotations-the-case-of-the-european-refugee-crisis">
                Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1701.08118.pdf">https://arxiv.org/pdf/1701.08118.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/UCSM-DUE/IWG_hatespeech_public">https://github.com/UCSM-DUE/IWG_hatespeech_public</a>
                </li>
                <li>Task description: Binary (Anti-refugee hate, None)</li>
                <li>Details of task: Refugees</li>
                <li>Size of dataset: 469</li>
                <li>Percentage abusive: NA</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ross, B., Rist, M., Carbonell, G., Cabrera, B., Kurowsky, N. and Wojatzki, M., 2017.
                    Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis.
                    ArXiv,.</li>
            </ul>

            <h4 id="detecting-offensive-statements-towards-foreigners-in-social-media">Detecting Offensive Statements
                Towards Foreigners in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://pdfs.semanticscholar.org/23dc/df7c7e82807445afd9f19474fc0a3d8169fe.pdf">https://pdfs.semanticscholar.org/23dc/df7c7e82807445afd9f19474fc0a3d8169fe.pdf</a>
                </li>
                <li>Link to data: <a href="http://ub-web.de/research/">http://ub-web.de/research/</a></li>
                <li>Task description: Hierarchical (Anti-foreigner prejudice, split into (1) slightly
                    offensive/offensive and (2) explicitly/substantially offensive). 6 targets (Foreigner, Government,
                    Press, Community, Other, Unknown)</li>
                <li>Details of task: Anti-foreigner prejudice</li>
                <li>Size of dataset: 5,836</li>
                <li>Percentage abusive: 0.11</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Bretschneider, U. and Peters, R., 2017. Detecting Offensive Statements towards Foreigners
                    in Social Media. In: Proceedings of the 50th Hawaii International Conference on System Sciences.
                </li>
            </ul>

            <h4 id="germeval-2018">GermEval 2018</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.researchgate.net/publication/327914386_Overview_of_the_GermEval_2018_Shared_Task_on_the_Identification_of_Offensive_Language">https://www.researchgate.net/publication/327914386_Overview_of_the_GermEval_2018_Shared_Task_on_the_Identification_of_Offensive_Language</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/uds-lsv/GermEval-2018-Data">https://github.com/uds-lsv/GermEval-2018-Data</a>
                </li>
                <li>Task description: Branching structure: Binary (Offense, Other), 3 levels within Offense (Abuse,
                    Insult, Profanity)</li>
                <li>Details of task: Group-directed + Incivility</li>
                <li>Size of dataset: 8,541</li>
                <li>Percentage abusive: 0.34</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared
                    Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference
                    on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate.</li>
            </ul>

            <h4
                id="overview-of-the-hasoc-track-at-fire-2019-hate-speech-and-offensive-content-identification-in-indo-european-languages-1">
                Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in
                Indo-European Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true">https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true</a>
                </li>
                <li>Link to data: <a
                        href="https://hasocfire.github.io/hasoc/2019/dataset.html">https://hasocfire.github.io/hasoc/2019/dataset.html</a>
                </li>
                <li>Task description: A: Hate / Offensive or neither, B: Hatespeech, Offensive, or Profane</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 4,669</li>
                <li>Percentage abusive: 0.24</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.
                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information
                    Retrieval Evaluation,.</li>
            </ul>

            <p><a id="Greek-header"></a></p>
            <h3 id="greek">Greek</h3>
            <h4 id="deep-learning-for-user-comment-moderation-flagged-comments">Deep Learning for User Comment
                Moderation, Flagged Comments</h4>
            <ul>
                <li>Link to publication: <a href="https://www.aclweb.org/anthology/W17-3004
https://www.aclweb.org/anthology/D17-1117">https://www.aclweb.org/anthology/W17-3004</a></li>
                <li>Link to data: <a href="http://www.straintek.com/data/">http://www.straintek.com/data/</a></li>
                <li>Task description: Binary (Flagged, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 1,450,000</li>
                <li>Percentage abusive: 0.34</li>
                <li>Language: Greek</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Gazetta</li>
                <li>Medium: text</li>
                <li>Reference: Pavlopoulos, J., Malakasiotis, P. and Androutsopoulos, I., 2017. Deep Learning for User
                    Comment Moderation. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver,
                    Canada: Association for Computational Linguistics, pp.25-35.</li>
            </ul>

            <h4 id="deep-learning-for-user-comment-moderation-moderated-comments">Deep Learning for User Comment
                Moderation, Moderated Comments</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W17-3004">https://www.aclweb.org/anthology/W17-3004</a>
                </li>
                <li>Link to data: <a href="http://www.straintek.com/data/">http://www.straintek.com/data/</a></li>
                <li>Task description: Binary (Flagged, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 1,500</li>
                <li>Percentage abusive: 0.22</li>
                <li>Language: Greek</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Gazetta</li>
                <li>Medium: text</li>
                <li>Reference: Pavlopoulos, J., Malakasiotis, P. and Androutsopoulos, I., 2017. Deep Learning for User
                    Comment Moderation. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver,
                    Canada: Association for Computational Linguistics, pp.25-35.</li>
            </ul>

            <h4 id="offensive-language-identification-in-greek">Offensive Language Identification in Greek</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2003.07459v1.pdf">https://arxiv.org/pdf/2003.07459v1.pdf</a></li>
                <li>Link to data: <a
                        href="https://sites.google.com/site/offensevalsharedtask/home">https://sites.google.com/site/offensevalsharedtask/home</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,
                    Not), Within Target (Individual, Group, Other)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 4779</li>
                <li>Percentage abusive: 0.29</li>
                <li>Language: Greek</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Pitenis, Z., Zampieri, M. and Ranasinghe, T., 2020. Offensive Language Identification in
                    Greek. ArXiv.</li>
                <li>Dataset reader: 🤗 <a
                        href="https://huggingface.co/datasets/strombergnlp/offenseval_2020">strombergnlp/offenseval_2020</a>
                </li>
            </ul>

            <p><a id="Hindi-header"></a></p>
            <h3 id="hindi--hindi-english">Hindi / Hindi-English</h3>
            <h4 id="hostility-detection-dataset-in-hindi">Hostility Detection Dataset in Hindi</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2011.03588.pdf">https://arxiv.org/pdf/2011.03588.pdf</a></li>
                <li>Link to data: <a
                        href="https://competitions.codalab.org/competitions/26654">https://competitions.codalab.org/competitions/26654</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hostile, Not Hostile), Multi-tags within
                    Hostile (Fake News, Hate, Offense, Defame)</li>
                <li>Details of task: Hostility detection</li>
                <li>Size of dataset: 8,192</li>
                <li>Percentage abusive: 47%</li>
                <li>Language: Hindi</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter, Facebook, WhatsApp</li>
                <li>Medium: Text</li>
                <li>Reference: Bhardwaj, M., Akhtar, M.S., Ekbal, A., Das, A. and Chakraborty, T., 2020. Hostility
                    detection dataset in hindi. arXiv preprint arXiv:2011.03588.</li>
            </ul>

            <h4 id="aggression-annotated-corpus-of-hindi-english-code-mixed-data">Aggression-annotated Corpus of
                Hindi-English Code-mixed Data</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1803.09402">https://arxiv.org/pdf/1803.09402</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/kraiyani/Facebook-Post-Aggression-Identification">https://github.com/kraiyani/Facebook-Post-Aggression-Identification</a>
                </li>
                <li>Task description: 3 part hierachy for hate (None, Covert Aggression, Overt Aggression), 4 part
                    target categorisation (Physical threat, Sexual threat, Identity threat, Non-threatening aggression),
                    3-part discursive role categorisation (Attack, Defend, Abet)</li>
                <li>Details of task: Numerous sub-categorizations</li>
                <li>Size of dataset: 18,000</li>
                <li>Percentage abusive: 0.06</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Kumar, R., Reganti, A., Bhatia, A. and Maheshwari, T., 2018. Aggression-annotated Corpus
                    of Hindi-English Code-mixed Data. ArXiv,.</li>
            </ul>

            <h4 id="aggression-annotated-corpus-of-hindi-english-code-mixed-data-1">Aggression-annotated Corpus of
                Hindi-English Code-mixed Data</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1803.09402">https://arxiv.org/pdf/1803.09402</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/kraiyani/Facebook-Post-Aggression-Identification">https://github.com/kraiyani/Facebook-Post-Aggression-Identification</a>
                </li>
                <li>Task description: 3 part hierachy for hate (None, Covert Aggression, Overt Aggression), 4 part
                    target categorisation (Physical threat, Sexual threat, Identity threat, Non-threatening aggression),
                    3-part discursive role categorisation (Attack, Defend, Abet)</li>
                <li>Details of task: Numerous sub-categorizations</li>
                <li>Size of dataset: 21,000</li>
                <li>Percentage abusive: 0.27</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Kumar, R., Reganti, A., Bhatia, A. and Maheshwari, T., 2018. Aggression-annotated Corpus
                    of Hindi-English Code-mixed Data. ArXiv,.</li>
            </ul>

            <h4 id="did-you-offend-me-classification-of-offensive-tweets-in-hinglish-language">Did You Offend Me?
                Classification of Offensive Tweets in Hinglish Language</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5118">https://www.aclweb.org/anthology/W18-5118</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/pmathur5k10/Hinglish-Offensive-Text-Classification">https://github.com/pmathur5k10/Hinglish-Offensive-Text-Classification</a>
                </li>
                <li>Task description: Hierarchy (Not Offensive, Abusive, Hate)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 3,189</li>
                <li>Percentage abusive: 0.65</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Mathur, P., Sawhney, R., Ayyar, M. and Shah, R., 2018. Did you offend me? Classification
                    of Offensive Tweets in Hinglish Language. In: Proceedings of the 2nd Workshop on Abusive Language
                    Online (ALW2). Brussels, Belgium: Association for Computational Linguistics, pp.138-148.</li>
            </ul>

            <h4 id="a-dataset-of-hindi-english-code-mixed-social-media-text-for-hate-speech-detection">A Dataset of
                Hindi-English Code-Mixed Social Media Text for Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-1105">https://www.aclweb.org/anthology/W18-1105</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/deepanshu1995/HateSpeech-Hindi-English-Code-Mixed-Social-Media-Text">https://github.com/deepanshu1995/HateSpeech-Hindi-English-Code-Mixed-Social-Media-Text</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 4,575</li>
                <li>Percentage abusive: 0.36</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Bohra, A., Vijay, D., Singh, V., Sarfaraz Akhtar, S. and Shrivastava, M., 2018. A Dataset
                    of Hindi-English Code-Mixed Social Media Text for Hate Speech Detection. In: Proceedings of the
                    Second Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social
                    Media. New Orleans, Louisiana: Association for Computational Linguistics, pp.36-41.</li>
            </ul>

            <h4
                id="overview-of-the-hasoc-track-at-fire-2019-hate-speech-and-offensive-content-identification-in-indo-european-languages-2">
                Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in
                Indo-European Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true">https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true</a>
                </li>
                <li>Link to data: <a
                        href="https://hasocfire.github.io/hasoc/2019/dataset.html">https://hasocfire.github.io/hasoc/2019/dataset.htm</a>
                </li>
                <li>Task description: A: Hate, Offensive or Neither, B: Hatespeech, Offensive, or Profane, C: Targeted
                    or Untargeted</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 5,983</li>
                <li>Percentage abusive: 0.51</li>
                <li>Language: Hindi</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.
                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information
                    Retrieval Evaluation,.</li>
            </ul>

            <p><a id="Indonesian-header"></a></p>
            <h3 id="indonesian">Indonesian</h3>
            <h4 id="hate-speech-detection-in-the-indonesian-language-a-dataset-and-preliminary-study">Hate Speech
                Detection in the Indonesian Language: A Dataset and Preliminary Study</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://ieeexplore.ieee.org/document/8355039">https://ieeexplore.ieee.org/document/8355039</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ialfina/id-hatespeech-detection">https://github.com/ialfina/id-hatespeech-detection</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 713</li>
                <li>Percentage abusive: 0.36</li>
                <li>Language: Indonesian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Alfina, I., Mulia, R., Fanany, M. and Ekanata, Y., 2017. Hate Speech Detection in the
                    Indonesian Language: A Dataset and Preliminary Study. In: International Conference on Advanced
                    Computer Science and Information Systems. pp.233-238.</li>
            </ul>

            <h4 id="multi-label-hate-speech-and-abusive-language-detection-in-indonesian-twitter">Multi-Label Hate
                Speech and Abusive Language Detection in Indonesian Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W19-3506">https://www.aclweb.org/anthology/W19-3506</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection">https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection</a>
                </li>
                <li>Task description: (No hate speech, No hate speech but abusive, Hate speech but no abuse, Hate speech
                    and abuse), within hate, category (Religion/creed, Race/ethnicity, Physical/disability,
                    Gender/sexual orientation, Other invective/slander), within hate, strength (Weak, Moderate and
                    Strong)</li>
                <li>Details of task: Religion, Race, Disability, Gender</li>
                <li>Size of dataset: 13,169</li>
                <li>Percentage abusive: 0.42</li>
                <li>Language: Indonesian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Okky Ibrohim, M. and Budi, I., 2019. Multi-label Hate Speech and Abusive Language
                    Detection in Indonesian Twitter. In: Proceedings of the Third Workshop on Abusive Language Online.
                    Florence, Italy: Association for Computational Linguistics, pp.46-57.</li>
            </ul>

            <h4 id="a-dataset-and-preliminaries-study-for-abusive-language-detection-in-indonesian-social-media">A
                Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.sciencedirect.com/science/article/pii/S1877050918314583">https://www.sciencedirect.com/science/article/pii/S1877050918314583</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/okkyibrohim/id-abusive-language-detection">https://github.com/okkyibrohim/id-abusive-language-detection</a>
                </li>
                <li>Task description: Hierarchical (Not abusive, Abusive but not offensive, Offensive)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 2,016</li>
                <li>Percentage abusive: 0.54</li>
                <li>Language: Indonesian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ibrohim, M. and Budi, I., 2018. A Dataset and Preliminaries Study for Abusive Language
                    Detection in Indonesian Social Media. Procedia Computer Science, 135, pp.222-229.</li>
            </ul>

            <p><a id="Korean-header"></a></p>
            <h3 id="korean">Korean</h3>
            <h4 id="beep-korean-corpus-of-online-news-comments-for-toxic-speech-detection__">BEEP! Korean Corpus of
                Online News Comments for Toxic Speech Detection__</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.socialnlp-1.4/">https://www.aclweb.org/anthology/2020.socialnlp-1.4</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/kocohub/korean-hate-speech">https://github.com/kocohub/korean-hate-speech</a>
                </li>
                <li>Task description: Binary (Gender bias, No gender bias), Ternary (Gender bias, Other biases, None),
                    Ternary (Hate, Offensive, None)</li>
                <li>Details of task: Person/Group-directed, Gender/Sexual orientation, Sexism, Harmfulness/Toxicity</li>
                <li>Size of dataset: 9,381</li>
                <li>Percentage abusive: 33.87 (Bias), 57.77 (Toxicity)</li>
                <li>Language: Korean</li>
                <li>Level of annotation: Comments</li>
                <li>Platform: NAVER entertainment news</li>
                <li>Medium: Text</li>
                <li>Reference: Moon, J., Cho, W. I., and Lee, J., 2020. BEEP! Korean Corpus of Online News Comments for
                    Toxic Speech Detection. In: Proceedings of the Eighth International Workshop on Natural Language
                    Processing for Social Media Month: July. Online: Association for Computational Linguistics,
                    pp.25-31.</li>
            </ul>

            <p><a id="Latvian-header"></a></p>
            <h3 id="latvian">Latvian</h3>
            <h4 id="latvian-newspaper-user-comment-dataset">Latvian newspaper user comment dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.hackashop-1.14.pdf">https://aclanthology.org/2021.hackashop-1.14.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://www.clarin.si/repository/xmlui/handle/11356/1407">https://www.clarin.si/repository/xmlui/handle/11356/1407</a>
                </li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content performmed by the real newspaper moderators</li>
                <li>Size of dataset: 12M</li>
                <li>Percentage abusive: ~10%</li>
                <li>Language: Latvian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Newspaper comments</li>
                <li>Medium: Text</li>
                <li>Reference: Senja Pollak, Marko Robnik-Šikonja, Matthew Purver, Michele Boggia, Ravi Shekhar, Marko
                    Pranjić, Salla Salmela, Ivar Krustok, Tarmo Paju, Carl-Gustav Linden, Leo Leppänen, Elaine Zosa,
                    Matej Ulčar, Linda Freiental, Silver Traat, Luis Adrián Cabrera-Diego, Matej Martinc, Nada Lavrač,
                    Blaž Škrlj, Martin Žnidaršič, Andraž Pelicon, Boshko Koloski, Vid Podečan, Janez Kranjc, Shane
                    Sheehan, Emanuela Boros, Jose Moreno, Antoine Doucet, Hannu Toivonen (2021). EMBEDDIA Tools,
                    Datasets and Challenges: Resources and Hackathon Contributions. Proceedings of the Hackashop on News
                    Media Content Analysis and Automated Report Generation (EACL).</li>
            </ul>

            <p><a id="Italian-header"></a></p>
            <h3 id="italian">Italian</h3>
            <h4 id="an-italian-twitter-corpus-of-hate-speech-against-immigrants">An Italian Twitter Corpus of Hate
                Speech against Immigrants</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/L18-1443">https://www.aclweb.org/anthology/L18-1443</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/msang/hate-speech-corpus">https://github.com/msang/hate-speech-corpus</a>
                </li>
                <li>Task description: Binary (Immigrants/Roma/Muslims, Not), additional categories. Within Hate,
                    Intensity measurement (Aggressiveness: No, Weak, Strong, Offensiveness: No, Weak, Strong, Irony: No,
                    Yes, Stereotype: No, Yes, Incitement degree: 0-4)</li>
                <li>Details of task: Immigrants, Roma and Muslims + numerous sub-categorizations</li>
                <li>Size of dataset: 1,827</li>
                <li>Percentage abusive: 0.13</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Sanguinetti, M., Poletto, F., Bosco, C., Patti, V. and Stranisci, M., 2018. An Italian
                    Twitter Corpus of Hate Speech against Immigrants. In: Proceedings of the Eleventh International
                    Conference on Language Resources and Evaluation (LREC 2018). Miyazaki, Japan: European Language
                    Resources Association (ELRA).</li>
            </ul>

            <h4 id="overview-of-the-evalita-2018-hate-speech-detection-task-facebook">Overview of the EVALITA 2018 Hate
                Speech Detection Task (Facebook)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2263/paper010.pdf">http://ceur-ws.org/Vol-2263/paper010.pdf</a>
                </li>
                <li>Link to data: <a
                        href="http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html">http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html</a>
                </li>
                <li>Task description: Binary (Hate, Not), Within hate for Facebook only, strength (No hate, Weak hate,
                    Strong hate) and theme ((1) religion, (2) physical and/or mental handicap, (3) socio-economic
                    status, (4) politics, (5) race, (6) sex and gender, (7) Other)</li>
                <li>Details of task: Religion, physical and/or mental handicap, socio-economic status, politics, race,
                    sex and gender</li>
                <li>Size of dataset: 4,000</li>
                <li>Percentage abusive: 0.51</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Bosco, C., Dell’Orletta, F. and Poletto, F., 2018. Overview of the EVALITA 2018 Hate
                    Speech Detection Task. In: EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and
                    Speech Tools for Italian. CEUR, pp.1-9.</li>
            </ul>

            <h4 id="overview-of-the-evalita-2018-hate-speech-detection-task-twitter">Overview of the EVALITA 2018 Hate
                Speech Detection Task (Twitter)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2263/paper010.pdf">http://ceur-ws.org/Vol-2263/paper010.pdf</a>
                </li>
                <li>Link to data: <a
                        href="http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html">http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html</a>
                </li>
                <li>Task description: Binary (Hate, Not), Within Hate For Twitter only Intensity (1-4 rating),
                    Aggressiveness (No, Weak, Strong), Offensiveness (No, Weak, Strong), Irony (Yes, No)</li>
                <li>Details of task: Group-directed</li>
                <li>Size of dataset: 4,000</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Bosco, C., Dell’Orletta, F. and Poletto, F., 2018. Overview of the EVALITA 2018 Hate
                    Speech Detection Task. In: EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and
                    Speech Tools for Italian. CEUR, pp.1-9.</li>
            </ul>

            <h4 id="automatic-misogyny-identification-ami-at-evalita-2020">Automatic Misogyny Identification (AMI) at
                Evalita 2020</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2765/paper161.pdf">http://ceur-ws.org/Vol-2765/paper161.pdf</a>
                </li>
                <li>Link to data: <a href="https://github.com/dnozza/ami2020">https://github.com/dnozza/ami2020</a></li>
                <li>Task description: Binary (misogyny / not), Binary (aggressive / not), Binary on synthetic fairness
                    test (misogyny / not)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 6,000 and 1,961 (synthetic fairness test)</li>
                <li>Percentage abusive: 47% and 50% (synthetic fairness test)</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fersini, E., Nozza, D., and Rosso, P., 2020. AMI @ EVALITA2020: Automatic Misogyny
                    Identification. In: Proceedings of the 7th evaluation campaign of Natural Language Processing and
                    Speech tools for Italian (EVALITA 2020).</li>
            </ul>

            <h4
                id="conan---counter-narratives-through-nichesourcing-a-multilingual-dataset-of-responses-to-fight-online-hate-speech-italian">
                CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online
                Hate Speech (Italian)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/P19-1271.pdf">https://www.aclweb.org/anthology/P19-1271.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (Islamophobic, Not), Multi-topic (Culture, Economics, Crimes, Rapism,
                    Terrorism, Women Oppression, History, Other/generic)</li>
                <li>Details of task: Islamophobia</li>
                <li>Size of dataset: 1,071</li>
                <li>Percentage abusive: 1</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Synthetic / Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives
                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:
                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,
                    Italy: Association for Computational Linguistics, pp.2819-2829.</li>
            </ul>

            <h4 id="creating-a-whatsapp-dataset-to-study-pre-teen-cyberbullying">Creating a WhatsApp Dataset to Study
                Pre-teen Cyberbullying</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5107">https://www.aclweb.org/anthology/W18-5107</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/dhfbk/WhatsApp-Dataset">https://github.com/dhfbk/WhatsApp-Dataset</a>
                </li>
                <li>Task description: Binary (Cyberbullying, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 14,600</li>
                <li>Percentage abusive: 0.08</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts, structured into 10 chats, with token level information</li>
                <li>Platform: Synthetic / Whatsapp</li>
                <li>Medium: Text</li>
                <li>Reference: Sprugnoli, R., Menini, S., Tonelli, S., Oncini, F. and Piras, E., 2018. Creating a
                    WhatsApp Dataset to Study Pre-teen Cyberbullying. In: Proceedings of the 2nd Workshop on Abusive
                    Language Online (ALW2) Month: October. Brussels, Belgium: Association for Computational Linguistics,
                    pp.51-59.</li>
            </ul>

            <p><a id="Polish-header"></a></p>
            <h3 id="polish">Polish</h3>
            <h4
                id="results-of-the-poleval-2019-shared-task-6first-dataset-and-open-shared-task-for-automatic-cyberbullying-detection-in-polish-twitter">
                Results of the PolEval 2019 Shared Task 6:First Dataset and Open Shared Task for Automatic Cyberbullying
                Detection in Polish Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://poleval.pl/files/poleval2019.pdf">http://poleval.pl/files/poleval2019.pdf</a></li>
                <li>Link to data: <a href="http://poleval.pl/tasks/task6">http://poleval.pl/tasks/task6</a></li>
                <li>Task description: Harmfulness score (three values), Multilabel from seven phenomena</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 10,041</li>
                <li>Percentage abusive: 0.09</li>
                <li>Language: Polish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ogrodniczuk, M. and Kobyliński, L., 2019. Results of the PolEval 2019 Shared Task 6:
                    First Dataset and Open Shared Task for Automatic Cyberbullying Detection in Polish Twitter. In:
                    Proceedings of the PolEval 2019 Workshop. Warszawa: Institute of Computer Science, Polish Academy of
                    Sciences.</li>
            </ul>

            <p><a id="Portuguese-header"></a></p>
            <h3 id="portuguese">Portuguese</h3>

            <h4 id="toxic-language-dataset-for-brazilian-portuguese-told-br">Toxic Language Dataset for Brazilian
                Portuguese (ToLD-Br)</h4>
            <ul>
                <li>Link to publication: https://arxiv.org/abs/2010.04543</li>
                <li>Link to data: https://github.com/JAugusto97/ToLD-Br</li>
                <li>Task description: Multiclass (LGBTQ+phobia, Insult, Xenophobia, Misogyny, Obscene, Racism)</li>
                <li>Details of task: Three annotators per example, demographically diverse selected annotators.</li>
                <li>Size of dataset: 21.000</li>
                <li>Percentage abusive: 44%</li>
                <li>Language: Portuguese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: João A. Leite, Diego F. Silva, Kalina Bontcheva, Carolina Scarton (2020): Toxic Language
                    Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis.
                    AACL-IJCNLP 2020</li>
            </ul>

            <h4 id="a-hierarchically-labeled-portuguese-hate-speech-dataset">A Hierarchically-Labeled Portuguese Hate
                Speech Dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W19-3510">https://www.aclweb.org/anthology/W19-3510</a>
                </li>
                <li>Link to data: <a
                        href="https://b2share.eudat.eu/records/9005efe2d6be4293b63c3cffd4cf193e">https://b2share.eudat.eu/records/9005efe2d6be4293b63c3cffd4cf193e</a>
                </li>
                <li>Task description: Binary (Hate, Not), Multi-level (81 categories, identified inductively; categories
                    have different granularities and content can be assigned to multiple categories at once)</li>
                <li>Details of task: Multiple identities inductively categorized</li>
                <li>Size of dataset: 3,059</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: Portuguese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fortuna, P., Rocha da Silva, J., Soler-Company, J., Warner, L. and Nunes, S., 2019. A
                    Hierarchically-Labeled Portuguese Hate Speech Dataset. In: Proceedings of the Third Workshop on
                    Abusive Language Online. Florence, Italy: Association for Computational Linguistics, pp.94-104.</li>
            </ul>

            <h4 id="offensive-comments-in-the-brazilian-web-a-dataset-and-baseline-results">Offensive Comments in the
                Brazilian Web: A Dataset and Baseline Results</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.each.usp.br/digiampietri/BraSNAM/2017/p04.pdf">http://www.each.usp.br/digiampietri/BraSNAM/2017/p04.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/rogersdepelle/OffComBR">https://github.com/rogersdepelle/OffComBR</a>
                </li>
                <li>Task description: Binary (Offensive, Not), Target (Xenophobia, homophobia, sexism, racism, cursing,
                    religious intolerance)</li>
                <li>Details of task: Religion/creed, Race/ethnicity, Physical/disability, Gender/sexual orientation</li>
                <li>Size of dataset: 1,250</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Portuguese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: g1.globo.com</li>
                <li>Medium: Text</li>
                <li>Reference: de Pelle, R. and Moreira, V., 2017. Offensive Comments in the Brazilian Web: A Dataset
                    and Baseline Results. In: VI Brazilian Workshop on Social Network Analysis and Mining. SBC.</li>
            </ul>

            <p><a id="Russian-header"></a></p>
            <h3 id="russian">Russian</h3>
            <h4 id="reducing-unintended-identity-bias-in-russian-hate-speech-detection">Reducing Unintended Identity
                Bias in Russian Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2020.alw-1.8.pdf">https://aclanthology.org/2020.alw-1.8.pdf</a>
                </li>
                <li>Link to data: License Required (Last checked 17/01/2022)</li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Toxicity, Harassment, Sexism, Homophobia, Nationalism</li>
                <li>Size of dataset: 100,000</li>
                <li>Percentage abusive: NA</li>
                <li>Language: Russian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Zueva, Nadezhda, et al, Oct. 2020. Reducing Unintended Identity Bias in Russian Hate
                    Speech Detection. In: Proceedings of the Fourth Workshop on Online Abuse and Harms, pages 65–69</li>
            </ul>

            <h4 id="detection-of-abusive-speech-for-mixed-sociolects-of-russian-and-ukrainian-languages">Detection of
                Abusive Speech for Mixed Sociolects of Russian and Ukrainian Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf">https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bohdan1/AbusiveLanguageDataset">https://github.com/bohdan1/AbusiveLanguageDataset</a>
                </li>
                <li>Task description: Binary (True == Abusive, False == Not)</li>
                <li>Details of task: Multilingual, Abusive Words, Political</li>
                <li>Size of dataset: 2,000</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Surzhyk (Russian &amp; Ukranian)</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Andrusyak, B., Rimel, M. and Kern, R., 2018. Detection of Abusive Speech for Mixed
                    Sociolects of Russian and Ukrainian Languages. In: Proceedings of Recent Advances in Slavonic
                    Natural Language Processing, RASLAN 2018, pp. 77–84, 2018.</li>
            </ul>

            <h4 id="russian-south-park">Russian South Park</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.bsnlp-1.3/">https://aclanthology.org/2021.bsnlp-1.3/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/Sariellee/Russan-Hate-speech-Recognition">https://github.com/Sariellee/Russan-Hate-speech-Recognition</a>
                </li>
                <li>Task description: Binary (abusive, non-abusive)</li>
                <li>Details of task: Abusive language in Russian South Park scripts</li>
                <li>Size of dataset: 1400</li>
                <li>Percentage abusive: 22.2%</li>
                <li>Language: Russian</li>
                <li>Level of annotation: Sentence</li>
                <li>Platform: TV Subtitles</li>
                <li>Medium: text</li>
                <li>Reference: Saitov &amp; Derczynski, 2021. “Abusive Language Recognition in Russian”. Proceedings of
                    the 8th BSNLP Workshop on Balto-Slavic Natural Language Processing, ACL</li>
            </ul>

            <p><a id="Slovene-header"></a></p>
            <h3 id="slovene">Slovene</h3>
            <h4 id="datasets-of-slovene-and-croatian-moderated-news-comments-1">Datasets of Slovene and Croatian
                Moderated News Comments</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5116">https://www.aclweb.org/anthology/W18-5116</a>
                </li>
                <li>Link to data: <a href="http://hdl.handle.net/11356/1201">http://hdl.handle.net/11356/1201</a></li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 7,600,000</li>
                <li>Percentage abusive: 0.08</li>
                <li>Language: Slovene</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: MMC RTV website</li>
                <li>Medium: Text</li>
                <li>Reference: Ljubešić, N., Erjavec, T. and Fišer, D., 2018. Datasets of Slovene and Croatian Moderated
                    News Comments. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2). Brussels,
                    Belgium: Association for Computational Linguistics, pp.124-131.</li>
            </ul>

            <p><a id="Spanish-header"></a></p>
            <h3 id="spanish">Spanish</h3>
            <h4
                id="overview-of-mex-a3t-at-ibereval-2018-authorship-and-aggressiveness-analysis-in-mexican-spanish-tweets">
                Overview of MEX-A3T at IberEval 2018: Authorship and Aggressiveness Analysis in Mexican Spanish Tweets
            </h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2150/overview-mex-a3t.pdf">http://ceur-ws.org/Vol-2150/overview-mex-a3t.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://mexa3t.wixsite.com/home/aggressive-detection-track">https://mexa3t.wixsite.com/home/aggressive-detection-track</a>
                </li>
                <li>Task description: Binary (Aggressive, Not)</li>
                <li>Details of task: Group-directed</li>
                <li>Size of dataset: 11,000</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: Spanish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Alvarez-Carmona, M., Guzman-Falcon, E., Montes-y-Gomez, M., Escalante, H.,
                    Villasenor-Pineda, L., Reyes-Meza, V. and Rico-Sulayes, A., 2018. Overview of MEX-A3T at IberEval
                    2018: Authorship and aggressiveness analysis in Mexican Spanish tweets. In: Proceedings of the Third
                    Workshop on Evaluation of Human Language Technologies for Iberian Languages (IberEval 2018).</li>
            </ul>

            <h4 id="overview-of-the-task-on-automatic-misogyny-identification-at-ibereval-2018-spanish">Overview of the
                Task on Automatic Misogyny Identification at IberEval 2018 (Spanish)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2150/overview-AMI.pdf">http://ceur-ws.org/Vol-2150/overview-AMI.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://amiibereval2018.wordpress.com/important-dates/data/">https://amiibereval2018.wordpress.com/important-dates/data/</a>
                </li>
                <li>Task description: Binary (Misogyny, Not), 5 categories (Stereotype, Dominance, Derailing, Sexual
                    harassment, Discredit), Target of misogyny (Active or Passive)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 4,138</li>
                <li>Percentage abusive: 0.5</li>
                <li>Language: Spanish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fersini, E., Rosso, P. and Anzovino, M., 2018. Overview of the Task on Automatic Misogyny
                    Identification at IberEval 2018. In: Proceedings of the Third Workshop on Evaluation of Human
                    Language Technologies for Iberian Languages (IberEval 2018).</li>
            </ul>

            <h4
                id="hateval-semeval-2019-task-5-multilingual-detection-of-hate-speech-against-immigrants-and-women-in-twitter-spanish">
                hatEval, SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in
                Twitter (Spanish)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/S19-2007">https://www.aclweb.org/anthology/S19-2007</a>
                </li>
                <li>Link to data: <a
                        href="competitions.codalab.org/competitions/19935">competitions.codalab.org/competitions/19935</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),
                    Within Hate (Agressive, Not)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 6,600</li>
                <li>Percentage abusive: 0.4</li>
                <li>Language: Spanish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Pardo, F., Rosso, P. and
                    Sanguinetti, M., 2019. SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants
                    and Women in Twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation.
                    Minneapolis, Minnesota: Association for Computational Linguistics, pp.54-63.</li>
            </ul>

            <p><a id="Turkish-header"></a></p>
            <h3 id="turkish">Turkish</h3>
            <h4 id="a-corpus-of-turkish-offensive-language-on-social-media">A Corpus of Turkish Offensive Language on
                Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://coltekin.github.io/offensive-turkish/troff.pdf">https://coltekin.github.io/offensive-turkish/troff.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://sites.google.com/site/offensevalsharedtask/home">https://sites.google.com/site/offensevalsharedtask/home</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),
                    Within Hate (Agressive, Not)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 36232</li>
                <li>Percentage abusive: 0.19</li>
                <li>Language: Turkish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Çöltekin, C., 2020. A Corpus of Turkish Offensive Language on Social Media. In:
                    Proceedings of the 12th International Conference on Language Resources and Evaluation.</li>
                <li>Dataset reader: 🤗 <a
                        href="https://huggingface.co/datasets/strombergnlp/offenseval_2020">strombergnlp/offenseval_2020</a>
                </li>
            </ul>

            <p><a id="Ukranian-header"></a></p>
            <h3 id="ukranian">Ukranian</h3>
            <h4 id="detection-of-abusive-speech-for-mixed-sociolects-of-russian-and-ukrainian-languages-1">Detection of
                Abusive Speech for Mixed Sociolects of Russian and Ukrainian Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf">https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bohdan1/AbusiveLanguageDataset">https://github.com/bohdan1/AbusiveLanguageDataset</a>
                </li>
                <li>Task description: Binary (True == Abusive, False == Not)</li>
                <li>Details of task: Multilingual, Abusive Words, Political</li>
                <li>Size of dataset: 2,000</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Surzhyk (Russian &amp; Ukranian)</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Andrusyak, B., Rimel, M. and Kern, R., 2018. Detection of Abusive Speech for Mixed
                    Sociolects of Russian and Ukrainian Languages. In: Proceedings of Recent Advances in Slavonic
                    Natural Language Processing, RASLAN 2018, pp. 77–84, 2018.</li>
            </ul>

            <p><a id="Urdu-header"></a></p>
            <h3 id="urdu">Urdu</h3>
            <h4 id="hate-speech-and-offensive-language-detection-in-roman-urdu">Hate-Speech and Offensive Language
                Detection in Roman Urdu</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.emnlp-main.197/">https://www.aclweb.org/anthology/2020.emnlp-main.197/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/haroonshakeel/roman_urdu_hate_speech">https://github.com/haroonshakeel/roman_urdu_hate_speech</a>
                </li>
                <li>Task description: There are 2 subtasks, Coarse-grained Classification(Hate-Offensive vs Normal) and
                    Fine-grained classification( Abusive/Offensive, Sexism, Religious Hate, Profane, Normal)</li>
                <li>Details of task: Binary classification + Hate-Offensive label is further broken down into 4
                    fine-grained labels</li>
                <li>Size of dataset: 10041</li>
                <li>Percentage abusive: 0.24%</li>
                <li>Language: Urdu-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Hammad Rizwan, Muhammad Haroon Shakeel, and Asim Karim. 2020. Hate-speech and offensive
                    language detection in Roman Urdu. In Proceedings of the 2020 Conference on Empirical Methods in
                    Natural Language Processing (EMNLP), pages 2512–2522, Online. Association for Computational
                    Linguistics.</li>
            </ul>