            <p><a id="Albanian-header"></a></p>
            <h3 id="albanian">Albanian</h3>
            <h4 id="detecting-abusive-albanian">Detecting Abusive Albanian</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2107.13592">https://arxiv.org/abs/2107.13592</a>
                </li>
                <li>Link to data: <a
                        href="https://doi.org/10.6084/m9.figshare.19333298.v1">https://doi.org/10.6084/m9.figshare.19333298.v1</a>
                </li>
                <li>Task description: Hierarchical (offensive/not; untargeted/targeted; person/group/other)</li>
                <li>Details of task: Detect and categorise abusive language in social media data</li>
                <li>Size of dataset: 11 874</li>
                <li>Percentage abusive: 13.2%</li>
                <li>Language: Albanian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Instagram, Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Nurce, E., Keci, J., Derczynski, L., 2021. Detecting Abusive Albanian. arXiv:2107.13592
                </li>
                <li>Dataset reader: ü§ó <a href="https://huggingface.co/datasets/strombergnlp/shaj">strombergnlp/shaj</a>
                </li>
            </ul>

            <p><a id="Arabic-header"></a></p>
            <h3 id="arabic">Arabic</h3>
            <h4 id="are-they-our-brothers-analysis-and-detection-of-religious-hate-speech-in-the-arabic-twittersphere">
                Are They our Brothers? Analysis and Detection of Religious Hate Speech in the Arabic Twittersphere</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://ieeexplore.ieee.org/document/8508247">https://ieeexplore.ieee.org/document/8508247</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/nuhaalbadi/Arabic_hatespeech">https://github.com/nuhaalbadi/Arabic_hatespeech</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Religious subcategories</li>
                <li>Size of dataset: 6,136</li>
                <li>Percentage abusive: 0.45</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Albadi, N., Kurdi, M. and Mishra, S., 2018. Are they Our Brothers? Analysis and Detection
                    of Religious Hate Speech in the Arabic Twittersphere. In: International Conference on Advances in
                    Social Networks Analysis and Mining. Barcelona, Spain: IEEE, pp.69-76.</li>
            </ul>

            <h4 id="multilingual-and-multi-aspect-hate-speech-analysis-arabic">Multilingual and Multi-Aspect Hate Speech
                Analysis (Arabic)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1908.11049">https://arxiv.org/abs/1908.11049</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HKUST-KnowComp/MLMA_hate_speech">https://github.com/HKUST-KnowComp/MLMA_hate_speech</a>
                </li>
                <li>Task description: Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target
                    Attribute, Target Group, How annotators felt on seeing the tweet.</li>
                <li>Details of task: Gender, Sexual orientation, Religion, Disability</li>
                <li>Size of dataset: 3,353</li>
                <li>Percentage abusive: 0.64</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and
                    Multi-Aspect Hate Speech Analysis. ArXiv,.</li>
            </ul>

            <h4 id="l-hsab-a-levantine-twitter-dataset-for-hate-speech-and-abusive-language">L-HSAB: A Levantine Twitter
                Dataset for Hate Speech and Abusive Language</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W19-3512">https://www.aclweb.org/anthology/W19-3512</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/Hala-Mulki/L-HSAB-First-Arabic-Levantine-HateSpeech-Dataset">https://github.com/Hala-Mulki/L-HSAB-First-Arabic-Levantine-HateSpeech-Dataset</a>
                </li>
                <li>Task description: Ternary (Hate, Abusive, Normal)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 5,846</li>
                <li>Percentage abusive: 0.38</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Mulki, H., Haddad, H., Bechikh, C. and Alshabani, H., 2019. L-HSAB: A Levantine Twitter
                    Dataset for Hate Speech and Abusive Language. In: Proceedings of the Third Workshop on Abusive
                    Language Online. Florence, Italy: Association for Computational Linguistics, pp.111-118.</li>
            </ul>

            <h4 id="abusive-language-detection-on-arabic-social-media-twitter">Abusive Language Detection on Arabic
                Social Media (Twitter)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W17-3008">https://www.aclweb.org/anthology/W17-3008</a>
                </li>
                <li>Link to data: <a
                        href="http://alt.qcri.org/~hmubarak/offensive/TweetClassification-Summary.xlsx">http://alt.qcri.org/~hmubarak/offensive/TweetClassification-Summary.xlsx</a>
                </li>
                <li>Task description: Ternary (Obscene, Offensive but not obscene, Clean)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 1,100</li>
                <li>Percentage abusive: 0.59</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Mubarak, H., Darwish, K. and Magdy, W., 2017. Abusive Language Detection on Arabic Social
                    Media. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver, Canada:
                    Association for Computational Linguistics, pp.52-56.</li>
                <li>Dataset reader: ü§ó <a
                        href="https://huggingface.co/datasets/strombergnlp/offenseval_2020">strombergnlp/offenseval_2020</a>
                </li>
            </ul>

            <h4 id="abusive-language-detection-on-arabic-social-media-al-jazeera">Abusive Language Detection on Arabic
                Social Media (Al Jazeera)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W17-3008">https://www.aclweb.org/anthology/W17-3008</a>
                </li>
                <li>Link to data: <a
                        href="http://alt.qcri.org/~hmubarak/offensive/AJCommentsClassification-CF.xlsx">http://alt.qcri.org/~hmubarak/offensive/AJCommentsClassification-CF.xlsx</a>
                </li>
                <li>Task description: Ternary (Obscene, Offensive but not obscene, Clean)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 32,000</li>
                <li>Percentage abusive: 0.81</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: AlJazeera</li>
                <li>Medium: Text</li>
                <li>Reference: Mubarak, H., Darwish, K. and Magdy, W., 2017. Abusive Language Detection on Arabic Social
                    Media. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver, Canada:
                    Association for Computational Linguistics, pp.52-56.</li>
            </ul>

            <h4 id="dataset-construction-for-the-detection-of-anti-social-behaviour-in-online-communication-in-arabic">
                Dataset Construction for the Detection of Anti-Social Behaviour in Online Communication in Arabic</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.sciencedirect.com/science/article/pii/S1877050918321756">https://www.sciencedirect.com/science/article/pii/S1877050918321756</a>
                </li>
                <li>Link to data: <a
                        href="https://onedrive.live.com/?authkey=!ACDXj_ZNcZPqzy0&amp;id=6EF6951FBF8217F9!105&amp;cid=6EF6951FBF8217F9">https://onedrive.live.com/?authkey=!ACDXj_ZNcZPqzy0&amp;id=6EF6951FBF8217F9!105&amp;cid=6EF6951FBF8217F9</a>
                </li>
                <li>Task description: Binary (Offensive, Not)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 15,050</li>
                <li>Percentage abusive: 0.39</li>
                <li>Language: Arabic</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: YouTube</li>
                <li>Medium: Text</li>
                <li>Reference: Alakrot, A., Murray, L. and Nikolov, N., 2018. Dataset Construction for the Detection of
                    Anti-Social Behaviour in Online Communication in Arabic. Procedia Computer Science, 142, pp.174-181.
                </li>
            </ul>

            <p><a id="Bengali-header"></a></p>
            <h3 id="bengali">Bengali</h3>
            <h4 id="hate-speech-detection-in-the-bengali-language-a-dataset-and-its-baseline-evaluation">Hate Speech
                Detection in the Bengali language: A Dataset and its Baseline Evaluation</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2012.09686.pdf">https://arxiv.org/pdf/2012.09686.pdf</a></li>
                <li>Link to data: <a
                        href="https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset">https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset</a>
                </li>
                <li>Task description: Binary (hateful, not)</li>
                <li>Details of task: Several categories: sports, entertainment, crime, religion, politics, celebrity and
                    meme</li>
                <li>Size of dataset: 30,000</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Bengali</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Romim, N., Ahmed, M., Talukder, H., &amp; Islam, M. S. (2021). Hate speech detection in
                    the bengali language: A dataset and its baseline evaluation. In Proceedings of International Joint
                    Conference on Advances in Computational Intelligence (pp. 457-468). Springer, Singapore.</li>
            </ul>

            <p><a id="Chinese-header"></a></p>
            <h3 id="chinese">Chinese</h3>
            <h4 id="swsr-a-chinese-dataset-and-lexicon-for-online-sexism-detection">SWSR: A Chinese Dataset and Lexicon
                for Online Sexism Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.sciencedirect.com/science/article/abs/pii/S2468696421000604#fn1">https://www.sciencedirect.com/science/article/abs/pii/S2468696421000604#fn1</a>
                </li>
                <li>Link to data: <a
                        href="https://doi.org/10.5281/zenodo.4773875">https://doi.org/10.5281/zenodo.4773875</a></li>
                <li>Task description: Binary (Sexist, Non-sexist), Categories of sexism (Stereotype based on Appearance,
                    Stereotype based on Cultural Background, MicroAggression, and Sexual Offense), Target of sexism
                    (Individual or Generic)</li>
                <li>Details of task: Sexism detection on social media in Chinese</li>
                <li>Size of dataset: 8,969 comments from 1,527 weibos</li>
                <li>Percentage abusive: 34.5%</li>
                <li>Language: Chinese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Sina Weibo</li>
                <li>Medium: Text</li>
                <li>Reference: Aiqi Jiang, Xiaohan Yang, Yang Liu, Arkaitz Zubiaga, SWSR: A Chinese dataset and lexicon
                    for online sexism detection, Online Social Networks and Media, Volume 27, 2022, 100182, ISSN
                    2468-6964.</li>
            </ul>

            <p><a id="Croatian-header"></a></p>
            <h3 id="croatian">Croatian</h3>
            <h4 id="datasets-of-slovene-and-croatian-moderated-news-comments">Datasets of Slovene and Croatian Moderated
                News Comments</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5116">https://www.aclweb.org/anthology/W18-5116</a>
                </li>
                <li>Link to data: <a href="http://hdl.handle.net/11356/1202">http://hdl.handle.net/11356/1202</a></li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 17,000,000</li>
                <li>Percentage abusive: 0.02</li>
                <li>Language: Croatian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: 24sata website</li>
                <li>Medium: Text</li>
                <li>Reference: Ljube≈°iƒá, N., Erjavec, T. and Fi≈°er, D., 2018. Datasets of Slovene and Croatian Moderated
                    News Comments. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2). Brussels,
                    Belgium: Association for Computational Linguistics, pp.124-131.</li>
            </ul>

            <h4 id="automating-news-comment-moderation-with-limited-resources-benchmarking-in-croatian-and-estonian">
                Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf">https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://www.clarin.si/repository/xmlui/handle/11356/1399">https://www.clarin.si/repository/xmlui/handle/11356/1399</a>
                </li>
                <li>Task description: Multi-class based on Different rules</li>
                <li>Details of task: Flagged content performmed by the real newspaper moderators</li>
                <li>Size of dataset: 21M</li>
                <li>Percentage abusive: 7.8%</li>
                <li>Language: Croatian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Newspaper comments</li>
                <li>Medium: Text</li>
                <li>Reference: Ravi Shekhar, Marko Pranjiƒá, Senja Pollak, Andra≈æ Pelicon, Matthew Purver (2020).
                    Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian.
                    Journal for Language Technology and Computational Linguistics (JLCL).</li>
            </ul>

            <p><a id="Danish-header"></a></p>
            <h3 id="danish">Danish</h3>
            <h4 id="offensive-language-and-hate-speech-detection-for-danish">Offensive Language and Hate Speech
                Detection for Danish</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.derczynski.com/papers/danish_hsd.pdf">http://www.derczynski.com/papers/danish_hsd.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://sites.google.com/site/offensevalsharedtask/home">https://figshare.com/articles/Danish_Hate_Speech_Abusive_Language_data/12220805</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,
                    Not), Within Target (Individual, Group, Other)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 3,600</li>
                <li>Percentage abusive: 0.12</li>
                <li>Language: Danish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter, Reddit, newspaper comments</li>
                <li>Medium: Text</li>
                <li>Reference: Sigurbergsson, G. and Derczynski, L., 2019. Offensive Language and Hate Speech Detection
                    for Danish. ArXiv.</li>
                <li>Dataset reader: ü§ó <a href="https://huggingface.co/datasets/DDSC/dkhate">DDSC/dkhate</a></li>
            </ul>

            <h4 id="bajer-misogyny-in-danish">BAJER: Misogyny in Danish</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.acl-long.247/">https://aclanthology.org/2021.acl-long.247/</a>
                </li>
                <li>Link to data: <a
                        href="https://docs.google.com/forms/d/e/1FAIpQLSfUKb7ZTKd01syaNkAW5GDfCSkaVsJlom06g_mJdWUkUikVHA/viewform">request
                        here</a></li>
                <li>Task description: Hierarchy of abusive content labels including subcategories of misogyny</li>
                <li>Details of task: ‚ÄúMisogyny detection on social media in Danish‚Äù</li>
                <li>Size of dataset: 27.9K comments</li>
                <li>Percentage abusive: 7% misogynistic, 27% abusive (i.e. 20% abusive but not misogyny)</li>
                <li>Language: Danish</li>
                <li>Level of annotation: Social media post / comment</li>
                <li>Platform: Twitter, Facebook, Reddit</li>
                <li>Medium: text</li>
                <li>Reference: Zeinert, Inie, &amp; Derczynski, 2021. ‚ÄúAnnotating Online Misogyny‚Äù. Proceedings of the
                    59th Annual Meeting of the Association for Computational Linguistics and the 11th International
                    Joint Conference on Natural Language Processing, ACL</li>
                <li>Dataset reader: ü§ó <a
                        href="https://huggingface.co/datasets/strombergnlp/bajer_danish_misogyny">strombergnlp/bajer_danish_misogyny</a>
                </li>
            </ul>

            <p><a id="Dutch-header"></a></p>
            <h3 id="dutch">Dutch</h3>
            <h4 id="the-dutch-abusive-language-corpus-v10-dalc-v10">The Dutch Abusive Language Corpus v1.0 (DALC v1.0)
            </h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.woah-1.6.pdf">https://aclanthology.org/2021.woah-1.6.pdf</a>
                    - link to the documentation and/or a data statement about the data</li>
                <li>Link to data: <a href="https://github.com/tommasoc80/DALC">https://github.com/tommasoc80/DALC</a>
                </li>
                <li>Task description: Multilayered (explicitness and target) for abusive language</li>
                <li>Details of task: Abusive language detection in social media in Dutch</li>
                <li>Size of dataset: 8,156 tweets</li>
                <li>Percentage abusive: 15.06% explicitly abusive; 8.09% implicitly abusive</li>
                <li>Language: Dutch</li>
                <li>Level of annotation: tweets</li>
                <li>Platform: Twitter</li>
                <li>Medium: text</li>
                <li>Reference: Caselli, T., Schelhaas, A., Weultjes, M., Leistra, F., van der Veen, H., Timmerman, G.,
                    and Nissim, M. 2021. ‚ÄúDALC: the Dutch Abusive Language Corpus‚Äù. Proceedings of the 5th Workshop on
                    Online Abuse and Harms (WOAH 2021), ACL.</li>
            </ul>

            <p><a id="English-header"></a></p>
            <h3 id="english">English</h3>

            <h4 id="convabuse">ConvAbuse</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.emnlp-main.587/">https://aclanthology.org/2021.emnlp-main.587/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/amandacurry/convabuse">https://github.com/amandacurry/convabuse</a>
                </li>
                <li>Task description: Hierarchical: 1. <em>Abuse binary</em>, <em>Abuse severity</em> 1,0,-1,-2,-3; 2.
                    <em>Directedness</em> explicit, implicit <em>Target</em> group, individual‚Äìsystem,
                    individual‚Äì3rd party, <em>Type</em> general, sexist, sexual harassment, homophobic, racist,
                    transphobic, ableist,
                    intellectual</li>
                <li>Details of task: Abuse detection in conversational AI</li>
                <li>Size of dataset: 4,185</li>
                <li>Percentage abusive: c. 20%</li>
                <li>Language: English</li>
                <li>Level of annotation: utterance (with conversational context)</li>
                <li>Platform: Carbonbot on Facebook Messenger and E.L.I.Z.A. chatbots</li>
                <li>Medium: text</li>
                <li>Reference: Curry, A. C., Abercrombie, G., &amp; Rieser, V. 2021. ConvAbuse: Data, Analysis, and
                    Benchmarks for Nuanced Detection in Conversational AI. In Proceedings of the 2021 Conference on
                    Empirical Methods in Natural Language Processing (pp. 7388-7403).</li>
            </ul>

            <h4 id="measuring-hate-speech">Measuring Hate Speech</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2009.10277">https://arxiv.org/abs/2009.10277</a>
                </li>
                <li>Link to data: <a
                        href="https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech">https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech</a>
                </li>
                <li>Task description: 10 ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status,
                    violence, dehumanization, genocide, attack/defense, hate speech), which are debiased and aggregated
                    into a continuous hate speech severity score (hate_speech_score) that includes a region for
                    counterspeech &amp; supportive speeech. Includes 8 target identity groups (race/ethnicity, religion,
                    national origin/citizenship, gender, sexual orientation, age, disability, political ideology) and 42
                    identity subgroups.</li>
                <li>Details of task: Hate speech measurement on social media in English</li>
                <li>Size of dataset: 39,565 comments annotated by 7,912 annotators on 10 ordinal labels, for 1,355,560
                    total labels.</li>
                <li>Percentage abusive: 25% - however this dichotomization is not in the spirit of the paper/dataset
                </li>
                <li>Language: English</li>
                <li>Level of annotation: Social media comment</li>
                <li>Platform: Twitter, Reddit, YouTube</li>
                <li>Medium: Text</li>
                <li>Reference: Kennedy, C. J., Bacon, G., Sahn, A., &amp; von Vacano, C. (2020). Constructing interval
                    variables via faceted Rasch measurement and multitask deep learning: a hate speech application.
                    arXiv preprint arXiv:2009.10277.</li>
            </ul>

            <h4 id="learning-from-the-worst-dynamically-generated-hate-speech-dataset">Learning From the Worst
                (Dynamically generated hate speech dataset)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.acl-long.132/">https://aclanthology.org/2021.acl-long.132/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset">https://github.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset</a>
                </li>
                <li>Task description: Multi-category hate speech detection</li>
                <li>Details of task: Hate detection with fine-grained labels for the type and target of hate. Generated
                    over 4 rounds of human-and-model-in-the-loop adversarial data generation. Collected through <a
                        href="https://dynabench.org/tasks/5#overall">Dynabench</a>.</li>
                <li>Size of dataset: 41,255</li>
                <li>Percentage abusive: 54%</li>
                <li>Language: English</li>
                <li>Level of annotation: posts</li>
                <li>Platform: Synthetically generated by humans to mimic real-world social media posts</li>
                <li>Medium: text</li>
                <li>Reference: Vidgen, B., Thurush, T., Waseem, Z., Kiela, D., 2021. Learning from the worst:
                    dynamically generated datasets to improve online hate detection. In Proceedings of the 59th Meeting
                    of the Association for Computational Lingusitics (pp. 1667-1682).</li>
            </ul>

            <h4 id="the-call-me-sexist-but-sexism-dataset">The ‚ÄòCall me sexist, but‚Äô sexism dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://ojs.aaai.org/index.php/ICWSM/article/view/18085/17888">https://ojs.aaai.org/index.php/ICWSM/article/view/18085/17888</a>
                </li>
                <li>Link to data: <a href="https://doi.org/10.7802/2251">https://doi.org/10.7802/2251</a></li>
                <li>Task description: Sexism detection based on content and phrasing</li>
                <li>Details of task: Sexism detection on English social media data informed by survey items measuring
                    sexist attitudes and adversarial examples</li>
                <li>Size of dataset: 6325</li>
                <li>Percentage abusive: 28%</li>
                <li>Language: English</li>
                <li>Level of annotation: tweets and survey items</li>
                <li>Platform: Twitter, Social Psychology scales</li>
                <li>Medium: text</li>
                <li>Reference: Samory, M., Sen, I., Kohne, J., Fl√∂ck, F. and Wagner, C., 2021, May. Call me sexist,
                    but‚Ä¶: Revisiting sexism detection using psychological scales and adversarial samples. In Intl AAAI
                    Conf. Web and Social Media (pp. 573-584).</li>
            </ul>

            <h4
                id="hate-towards-the-political-opponent-a-twitter-corpus-study-of-the-2020-us-elections-on-the-basis-of-offensive-speech-and-stance-detection__">
                Hate Towards the Political Opponent: A Twitter Corpus Study of the 2020 US Elections on the Basis of
                Offensive Speech and Stance Detection__</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.wassa-1.18/">https://aclanthology.org/2021.wassa-1.18/</a>
                </li>
                <li>Link to data: <a
                        href="https://www.ims.uni-stuttgart.de/data/stance_hof_us2020">https://www.ims.uni-stuttgart.de/data/stance_hof_us2020</a>
                </li>
                <li>Task description: Hate / Offensive or neither</li>
                <li>Details of task: Data collected to be Twitter by supporters of Trump
                    or Biden</li>
                <li>Size of dataset: 3,000</li>
                <li>Percentage abusive: 12%</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Lara Grimminger and Roman Klinger (2020): Hate Towards the Political Opponent: A Twitter
                    Corpus Study of the 2020 US Elections on the Basis of Offensive Speech and Stance Detection. 11th
                    Workshop on Computational Approaches to Subjectivity, Sentiment &amp; Social Media Analysis
                    (collocated with EACL 2021).</li>
            </ul>

            <h4 id="abuseeval-v10">AbuseEval v1.0</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.760.pdf">http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.760.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/tommasoc80/AbuseEval">https://github.com/tommasoc80/AbuseEval</a></li>
                <li>Task description: Explicitness annotation of offensive and abusive content</li>
                <li>Details of task: Enriched versions of the OffensEval/OLID dataset with the distinction of
                    explicit/implicit offensive messages and the new dimension for abusive messages. Labels for
                    offensive language: EXPLICIT, IMPLICT, NOT; Labels for abusive language: EXPLICIT, IMPLICT, NOTABU
                </li>
                <li>Size of dataset: 14,100</li>
                <li>Percentage abusive: 20.75%</li>
                <li>Language: English</li>
                <li>Level of annotation: tweets</li>
                <li>Platform: Twitter</li>
                <li>Medium: text</li>
                <li>Reference: Caselli, T., Basile, V., Jelena, M., Inga, K., and Michael, G. 2020. ‚ÄúI feel offended,
                    don‚Äôt be abusive! implicit/explicit messages in offensive and abusive language‚Äù. The 12th Language
                    Resources and Evaluation Conference (pp. 6193-6202). European Language Resources Association.</li>
            </ul>

            <h4 id="do-you-really-want-to-hurt-me-predicting-abusive-swearing-in-social-media">Do You Really Want to
                Hurt Me? Predicting Abusive Swearing in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.lrec-1.765.pdf">https://www.aclweb.org/anthology/2020.lrec-1.765.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/dadangewp/SWAD-Repository">https://github.com/dadangewp/SWAD-Repository</a>
                </li>
                <li>Task description: Binary (abusive swear word, non-abusive swear word)</li>
                <li>Details of task: Abusive swearing</li>
                <li>Size of dataset: 1,511 swear words (1675 tweets)</li>
                <li>Percentage abusive: 0.41% (word level), 0.51% (post level)</li>
                <li>Language: English</li>
                <li>Level of annotation: Words</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Pamungkas, E. W., Basile, V., &amp; Patti, V. (2020). Do you really want to hurt me?
                    predicting abusive swearing in social media. In The 12th Language Resources and Evaluation
                    Conference (pp. 6237-6246). European Language Resources Association.</li>
            </ul>

            <h4 id="multimodal-meme-dataset-multioff-for-identifying-offensive-content-in-image-and-text">Multimodal
                Meme Dataset (MultiOFF) for Identifying Offensive Content in Image and Text</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.trac-1.6.pdf">https://www.aclweb.org/anthology/2020.trac-1.6.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text">https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text</a>
                </li>
                <li>Task description: Binary (offensive, non-offensive)</li>
                <li>Details of task: Hate per se (related to 2016 U.S. presidential election)</li>
                <li>Size of dataset: 743</li>
                <li>Percentage abusive: 0.41%</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Kaggle, Reddit, Facebook, Twitter and Instagram</li>
                <li>Medium: Text and Images/memes</li>
                <li>Reference: Suryawanshi, S., Chakravarthi, B. R., Arcan, M., &amp; Buitelaar, P. (2020, May).
                    Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text. In
                    Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying (pp. 32-41).</li>
            </ul>

            <h4
                id="hatemoji-a-test-suite-and-adversarially-generated-dataset-for-benchmarking-and-detecting-emoji-based-hate">
                Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based
                Hate</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2108.05921">https://arxiv.org/abs/2108.05921</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HannahKirk/Hatemoji">https://github.com/HannahKirk/Hatemoji</a></li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not Hate), Within Hate (Type, Target)
                </li>
                <li>Details of task: Hate speech detection for text statements including emoji, consisting of a
                    checklist-based test suite (HatemojiCheck) and an adversarially-generated dataset (HatemojiBuild)
                </li>
                <li>Size of dataset: HatemojiCheck = 3,930; HatemojiBuild = 5,912.</li>
                <li>Percentage abusive: HatemojiCheck = 69%, HatemojiBuild = 50%</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Synthetically-Generated</li>
                <li>Medium: Text with emoji</li>
                <li>Reference: Kirk, H. R., Vidgen, B., R√∂ttger, P., Thrush, T., &amp; Hale, S. A. 2021. Hatemoji: A
                    test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate.
                    arXiv preprint arXiv:2108.05921.</li>
            </ul>

            <h4 id="hatecheck-functional-tests-for-hate-speech-detection-models">HateCheck: Functional Tests for Hate
                Speech Detection Models</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2012.15606.pdf">https://arxiv.org/pdf/2012.15606.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/paul-rottger/hatecheck-data">https://github.com/paul-rottger/hatecheck-data</a>
                </li>
                <li>Task description: Binary (Hate, Not Hate), 7 Targets Within Hate (Women, Trans people, Black people,
                    Gay people, Disabled people, Muslims, Immigrants)</li>
                <li>Details of task: A checklist of functional tests to evaluate hate speech detection models.</li>
                <li>Size of dataset: 3,728</li>
                <li>Percentage abusive: 68%</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Synthetically-Generated</li>
                <li>Medium: Text</li>
                <li>Reference: R√∂ttger, P., Vidgen, B., Nguyen, D., Waseem, Z., Margetts, H. and Pierrehumbert, J.,
                    2020. Hatecheck: Functional tests for hate speech detection models. arXiv preprint arXiv:2012.15606.
                </li>
            </ul>

            <h4 id="semeval-2021-task-5-toxic-spans-detection">Semeval-2021 Task 5: Toxic Spans Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.semeval-1.6.pdf">https://aclanthology.org/2021.semeval-1.6.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ipavlopoulos/toxic_spans">https://github.com/ipavlopoulos/toxic_spans</a>
                </li>
                <li>Task description: Binary toxic spans (toxic, non-toxic) &amp; reading comprehension</li>
                <li>Details of task: Predict the spans of toxic posts that were responsible for the toxic label of the
                    posts.</li>
                <li>Size of dataset: 10,629</li>
                <li>Percentage abusive: 0.56</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Civil Comments</li>
                <li>Medium: Text</li>
                <li>Reference: Pavlopoulos, J., Sorensen, J., Laugier, L., &amp; Androutsopoulos, I. (2021, August).
                    Semeval-2021 task 5: Toxic spans detection. In Proceedings of the 15th International Workshop on
                    Semantic Evaluation (SemEval-2021) (pp. 59-69).</li>
            </ul>

            <h4
                id="human-in-the-loop-for-data-collection-a-multi-target-counter-narrative-dataset-to-fight-online-hate-speech">
                Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate
                Speech</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.acl-long.250.pdf">https://aclanthology.org/2021.acl-long.250.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (hateful, not)</li>
                <li>Details of task: race, religion, country of origin, sexual orientation, disability, gender</li>
                <li>Size of dataset: 5,003</li>
                <li>Percentage abusive: 1</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Semi-synthetic text</li>
                <li>Medium: Text</li>
                <li>Reference: Margherita Fanton, Helena Bonaldi, Serra Sinem Tekiroƒülu, Marco Guerini Human-in-the-Loop
                    for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech In
                    Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics: Long
                    Papers.</li>
            </ul>

            <h4 id="hatexplain-a-benchmark-dataset-for-explainable-hate-speech-detection">HateXplain: A Benchmark
                Dataset for Explainable Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/2012.10289">https://arxiv.org/abs/2012.10289</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/punyajoy/HateXplain">https://github.com/punyajoy/HateXplain</a></li>
                <li>Task description: Level of hate (hate, offensive or normal), on target groups (race, religion,
                    gender, sexual orientation, miscellaneous), and rationales</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 20,148</li>
                <li>Percentage abusive: 0.57</li>
                <li>Language: English</li>
                <li>Level of annotation: Words, phrases, posts</li>
                <li>Platform: Twitter and Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Mathew, B., Saha, P., Yimam, S. M., Biemann, C., Goyal, P., &amp; Mukherjee, A. (2021,
                    May). HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection. In Proceedings of the
                    AAAI Conference on Artificial Intelligence (Vol. 35, No. 17, pp. 14867-14875).</li>
            </ul>

            <h4 id="alone-a-dataset-for-toxic-behavior-among-adolescents-on-twitter">ALONE: A Dataset for Toxic Behavior
                among Adolescents on Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2008.06465.pdf">https://arxiv.org/pdf/2008.06465.pdf</a></li>
                <li>Link to data: Data made available upon request, please email Ugur Kursuncu ugur@gsu.edu and
                    thilini@sc.edu thilini@sc.edu.</li>
                <li>Task description: Binary (Toxic, Non-Toxic)</li>
                <li>Details of task: Annotates interactions (Tweets and their replies), and assigns keywords describing
                    use of emojis, URL content and images.</li>
                <li>Size of dataset: 688</li>
                <li>Percentage abusive: 0.17</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Twitter</li>
                <li>Medium: Multimodal (text, images, emojis, metadata)</li>
                <li>Reference: Wijesiriwardene, T., Inan, H., Kursuncu, U., Gaur, M., Shalin, V., Thirunarayan, K.,
                    Sheth, A. and Arpinar, I., 2020, Arxiv.</li>
            </ul>

            <h4 id="towards-a-comprehensive-taxonomy-and-large-scale-annotated-corpus-for-online-slur-usage">Towards a
                Comprehensive Taxonomy and Large-Scale Annotated Corpus for Online Slur Usage</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.alw-1.17.pdf">https://www.aclweb.org/anthology/2020.alw-1.17.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/networkdynamics/slur-corpus">https://github.com/networkdynamics/slur-corpus</a>
                </li>
                <li>Task description: 4 primary categories (derogatory, appropriate, non-derogatory/non-appropriate,
                    homonyms, noise)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 39,811</li>
                <li>Percentage abusive: 0.52</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Kurrek, J., Saleem, H. M., &amp; Ruths, D. (2020, November). Towards a comprehensive
                    taxonomy and large-scale annotated corpus for online slur usage. In Proceedings of the Fourth
                    Workshop on Online Abuse and Harms (pp. 138-149).</li>
            </ul>

            <h4 id="multimodal-meme-dataset-multioff-for-identifying-offensive-content-in-image-and-text-1">Multimodal
                Meme Dataset (MultiOFF) for Identifying Offensive Content in Image and Text</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.trac-1.6.pdf">https://www.aclweb.org/anthology/2020.trac-1.6.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://www.aclweb.org/anthology/2020.trac-1.6.pdf">https://www.aclweb.org/anthology/2020.trac-1.6.pdf</a>
                </li>
                <li>Task description: Binary (offensive, non-offensive)</li>
                <li>Details of task: Hate per se (related to 2016 U.S. presidential election)</li>
                <li>Size of dataset: 743</li>
                <li>Percentage abusive: 0.41</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Kaggle, Reddit, Facebook, Twitter and Instagram</li>
                <li>Medium: Text and Images/memes</li>
                <li>Reference: Suryawanshi, S., Chakravarthi, B. R., Arcan, M., &amp; Buitelaar, P. (2020, May).
                    Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text. In
                    Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying (pp. 32-41).</li>
            </ul>

            <h4 id="predicting-the-type-and-target-of-offensive-posts-in-social-media">Predicting the Type and Target of
                Offensive Posts in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/N19-1144.pdf">https://aclanthology.org/N19-1144.pdf</a></li>
                <li>Link to data: <a
                        href="https://scholar.harvard.edu/malmasi/olid">https://scholar.harvard.edu/malmasi/olid</a>
                </li>
                <li>Task description: Branching structure of tasks. A: offensive / not, B: targeted insult / untargeted,
                    C: individual, group, other.</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 14,100</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., &amp; Kumar, R. (2019,
                    June). Predicting the Type and Target of Offensive Posts in Social Media. In Proceedings of the 2019
                    Conference of the North American Chapter of the Association for Computational Linguistics: Human
                    Language Technologies, Volume 1 (Long and Short Papers) (pp. 1415-1420).</li>
            </ul>

            <h4 id="nuanced-metrics-for-measuring-unintended-bias-with-real-data-for-text-classification">Nuanced
                metrics for measuring unintended bias with real data for text classification</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1903.04561.pdf">https://arxiv.org/pdf/1903.04561.pdf</a></li>
                <li>Link to data: <a
                        href="https://www.tensorflow.org/datasets/catalog/civil_comments">https://www.tensorflow.org/datasets/catalog/civil_comments</a>
                </li>
                <li>Task description: Toxicity (severe, obscene, threat, insult, identity attack, sexual explicit), and
                    several identity attributes (e.g., gender, religion and race)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 1,804,875</li>
                <li>Percentage abusive: 0.8</li>
                <li>Language: English</li>
                <li>Level of annotation: Comments/posts</li>
                <li>Platform: Civil Comments</li>
                <li>Medium: Text</li>
                <li>Reference: Borkan, D., Dixon, L., Sorensen, J., Thain, N., &amp; Vasserman, L. (2019, May). Nuanced
                    metrics for measuring unintended bias with real data for text classification. In Companion
                    proceedings of the 2019 world wide web conference (pp. 491-500).</li>
            </ul>

            <h4 id="introducing-cad-the-contextual-abuse-dataset">Introducing CAD: the Contextual Abuse Dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.naacl-main.182.pdf">https://aclanthology.org/2021.naacl-main.182.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://zenodo.org/record/4881008#.Ye6OwhP7R6o">https://zenodo.org/record/4881008#.Ye6OwhP7R6o</a>
                </li>
                <li>Task description: Contextually abusive language, person-directed + group-directed</li>
                <li>Details of task: Primary categories (secondary categories): Abusive + Identity-directed
                    (derogation/animosity/threatening/glorification/dehumanization), Abusive + Person-directed
                    (derogation/animosity/threatening/glorification/dehumanization), Abusive + Affiliation directed
                    (abuse to them/abuse about them), Counter Speech (against identity-directed abuse/against
                    affiliation-directed abuse/against person-directed abuse), Non-hateful Slurs and Neutral.</li>
                <li>Size of dataset: 25,000</li>
                <li>Percentage abusive: Affiliation-directed, 6%; Identity-directed, 13%; Person-directed, 5%</li>
                <li>Language: English</li>
                <li>Level of annotation: Conversation thread</li>
                <li>Platform: Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Vidgen, B., Nguyen, D., Margetts, H., Rossini, P., and Troble, R., Introducing CAD: the
                    Contextual Abuse Dataset, 2021, In: Proceedings of the 2021 Conference of the North American Chapter
                    of the Association for Computational Linguistics: Human Language Technologies, pp.2289‚Äì2303</li>
            </ul>

            <h4 id="automated-hate-speech-detection-and-the-problem-of-offensive-language">Automated Hate Speech
                Detection and the Problem of Offensive Language</h4>
            <ul>
                <li>Link to publication: [https://ojs.aaai.org/index.php/ICWSM/article/view/14955)</li>
                <li>Link to data: <a
                        href="https://github.com/t-davidson/hate-speech-and-offensive-language">https://github.com/t-davidson/hate-speech-and-offensive-language</a>
                </li>
                <li>Task description: Hierarchy (Hate, Offensive, Neither)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 24,802</li>
                <li>Percentage abusive: 0.06</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Davidson, T., Warmsley, D., Macy, M., &amp; Weber, I. 2017. Automated Hate Speech
                    Detection and the Problem of Offensive Language. Proceedings of the International AAAI Conference on
                    Web and Social Media, 11(1), 512-515.</li>
            </ul>

            <h4 id="hate-speech-dataset-from-a-white-supremacy-forum">Hate Speech Dataset from a White Supremacy Forum
            </h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5102.pdf">https://www.aclweb.org/anthology/W18-5102.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/Vicomtech/hate-speech-dataset">https://github.com/Vicomtech/hate-speech-dataset</a>
                </li>
                <li>Task description: Ternary (Hate, Relation, Not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 9,916</li>
                <li>Percentage abusive: 0.11</li>
                <li>Language: English</li>
                <li>Level of annotation: Sentence - with context of the converstaional thread taken into account</li>
                <li>Platform: Stormfront</li>
                <li>Medium: Text</li>
                <li>Reference: de Gibert, O., Perez, N., Garc√≠a-Pablos, A., and Cuadros, M., 2018. Hate Speech Dataset
                    from a White Supremacy Forum. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2).
                    Brussels, Belgium: Association for Computational Linguistics, pp.11-20.</li>
            </ul>

            <h4 id="hateful-symbols-or-hateful-people-predictive-features-for-hate-speech-detection-on-twitter">Hateful
                Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/N16-2013">https://www.aclweb.org/anthology/N16-2013</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ZeerakW/hatespeech">https://github.com/ZeerakW/hatespeech</a></li>
                <li>Task description: 3-topic (Sexist, Racist, Not)</li>
                <li>Details of task: Racism, Sexism</li>
                <li>Size of dataset: 16,914</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Waseem, Z. and Horvy, D., 2016. Hateful Symbols or Hateful People? Predictive Features
                    for Hate Speech Detection on Twitter. In: Proceedings of the NAACL Student Research Workshop. San
                    Diego, California: Association for Computational Linguistics, pp.88-93.</li>
            </ul>

            <h4 id="detecting-online-hate-speech-using-context-aware-models">Detecting Online Hate Speech Using Context
                Aware Models</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1710.07395.pdf">https://arxiv.org/pdf/1710.07395.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/sjtuprog/fox-news-comments">https://github.com/sjtuprog/fox-news-comments</a>
                </li>
                <li>Task description: Binary (Hate / not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 1528</li>
                <li>Percentage abusive: 0.28</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Fox News</li>
                <li>Medium: Text</li>
                <li>Reference: Gao, L. and Huang, R., 2018. Detecting Online Hate Speech Using Context Aware Models.
                    ArXiv,.</li>
            </ul>

            <h4 id="the-gab-hate-corpus-a-collection-of-27k-posts-annotated-for-hate-speech">The Gab Hate Corpus: A
                collection of 27k posts annotated for hate speech</h4>
            <ul>
                <li>Link to publication: <a href="https://psyarxiv.com/hqjxn/">https://psyarxiv.com/hqjxn/</a></li>
                <li>Link to data: <a href="https://osf.io/edua3/">https://osf.io/edua3/</a></li>
                <li>Task description: Binary (Hate vs. Offensive/Vulgarity), Binary (Assault on human Dignity/Call for
                    Violence ‚Äì sub task on message delivery, binary: explicit/implicit), Multinomial classification:
                    Identity based hate (race/ethnicity, nationality/regionalism/xenophobia, gender, religion/belief
                    system, sexual orientation, ideology, political identification/party, mental/physical health)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 27,665</li>
                <li>Percentage abusive: 0.09 Hate, 0.06 Offensive/Vulgar</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Kennedy, B., Araria, M., Mostafazadeh Davani, A., Yeh, L., Omrani, A., Kim, Y., Koombs,
                    K., Havaldar, S., Portillo-Wightman, G., Gonzalez, E., Hoover, J., Azatain, A., Hussain, A., Lara,
                    A., Olmos, G., Omary, A., Park, C., Wang, C., Wang, X., Zhang, Y. and Dehghani, M., 2018, The Gab
                    Hate Corpus: A collection of 27k posts annotated for hate speech. PsyArXiv.</li>
            </ul>

            <h4 id="are-you-a-racist-or-am-i-seeing-things-annotator-influence-on-hate-speech-detection-on-twitter">Are
                You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://pdfs.semanticscholar.org/3eeb/b7907a9b94f8d65f969f63b76ff5f643f6d3.pdf">https://pdfs.semanticscholar.org/3eeb/b7907a9b94f8d65f969f63b76ff5f643f6d3.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ZeerakW/hatespeech">https://github.com/ZeerakW/hatespeech</a></li>
                <li>Task description: Multi-topic (Sexist, Racist, Neither, Both)</li>
                <li>Details of task: Racism, Sexism</li>
                <li>Size of dataset: 4,033</li>
                <li>Percentage abusive: 0.16</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Waseem, Z., 2016. Are You a Racist or Am I Seeing Things? Annotator Influence on Hate
                    Speech Detection on Twitter. In: Proceedings of 2016 EMNLP Workshop on Natural Language Processing
                    and Computational Social Science. Copenhagen, Denmark: Association for Computational Linguistics,
                    pp.138-142.</li>
            </ul>

            <h4
                id="when-does-a-compliment-become-sexist-analysis-and-classification-of-ambivalent-sexism-using-twitter-data">
                When Does a Compliment Become Sexist? Analysis and Classification of Ambivalent Sexism Using Twitter
                Data</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://pdfs.semanticscholar.org/225f/f8a6a562bbb64b22cebfcd3288c6b930d1ef.pdf">https://pdfs.semanticscholar.org/225f/f8a6a562bbb64b22cebfcd3288c6b930d1ef.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/AkshitaJha/NLP_CSS_2017">https://github.com/AkshitaJha/NLP_CSS_2017</a>
                </li>
                <li>Task description: Hierarchy of Sexism (Benevolent sexism, Hostile sexism, None)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 712</li>
                <li>Percentage abusive: 1</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Jha, A. and Mamidi, R., 2017. When does a Compliment become Sexist? Analysis and
                    Classification of Ambivalent Sexism using Twitter Data. In: Proceedings of the Second Workshop on
                    Natural Language Processing and Computational Social Science. Vancouver, Canada: Association for
                    Computational Linguistics, pp.7-16.</li>
            </ul>

            <h4 id="overview-of-the-task-on-automatic-misogyny-identification-at-ibereval-2018-english">Overview of the
                Task on Automatic Misogyny Identification at IberEval 2018 (English)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2150/overview-AMI.pdf">http://ceur-ws.org/Vol-2150/overview-AMI.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://amiibereval2018.wordpress.com/important-dates/data/">https://amiibereval2018.wordpress.com/im
                        nt-dates/data/</a></li>
                <li>Task description: Binary (misogyny / not), 5 categories (stereotype, dominance, derailing, sexual
                    harassment, discredit), target of misogyny (active or passive)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 3,977</li>
                <li>Percentage abusive: 0.47</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fersini, E., Rosso, P. and Anzovino, M., 2018. Overview of the Task on Automatic Misogyny
                    Identification at IberEval 2018. In: Proceedings of the Third Workshop on Evaluation of Human
                    Language Technologies for Iberian Languages (IberEval 2018).</li>
            </ul>

            <h4
                id="conan---counter-narratives-through-nichesourcing-a-multilingual-dataset-of-responses-to-fight-online-hate-speech-english">
                CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online
                Hate Speech (English)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/P19-1271.pdf">https://www.aclweb.org/anthology/P19-1271.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (Islamophobic / not), multi-topic (Culture, Economics, Crimes, Rapism,
                    Terrorism, Women Oppression, History, Other/generic)</li>
                <li>Details of task: Islamophobia</li>
                <li>Size of dataset: 1,288</li>
                <li>Percentage abusive: 1</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Synthetic / Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives
                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:
                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,
                    Italy: Association for Computational Linguistics, pp.2819-2829.</li>
            </ul>

            <h4 id="characterizing-and-detecting-hateful-users-on-twitter">Characterizing and Detecting Hateful Users on
                Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1803.08977.pdf">https://arxiv.org/pdf/1803.08977.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/manoelhortaribeiro/HatefulUsersTwitter">https://github.com/manoelhortaribeiro/HatefulUsersTwitter</a>
                </li>
                <li>Task description: Binary (hateful/not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 4,972</li>
                <li>Percentage abusive: 0.11</li>
                <li>Language: English</li>
                <li>Level of annotation: Users</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ribeiro, M., Calais, P., Santos, Y., Almeida, V. and Meira, W., 2018. Characterizing and
                    Detecting Hateful Users on Twitter. ArXiv,.</li>
            </ul>

            <h4 id="a-benchmark-dataset-for-learning-to-intervene-in-online-hate-speech-gab">A Benchmark Dataset for
                Learning to Intervene in Online Hate Speech (Gab)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1909.04251">https://arxiv.org/abs/1909.04251</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech">https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech</a>
                </li>
                <li>Task description: Binary (hateful/not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 33,776</li>
                <li>Percentage abusive: 0.43</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts (in the context of a conversation)</li>
                <li>Platform: Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Qian, J., Bethke, A., Belding, E. and Yang Wang, W., 2019. A Benchmark Dataset for
                    Learning to Intervene in Online Hate Speech. ArXiv,.</li>
            </ul>

            <h4 id="a-benchmark-dataset-for-learning-to-intervene-in-online-hate-speech-reddit">A Benchmark Dataset for
                Learning to Intervene in Online Hate Speech (Reddit)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1909.04251">https://arxiv.org/abs/1909.04251</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech">https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech</a>
                </li>
                <li>Task description: Binary (hateful/not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 22,324</li>
                <li>Percentage abusive: 0.24</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts (with context of the converstaional thread taken into account)</li>
                <li>Platform: Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Qian, J., Bethke, A., Belding, E. and Yang Wang, W., 2019. A Benchmark Dataset for
                    Learning to Intervene in Online Hate Speech. ArXiv,.</li>
            </ul>

            <h4 id="multilingual-and-multi-aspect-hate-speech-analysis-english">Multilingual and Multi-Aspect Hate
                Speech Analysis (English)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1908.11049">https://arxiv.org/abs/1908.11049</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HKUST-KnowComp/MLMA_hate_speech">https://github.com/HKUST-KnowComp/MLMA_hate_speech</a>
                </li>
                <li>Task description: Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target
                    attribute and Target group.</li>
                <li>Details of task: Gender, Sexual orientation, Religion, Disability</li>
                <li>Size of dataset: 5,647</li>
                <li>Percentage abusive: 0.76</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and
                    Multi-Aspect Hate Speech Analysis. ArXiv,.</li>
            </ul>

            <h4 id="exploring-hate-speech-detection-in-multimodal-publications">Exploring Hate Speech Detection in
                Multimodal Publications</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1910.03814.pdf">https://arxiv.org/pdf/1910.03814.pdf</a></li>
                <li>Link to data: <a
                        href="https://drive.google.com/file/d/1S9mMhZFkntNnYdO-1dZXwF_8XIiFcmlF/view">https://drive.google.com/file/d/1S9mMhZFkntNnYdO-1dZXwF_8XIiFcmlF/view</a>
                </li>
                <li>Task description: Multimodal Hate Speech Detection, including six primary categories (No attacks to
                    any community, Racist, Sexist, Homophobic, Religion based attack, Attack to other community)</li>
                <li>Details of task: Racism, Sexism, Homophobia, Religion-based attack</li>
                <li>Size of dataset: 149,823</li>
                <li>Percentage abusive: 0.25</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text and Images/Memes</li>
                <li>Reference: Gomez, R., Gibert, J., Gomez, L. and Karatzas, D., 2020. In Proceedings of the IEEE/CVF
                    winter conference on applications of computer vision (pp. 1470-1478).</li>
            </ul>

            <h4 id="predicting-the-type-and-target-of-offensive-posts-in-social-media-1">Predicting the Type and Target
                of Offensive Posts in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1902.09666.pdf">https://arxiv.org/pdf/1902.09666.pdf</a></li>
                <li>Link to data: <a
                        href="http://competitions.codalab.org/ competitions/20011">http://competitions.codalab.org/
                        competitions/20011</a></li>
                <li>Task description: Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,
                    Not), Within Target (Individual, Group, Other)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 14,100</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N. and Kumar, R., 2019.
                    SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval).
                    ArXiv,.</li>
            </ul>

            <h4
                id="hateval-semeval-2019-task-5-multilingual-detection-of-hate-speech-against-immigrants-and-women-in-twitter-english">
                hatEval, SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in
                Twitter (English)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/S19-2007">https://www.aclweb.org/anthology/S19-2007</a>
                </li>
                <li>Link to data: <a
                        href="competitions.codalab.org/competitions/19935">http://competitions.codalab.org/competitions/19935</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),
                    Within Hate (Agressive, Not)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 13,000</li>
                <li>Percentage abusive: 0.4</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Pardo, F., Rosso, P. and
                    Sanguinetti, M., 2019. SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants
                    and Women in Twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation.
                    Minneapolis, Minnesota: Association for Computational Linguistics, pp.54-63.</li>
            </ul>

            <h4 id="peer-to-peer-hate-hate-speech-instigators-and-their-targets">Peer to Peer Hate: Hate Speech
                Instigators and Their Targets</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17905/16996">https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17905/16996</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/mayelsherif/hate_speech_icwsm18">https://github.com/mayelsherif/hate_speech_icwsm18</a>
                </li>
                <li>Task description: Binary (Hate/Not), only for tweets which have both a Hate Instigator and Hate
                    Target</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 27,330</li>
                <li>Percentage abusive: 0.98</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: ElSherief, M., Nilizadeh, S., Nguyen, D., Vigna, G. and Belding, E., 2018. Peer to Peer
                    Hate: Hate Speech Instigators and Their Targets. In: Proceedings of the Twelfth International AAAI
                    Conference on Web and Social Media (ICWSM 2018). Santa Barbara, California: University of
                    California, pp.52-61.</li>
            </ul>

            <h4
                id="overview-of-the-hasoc-track-at-fire-2019-hate-speech-and-offensive-content-identification-in-indo-european-languages">
                Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in
                Indo-European Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true">https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true</a>
                </li>
                <li>Link to data: <a
                        href="https://hasocfire.github.io/hasoc/2019/dataset.html">https://hasocfire.github.io/hasoc/2019/dataset.html</a>
                </li>
                <li>Task description: Branching structure of tasks. A: Hate / Offensive or Neither, B: Hatespeech,
                    Offensive, or Profane, C: Targeted or Untargeted</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 7,005</li>
                <li>Percentage abusive: 0.36</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.
                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information
                    Retrieval Evaluation,.</li>
            </ul>

            <h4 id="detecting-east-asian-prejudice-on-social-media">Detecting East Asian Prejudice on Social media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.alw-1.19.pdf">https://www.aclweb.org/anthology/2020.alw-1.19.pdf</a>
                </li>
                <li>Link to data: <a href="https://zenodo.org/record/3816667">https://zenodo.org/record/3816667</a></li>
                <li>Task description: Task 1: Thematic annotation (East Asia/Covid-19) Task 2: Primary category
                    annotation: 1) Hostility against an East Asian (EA) entity 2) Criticism of an East Asian entity 3)
                    Counter speech 5) Discussion of East Asian prejudice 5) Non-related. Task 3: Secondary category
                    annotation (if (1) or (2) - identifying what East Asian entity was targeted + if (1) interpersonal
                    abuse/threatening language/dehumanization).</li>
                <li>Details of task: Detecting East Asian prejudice</li>
                <li>Size of dataset: 20,000</li>
                <li>Percentage abusive: 27% (Hostility, 19.5%; Criticism, 7.2%)</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Vidgen, B., Botelho, A., Broniatowski, D., Guest, E., Hall, M., Margetts, H., Tromble,
                    R., Waseem, Z. and Hale, S., Detecting East Asian Prejudice on Social media, 2020, In: Proceedings
                    of the Fourth Workshop on Online Abuse and Harms, pp.162‚Äì172</li>
            </ul>

            <h4 id="large-scale-crowdsourcing-and-characterization-of-twitter-abusive-behavior">Large Scale
                Crowdsourcing and Characterization of Twitter Abusive Behavior</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1802.00393.pdf">https://arxiv.org/pdf/1802.00393.pdf</a></li>
                <li>Link to data: <a
                        href="https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN">https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN</a>
                </li>
                <li>Task description: Multi-thematic (Abusive, Hateful, Normal, Spam)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 80,000</li>
                <li>Percentage abusive: 0.18</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Annotation process: Very detailed information is given: multiple rounds, using a smaller 300 tweet
                    dataset for testing the schema. For the final 80k, 5 judgements per tweet. CrowdFlower</li>
                <li>Annotation agreement: 55.9% = 4/5, 36.6% = 3/5, 7.5% = 2/5</li>
                <li>Reference: Founta, A., Djouvas, C., Chatzakou, D., Leontiadis, I., Blackburn, J., Stringhini, G.,
                    Vakali, A., Sirivianos, M. and Kourtellis, N., 2018. Large Scale Crowdsourcing and Characterization
                    of Twitter Abusive Behavior. ArXiv,.</li>
            </ul>

            <h4 id="a-large-labeled-corpus-for-online-harassment-research">A Large Labeled Corpus for Online Harassment
                Research</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.cs.umd.edu/~golbeck/papers/trolling.pdf">http://www.cs.umd.edu/~golbeck/papers/trolling.pdf</a>
                </li>
                <li>Link to data: jgolbeck@umd.edu</li>
                <li>Task description: Binary (Harassment, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 35,000</li>
                <li>Percentage abusive: 0.16</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Golbeck, J., Ashktorab, Z., Banjo, R., Berlinger, A., Bhagwan, S., Buntain, C.,
                    Cheakalos, P., Geller, A., Gergory, Q., Gnanasekaran, R., Gnanasekaran, R., Hoffman, K., Hottle, J.,
                    Jienjitlert, V., Khare, S., Lau, R., Martindale, M., Naik, S., Nixon, H., Ramachandran, P., Rogers,
                    K., Rogers, L., Sarin, M., Shahane, G., Thanki, J., Vengataraman, P., Wan, Z. and Wu, D., 2017. A
                    Large Labeled Corpus for Online Harassment Research. In: Proceedings of the 2017 ACM on Web Science
                    Conference. New York: Association for Computing Machinery, pp.229-233.</li>
            </ul>

            <h4 id="ex-machina-personal-attacks-seen-at-scale-personal-attacks">Ex Machina: Personal Attacks Seen at
                Scale, Personal attacks</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1610.08914">https://arxiv.org/pdf/1610.08914</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ewulczyn/wiki-detox">https://github.com/ewulczyn/wiki-detox</a></li>
                <li>Task description: Binary (Personal attack, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 115,737</li>
                <li>Percentage abusive: 0.12</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Wikipedia</li>
                <li>Medium: Text</li>
                <li>Reference: Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.
                    ArXiv,.</li>
            </ul>

            <h4 id="ex-machina-personal-attacks-seen-at-scale-toxicity">Ex Machina: Personal Attacks Seen at Scale,
                Toxicity</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1610.08914">https://arxiv.org/pdf/1610.08914</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ewulczyn/wiki-detox">https://github.com/ewulczyn/wiki-detox</a></li>
                <li>Task description: Toxicity/healthiness judgement (-2 == very toxic, 0 == neutral, 2 == very healthy)
                </li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 100,000</li>
                <li>Percentage abusive: NA</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Wikipedia</li>
                <li>Medium: Text</li>
                <li>Reference: Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.
                    ArXiv,.</li>
            </ul>

            <h4 id="detecting-cyberbullying-in-online-communities-world-of-warcraft">Detecting cyberbullying in online
                communities (World of Warcraft)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://aisel.aisnet.org/ecis2016_rp/61/">http://aisel.aisnet.org/ecis2016_rp/61/</a></li>
                <li>Link to data: <a href="http://ub-web.de/research/">http://ub-web.de/research/</a></li>
                <li>Task description: Binary (Harassment, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 16,975</li>
                <li>Percentage abusive: 0.01</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: World of Warcraft</li>
                <li>Medium: Text</li>
                <li>Reference: Bretschneider, U. and Peters, R., 2016. Detecting Cyberbullying in Online Communities.
                    Research Papers, 61.</li>
            </ul>

            <h4 id="detecting-cyberbullying-in-online-communities-league-of-legends">Detecting cyberbullying in online
                communities (League of Legends)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://aisel.aisnet.org/ecis2016_rp/61/">http://aisel.aisnet.org/ecis2016_rp/61/</a></li>
                <li>Link to data: <a href="http://ub-web.de/research/">http://ub-web.de/research/</a></li>
                <li>Task description: Binary (Harassment, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 17,354</li>
                <li>Percentage abusive: 0.01</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: League of Legends</li>
                <li>Medium: Text</li>
                <li>Reference: Bretschneider, U. and Peters, R., 2016. Detecting Cyberbullying in Online Communities.
                    Research Papers, 61.</li>
            </ul>

            <h4 id="a-quality-type-aware-annotated-corpus-and-lexicon-for-harassment-research">A Quality Type-aware
                Annotated Corpus and Lexicon for Harassment Research</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1802.09416.pdf">https://arxiv.org/pdf/1802.09416.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/Mrezvan94/Harassment-Corpus">https://github.com/Mrezvan94/Harassment-Corpus</a>
                </li>
                <li>Task description: Multi-topic harassment detection</li>
                <li>Details of task: Racism, Sexism, Appearance-related, Intellectual, Political</li>
                <li>Size of dataset: 24,189</li>
                <li>Percentage abusive: 0.13</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Rezvan, M., Shekarpour, S., Balasuriya, L., Thirunarayan, K., Shalin, V. and Sheth, A.,
                    2018. A Quality Type-aware Annotated Corpus and Lexicon for Harassment Research. ArXiv,.</li>
            </ul>

            <h4 id="ex-machina-personal-attacks-seen-at-scale-aggression-and-friendliness">Ex Machina: Personal Attacks
                Seen at Scale, Aggression and Friendliness</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1610.08914">https://arxiv.org/pdf/1610.08914</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ewulczyn/wiki-detox">https://github.com/ewulczyn/wiki-detox</a></li>
                <li>Task description: Aggression/friendliness judgement on a 5 point scale. (-2 == very aggressive, 0 ==
                    neutral, 3 == very friendly).</li>
                <li>Details of task: Person-Directed + Group-Directed</li>
                <li>Size of dataset: 160,000</li>
                <li>Percentage abusive: NA</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Wikipedia</li>
                <li>Medium: Text</li>
                <li>Reference: Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.
                    ArXiv,.</li>
            </ul>

            <h4 id="are-chess-discussions-racist-an-adversarial-hate-speech-data-set">Are Chess Discussions Racist? An
                Adversarial Hate Speech Data Set</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2011.10280.pdf">https://arxiv.org/pdf/2011.10280.pdf</a></li>
                <li>Link to data: <a
                        href="https://www.cs.cmu.edu/~akhudabu/Chess.html">https://www.cs.cmu.edu/~akhudabu/Chess.html</a>
                </li>
                <li>Task description: Not Labeled</li>
                <li>Details of task: Racism, Misclassification</li>
                <li>Size of dataset: 1,000</li>
                <li>Percentage abusive: 0.0</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Rupak Sarkar and Ashiqur R. KhudaBukhsh, Nov. 2020. Are Chess Discussions Racist? An
                    Adversarial Hate Speech Data Set. In: The Thirty-Fifth {AAAI} Conference on Artificial Intelligence,
                    {AAAI} 2021</li>
            </ul>

            <h4 id="ethos-an-online-hate-speech-detection-dataset-binary">ETHOS: an Online Hate Speech Detection Dataset
                (Binary)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.08328.pdf">https://arxiv.org/pdf/2006.08328.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset">https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Gender, Race, National Origin, Disability, Religion, Sexual Orientation</li>
                <li>Size of dataset: 998</li>
                <li>Percentage abusive: 0.43</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube, Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Mollas, I., Chrysopoulou, Z., Karlos, S., and Tsoumakas, G., 2021. ETHOS: an Online Hate
                    Speech Detection Dataset. Complex &amp; Intelligent Systems, Jan. 2022</li>
            </ul>

            <h4 id="ethos-an-online-hate-speech-detection-dataset-multi-label">ETHOS: an Online Hate Speech Detection
                Dataset (Multi label)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.08328.pdf">https://arxiv.org/pdf/2006.08328.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset">https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset</a>
                </li>
                <li>Task description: 8 Categories (Violence, Directed/Undirected, Gender, Race, National Origin,
                    Disability, Sexual Orientation, Religion)</li>
                <li>Details of task: Gender, Race, National Origin, Disability, Religion, Sexual Orientation</li>
                <li>Size of dataset: 433</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube, Reddit</li>
                <li>Medium: Text</li>
                <li>Reference: Mollas, I., Chrysopoulou, Z., Karlos, S., and Tsoumakas, G., 2021. ETHOS: an Online Hate
                    Speech Detection Dataset. Complex &amp; Intelligent Systems, Jan. 2022</li>
            </ul>

            <h4 id="twitter-sentiment-analysis">Twitter Sentiment Analysis</h4>
            <ul>
                <li>Link to publication: NA</li>
                <li>Link to data: <a
                        href="https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech">https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Racism, Sexism</li>
                <li>Size of dataset: 31,961</li>
                <li>Percentage abusive: 0.07</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ali Toosi, Jan 2019. Twitter Sentiment Analysis</li>
            </ul>

            <h4 id="toxicity-detection-does-context-really-matter-cat-large-no-context">Toxicity Detection: Does Context
                Really Matter? CAT-LARGE (No Context)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.00998.pdf">https://arxiv.org/pdf/2006.00998.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/ipavlopoulos/context_toxicity">https://github.com/ipavlopoulos/context_toxicity</a>
                </li>
                <li>Task description: Binary (Toxic, Non-toxic)</li>
                <li>Details of task: Toxicity, Context</li>
                <li>Size of dataset: 10,000</li>
                <li>Percentage abusive: 0.006</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Wikipedia Talk Pages</li>
                <li>Medium: Text</li>
                <li>Reference: Pavlopoulos, J., Sorensen, J., Dixon, L., Thain, N., &amp; Androutsopoulos, I. (2020).
                    Toxicity Detection: Does Context Really Matter? ArXiv:2006.00998 [Cs].</li>
            </ul>

            <h4 id="toxicity-detection-does-context-really-matter-cat-large-with-context">Toxicity Detection: Does
                Context Really Matter? CAT-LARGE (With Context)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2006.00998.pdf">https://arxiv.org/pdf/2006.00998.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/ipavlopoulos/context_toxicity">https://github.com/ipavlopoulos/context_toxicity</a>
                </li>
                <li>Task description: Binary (Toxic, Non-toxic)</li>
                <li>Details of task: Toxicity, Context</li>
                <li>Size of dataset: 10,000</li>
                <li>Percentage abusive: 0.02</li>
                <li>Language: English</li>
                <li>Level of annotation: Post</li>
                <li>Platform: Wikipedia Talk Pages</li>
                <li>Medium: Text</li>
                <li>Reference: Pavlopoulos, J., Sorensen, J., Dixon, L., Thain, N., &amp; Androutsopoulos, I. (2020).
                    Toxicity Detection: Does Context Really Matter? ArXiv:2006.00998 [Cs].</li>
            </ul>

            <h4
                id="anatomy-of-online-hate-developing-a-taxonomy-and-machine-learning-models-for-identifying-and-classifying-hate-in-online-news-media">
                Anatomy of Online Hate: Developing a Taxonomy and Machine Learning Models for Identifying and
                Classifying Hate in Online News Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewFile/17885/17024">https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewFile/17885/17024</a>
                </li>
                <li>Link to data: <a
                        href="https://www.dropbox.com/s/21wtzy9arc5skr8/ICWSM18%20-%20SALMINEN%20ET%20AL.xlsx?dl=0">https://www.dropbox.com/s/21wtzy9arc5skr8/ICWSM18%20-%20SALMINEN%20ET%20AL.xlsx?dl=0</a>
                </li>
                <li>Task description: Binary (Hate, Not), Multinomial classification (21 categories divided into
                    ‚Äòhateful language‚Äô, ‚Äòhate targets‚Äô and ‚Äòhate sub-targets‚Äô)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 5,143</li>
                <li>Percentage abusive: 82%</li>
                <li>Language: English</li>
                <li>Level of annotation: Comment</li>
                <li>Platform: YouTube and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Salminen, J., Almerekhi, H., Milenkoviƒá, M., Jung, S., An, J., Kwak, H. and Jansen, B.,
                    2018, Anatomy of Online Hate: Developing a Taxonomy and Machine Learning Models for Identifying and
                    Classifying Hate in Online News Media, In: Proceedings of the Twelfth International AAAI Conference
                    on Web and Social Media (ICWSM 2018), pp.330-339</li>
            </ul>

            <p><a id="Estonian-header"></a></p>
            <h3 id="estonian">Estonian</h3>
            <h4 id="automating-news-comment-moderation-with-limited-resources-benchmarking-in-croatian-and-estonian-1">
                Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf">https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf</a>
                </li>
                <li>Link to data: <a href="http://hdl.handle.net/11356/1401">http://hdl.handle.net/11356/1401</a></li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content performmed by the real newspaper moderators</li>
                <li>Size of dataset: 31.5M</li>
                <li>Percentage abusive: 12.5%</li>
                <li>Language: Estonian (some in Russian also)</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Newspaper comments, Eesti Ekspress (www.ekspress.ee) website</li>
                <li>Medium: Text</li>
                <li>Reference: Ravi Shekhar, Marko Pranjiƒá, Senja Pollak, Andra≈æ Pelicon, Matthew Purver (2020).
                    Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian.
                    Journal for Language Technology and Computational Linguistics (JLCL).</li>
            </ul>

            <h4 id="hatexplain-a-benchmark-dataset-for-explainable-hate-speech-detection-1">HateXplain: A Benchmark
                Dataset for Explainable Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2012.10289.pdf">https://arxiv.org/pdf/2012.10289.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/punyajoy/HateXplain">https://github.com/punyajoy/HateXplain</a></li>
                <li>Task description: Binary (Hate, Not) and Three-class (Hate speech, Offensive language, None)</li>
                <li>Details of task: Hatespeech detection on social media in English, including 10 categories: African,
                    Islam, Jewish, LGBTQ, Women, Refugee, Arab, Caucasian, Hispanic, Asian</li>
                <li>Size of dataset: 20148</li>
                <li>Percentage abusive: 57%</li>
                <li>Language: English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Gab</li>
                <li>Medium: Text</li>
                <li>Reference: Mathew, B., Saha, P., Yimam, S. M., Biemann, C., Goyal, P., &amp; Mukherjee, A. (2020).
                    Hatexplain: A benchmark dataset for explainable hate speech detection. arXiv preprint
                    arXiv:2012.10289.</li>
            </ul>

            <p><a id="French-header"></a></p>
            <h3 id="french">French</h3>
            <h4
                id="conan---counter-narratives-through-nichesourcing-a-multilingual-dataset-of-responses-to-fight-online-hate-speech-french">
                CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online
                Hate Speech (French)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/P19-1271.pdf">https://www.aclweb.org/anthology/P19-1271.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (Islamophobic / not), Multi-topic (Culture, Economics, Crimes, Rapism,
                    Terrorism, Women Oppression, History, Other/generic)</li>
                <li>Details of task: Islamophobia</li>
                <li>Size of dataset: 1,719</li>
                <li>Percentage abusive: 1</li>
                <li>Language: French</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Synthetic / Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives
                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:
                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,
                    Italy: Association for Computational Linguistics, pp.2819-2829.</li>
            </ul>

            <h4 id="multilingual-and-multi-aspect-hate-speech-analysis-french">Multilingual and Multi-Aspect Hate Speech
                Analysis (French)</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/abs/1908.11049">https://arxiv.org/abs/1908.11049</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/HKUST-KnowComp/MLMA_hate_speech">https://github.com/HKUST-KnowComp/MLMA_hate_speech</a>
                </li>
                <li>Task description: Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target
                    Attribute, Target Group, How annotators felt on seeing the tweet.</li>
                <li>Details of task: Gender, Sexual orientation, Religion, Disability</li>
                <li>Size of dataset: 4,014</li>
                <li>Percentage abusive: 0.72</li>
                <li>Language: French</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and
                    Multi-Aspect Hate Speech Analysis. ArXiv,.</li>
            </ul>

            <p><a id="German-header"></a></p>
            <h3 id="german">German</h3>
            <h4 id="rp-mod--rp-crowd-moderator--and-crowd-annotated-german-news-comment-datasets">RP-Mod &amp; RP-Crowd:
                Moderator- and Crowd-Annotated German News Comment Datasets</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/c9e1074f5b3f9fc8ea15d152add07294-Paper-round2.pdf">https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/c9e1074f5b3f9fc8ea15d152add07294-Paper-round2.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://zenodo.org/record/5291339#.Ybr_9VkxkUE">https://zenodo.org/record/5291339#.Ybr_9VkxkUE</a>
                </li>
                <li>Task description: Binary (Offensive or Not), Multi-class/-label (sexism, racism, threats, insults,
                    profane language, meta, advertisement).</li>
                <li>Details of task: The comments originate from a large German newspaper and are annotated by
                    professional moderators (community managers). Additionally, each comment was further annotated by
                    five different crowd-workers.</li>
                <li>Size of dataset: 85,000</li>
                <li>Percentage abusive: 8.4%</li>
                <li>Language: German</li>
                <li>Level of annotation: Comments</li>
                <li>Platform: German Newspaper (Rheinische Post)</li>
                <li>Medium: Text</li>
                <li>Reference: Assenmacher, D., Niemann, M., M√ºller, K., Seiler, M., Riehle, D. M., &amp; Trautmann, H.
                    (2021). RP-Mod &amp; RP-Crowd: Moderator- and crowd-annotated german news comment datasets. In
                    Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmark.</li>
            </ul>

            <h4 id="measuring-the-reliability-of-hate-speech-annotations-the-case-of-the-european-refugee-crisis">
                Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/1701.08118.pdf">https://arxiv.org/pdf/1701.08118.pdf</a></li>
                <li>Link to data: <a
                        href="https://github.com/UCSM-DUE/IWG_hatespeech_public">https://github.com/UCSM-DUE/IWG_hatespeech_public</a>
                </li>
                <li>Task description: Binary (Anti-refugee hate, None)</li>
                <li>Details of task: Refugees</li>
                <li>Size of dataset: 469</li>
                <li>Percentage abusive: NA</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ross, B., Rist, M., Carbonell, G., Cabrera, B., Kurowsky, N. and Wojatzki, M., 2017.
                    Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis.
                    ArXiv,.</li>
            </ul>

            <h4 id="detecting-offensive-statements-towards-foreigners-in-social-media">Detecting Offensive Statements
                Towards Foreigners in Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://pdfs.semanticscholar.org/23dc/df7c7e82807445afd9f19474fc0a3d8169fe.pdf">https://pdfs.semanticscholar.org/23dc/df7c7e82807445afd9f19474fc0a3d8169fe.pdf</a>
                </li>
                <li>Link to data: <a href="http://ub-web.de/research/">http://ub-web.de/research/</a></li>
                <li>Task description: Hierarchical (Anti-foreigner prejudice, split into (1) slightly
                    offensive/offensive and (2) explicitly/substantially offensive). 6 targets (Foreigner, Government,
                    Press, Community, Other, Unknown)</li>
                <li>Details of task: Anti-foreigner prejudice</li>
                <li>Size of dataset: 5,836</li>
                <li>Percentage abusive: 0.11</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Bretschneider, U. and Peters, R., 2017. Detecting Offensive Statements towards Foreigners
                    in Social Media. In: Proceedings of the 50th Hawaii International Conference on System Sciences.
                </li>
            </ul>

            <h4 id="germeval-2018">GermEval 2018</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.researchgate.net/publication/327914386_Overview_of_the_GermEval_2018_Shared_Task_on_the_Identification_of_Offensive_Language">https://www.researchgate.net/publication/327914386_Overview_of_the_GermEval_2018_Shared_Task_on_the_Identification_of_Offensive_Language</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/uds-lsv/GermEval-2018-Data">https://github.com/uds-lsv/GermEval-2018-Data</a>
                </li>
                <li>Task description: Branching structure: Binary (Offense, Other), 3 levels within Offense (Abuse,
                    Insult, Profanity)</li>
                <li>Details of task: Group-directed + Incivility</li>
                <li>Size of dataset: 8,541</li>
                <li>Percentage abusive: 0.34</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared
                    Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference
                    on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate.</li>
            </ul>

            <h4
                id="overview-of-the-hasoc-track-at-fire-2019-hate-speech-and-offensive-content-identification-in-indo-european-languages-1">
                Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in
                Indo-European Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true">https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true</a>
                </li>
                <li>Link to data: <a
                        href="https://hasocfire.github.io/hasoc/2019/dataset.html">https://hasocfire.github.io/hasoc/2019/dataset.html</a>
                </li>
                <li>Task description: A: Hate / Offensive or neither, B: Hatespeech, Offensive, or Profane</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 4,669</li>
                <li>Percentage abusive: 0.24</li>
                <li>Language: German</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.
                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information
                    Retrieval Evaluation,.</li>
            </ul>

            <p><a id="Greek-header"></a></p>
            <h3 id="greek">Greek</h3>
            <h4 id="deep-learning-for-user-comment-moderation-flagged-comments">Deep Learning for User Comment
                Moderation, Flagged Comments</h4>
            <ul>
                <li>Link to publication: <a href="https://www.aclweb.org/anthology/W17-3004
https://www.aclweb.org/anthology/D17-1117">https://www.aclweb.org/anthology/W17-3004</a></li>
                <li>Link to data: <a href="http://www.straintek.com/data/">http://www.straintek.com/data/</a></li>
                <li>Task description: Binary (Flagged, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 1,450,000</li>
                <li>Percentage abusive: 0.34</li>
                <li>Language: Greek</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Gazetta</li>
                <li>Medium: text</li>
                <li>Reference: Pavlopoulos, J., Malakasiotis, P. and Androutsopoulos, I., 2017. Deep Learning for User
                    Comment Moderation. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver,
                    Canada: Association for Computational Linguistics, pp.25-35.</li>
            </ul>

            <h4 id="deep-learning-for-user-comment-moderation-moderated-comments">Deep Learning for User Comment
                Moderation, Moderated Comments</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W17-3004">https://www.aclweb.org/anthology/W17-3004</a>
                </li>
                <li>Link to data: <a href="http://www.straintek.com/data/">http://www.straintek.com/data/</a></li>
                <li>Task description: Binary (Flagged, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 1,500</li>
                <li>Percentage abusive: 0.22</li>
                <li>Language: Greek</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Gazetta</li>
                <li>Medium: text</li>
                <li>Reference: Pavlopoulos, J., Malakasiotis, P. and Androutsopoulos, I., 2017. Deep Learning for User
                    Comment Moderation. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver,
                    Canada: Association for Computational Linguistics, pp.25-35.</li>
            </ul>

            <h4 id="offensive-language-identification-in-greek">Offensive Language Identification in Greek</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2003.07459v1.pdf">https://arxiv.org/pdf/2003.07459v1.pdf</a></li>
                <li>Link to data: <a
                        href="https://sites.google.com/site/offensevalsharedtask/home">https://sites.google.com/site/offensevalsharedtask/home</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,
                    Not), Within Target (Individual, Group, Other)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 4779</li>
                <li>Percentage abusive: 0.29</li>
                <li>Language: Greek</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Pitenis, Z., Zampieri, M. and Ranasinghe, T., 2020. Offensive Language Identification in
                    Greek. ArXiv.</li>
                <li>Dataset reader: ü§ó <a
                        href="https://huggingface.co/datasets/strombergnlp/offenseval_2020">strombergnlp/offenseval_2020</a>
                </li>
            </ul>

            <p><a id="Hindi-header"></a></p>
            <h3 id="hindi--hindi-english">Hindi / Hindi-English</h3>
            <h4 id="hostility-detection-dataset-in-hindi">Hostility Detection Dataset in Hindi</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://arxiv.org/pdf/2011.03588.pdf">https://arxiv.org/pdf/2011.03588.pdf</a></li>
                <li>Link to data: <a
                        href="https://competitions.codalab.org/competitions/26654">https://competitions.codalab.org/competitions/26654</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hostile, Not Hostile), Multi-tags within
                    Hostile (Fake News, Hate, Offense, Defame)</li>
                <li>Details of task: Hostility detection</li>
                <li>Size of dataset: 8,192</li>
                <li>Percentage abusive: 47%</li>
                <li>Language: Hindi</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter, Facebook, WhatsApp</li>
                <li>Medium: Text</li>
                <li>Reference: Bhardwaj, M., Akhtar, M.S., Ekbal, A., Das, A. and Chakraborty, T., 2020. Hostility
                    detection dataset in hindi. arXiv preprint arXiv:2011.03588.</li>
            </ul>

            <h4 id="aggression-annotated-corpus-of-hindi-english-code-mixed-data">Aggression-annotated Corpus of
                Hindi-English Code-mixed Data</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1803.09402">https://arxiv.org/pdf/1803.09402</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/kraiyani/Facebook-Post-Aggression-Identification">https://github.com/kraiyani/Facebook-Post-Aggression-Identification</a>
                </li>
                <li>Task description: 3 part hierachy for hate (None, Covert Aggression, Overt Aggression), 4 part
                    target categorisation (Physical threat, Sexual threat, Identity threat, Non-threatening aggression),
                    3-part discursive role categorisation (Attack, Defend, Abet)</li>
                <li>Details of task: Numerous sub-categorizations</li>
                <li>Size of dataset: 18,000</li>
                <li>Percentage abusive: 0.06</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Kumar, R., Reganti, A., Bhatia, A. and Maheshwari, T., 2018. Aggression-annotated Corpus
                    of Hindi-English Code-mixed Data. ArXiv,.</li>
            </ul>

            <h4 id="aggression-annotated-corpus-of-hindi-english-code-mixed-data-1">Aggression-annotated Corpus of
                Hindi-English Code-mixed Data</h4>
            <ul>
                <li>Link to publication: <a href="https://arxiv.org/pdf/1803.09402">https://arxiv.org/pdf/1803.09402</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/kraiyani/Facebook-Post-Aggression-Identification">https://github.com/kraiyani/Facebook-Post-Aggression-Identification</a>
                </li>
                <li>Task description: 3 part hierachy for hate (None, Covert Aggression, Overt Aggression), 4 part
                    target categorisation (Physical threat, Sexual threat, Identity threat, Non-threatening aggression),
                    3-part discursive role categorisation (Attack, Defend, Abet)</li>
                <li>Details of task: Numerous sub-categorizations</li>
                <li>Size of dataset: 21,000</li>
                <li>Percentage abusive: 0.27</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Kumar, R., Reganti, A., Bhatia, A. and Maheshwari, T., 2018. Aggression-annotated Corpus
                    of Hindi-English Code-mixed Data. ArXiv,.</li>
            </ul>

            <h4 id="did-you-offend-me-classification-of-offensive-tweets-in-hinglish-language">Did You Offend Me?
                Classification of Offensive Tweets in Hinglish Language</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5118">https://www.aclweb.org/anthology/W18-5118</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/pmathur5k10/Hinglish-Offensive-Text-Classification">https://github.com/pmathur5k10/Hinglish-Offensive-Text-Classification</a>
                </li>
                <li>Task description: Hierarchy (Not Offensive, Abusive, Hate)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 3,189</li>
                <li>Percentage abusive: 0.65</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Mathur, P., Sawhney, R., Ayyar, M. and Shah, R., 2018. Did you offend me? Classification
                    of Offensive Tweets in Hinglish Language. In: Proceedings of the 2nd Workshop on Abusive Language
                    Online (ALW2). Brussels, Belgium: Association for Computational Linguistics, pp.138-148.</li>
            </ul>

            <h4 id="a-dataset-of-hindi-english-code-mixed-social-media-text-for-hate-speech-detection">A Dataset of
                Hindi-English Code-Mixed Social Media Text for Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-1105">https://www.aclweb.org/anthology/W18-1105</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/deepanshu1995/HateSpeech-Hindi-English-Code-Mixed-Social-Media-Text">https://github.com/deepanshu1995/HateSpeech-Hindi-English-Code-Mixed-Social-Media-Text</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 4,575</li>
                <li>Percentage abusive: 0.36</li>
                <li>Language: Hindi-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Bohra, A., Vijay, D., Singh, V., Sarfaraz Akhtar, S. and Shrivastava, M., 2018. A Dataset
                    of Hindi-English Code-Mixed Social Media Text for Hate Speech Detection. In: Proceedings of the
                    Second Workshop on Computational Modeling of People‚Äôs Opinions, Personality, and Emotions in Social
                    Media. New Orleans, Louisiana: Association for Computational Linguistics, pp.36-41.</li>
            </ul>

            <h4
                id="overview-of-the-hasoc-track-at-fire-2019-hate-speech-and-offensive-content-identification-in-indo-european-languages-2">
                Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in
                Indo-European Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true">https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true</a>
                </li>
                <li>Link to data: <a
                        href="https://hasocfire.github.io/hasoc/2019/dataset.html">https://hasocfire.github.io/hasoc/2019/dataset.htm</a>
                </li>
                <li>Task description: A: Hate, Offensive or Neither, B: Hatespeech, Offensive, or Profane, C: Targeted
                    or Untargeted</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 5,983</li>
                <li>Percentage abusive: 0.51</li>
                <li>Language: Hindi</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter and Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.
                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information
                    Retrieval Evaluation,.</li>
            </ul>

            <p><a id="Indonesian-header"></a></p>
            <h3 id="indonesian">Indonesian</h3>
            <h4 id="hate-speech-detection-in-the-indonesian-language-a-dataset-and-preliminary-study">Hate Speech
                Detection in the Indonesian Language: A Dataset and Preliminary Study</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://ieeexplore.ieee.org/document/8355039">https://ieeexplore.ieee.org/document/8355039</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/ialfina/id-hatespeech-detection">https://github.com/ialfina/id-hatespeech-detection</a>
                </li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Hate per se</li>
                <li>Size of dataset: 713</li>
                <li>Percentage abusive: 0.36</li>
                <li>Language: Indonesian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Alfina, I., Mulia, R., Fanany, M. and Ekanata, Y., 2017. Hate Speech Detection in the
                    Indonesian Language: A Dataset and Preliminary Study. In: International Conference on Advanced
                    Computer Science and Information Systems. pp.233-238.</li>
            </ul>

            <h4 id="multi-label-hate-speech-and-abusive-language-detection-in-indonesian-twitter">Multi-Label Hate
                Speech and Abusive Language Detection in Indonesian Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W19-3506">https://www.aclweb.org/anthology/W19-3506</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection">https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection</a>
                </li>
                <li>Task description: (No hate speech, No hate speech but abusive, Hate speech but no abuse, Hate speech
                    and abuse), within hate, category (Religion/creed, Race/ethnicity, Physical/disability,
                    Gender/sexual orientation, Other invective/slander), within hate, strength (Weak, Moderate and
                    Strong)</li>
                <li>Details of task: Religion, Race, Disability, Gender</li>
                <li>Size of dataset: 13,169</li>
                <li>Percentage abusive: 0.42</li>
                <li>Language: Indonesian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Okky Ibrohim, M. and Budi, I., 2019. Multi-label Hate Speech and Abusive Language
                    Detection in Indonesian Twitter. In: Proceedings of the Third Workshop on Abusive Language Online.
                    Florence, Italy: Association for Computational Linguistics, pp.46-57.</li>
            </ul>

            <h4 id="a-dataset-and-preliminaries-study-for-abusive-language-detection-in-indonesian-social-media">A
                Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.sciencedirect.com/science/article/pii/S1877050918314583">https://www.sciencedirect.com/science/article/pii/S1877050918314583</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/okkyibrohim/id-abusive-language-detection">https://github.com/okkyibrohim/id-abusive-language-detection</a>
                </li>
                <li>Task description: Hierarchical (Not abusive, Abusive but not offensive, Offensive)</li>
                <li>Details of task: Incivility</li>
                <li>Size of dataset: 2,016</li>
                <li>Percentage abusive: 0.54</li>
                <li>Language: Indonesian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ibrohim, M. and Budi, I., 2018. A Dataset and Preliminaries Study for Abusive Language
                    Detection in Indonesian Social Media. Procedia Computer Science, 135, pp.222-229.</li>
            </ul>

            <p><a id="Korean-header"></a></p>
            <h3 id="korean">Korean</h3>
            <h4 id="beep-korean-corpus-of-online-news-comments-for-toxic-speech-detection__">BEEP! Korean Corpus of
                Online News Comments for Toxic Speech Detection__</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.socialnlp-1.4/">https://www.aclweb.org/anthology/2020.socialnlp-1.4</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/kocohub/korean-hate-speech">https://github.com/kocohub/korean-hate-speech</a>
                </li>
                <li>Task description: Binary (Gender bias, No gender bias), Ternary (Gender bias, Other biases, None),
                    Ternary (Hate, Offensive, None)</li>
                <li>Details of task: Person/Group-directed, Gender/Sexual orientation, Sexism, Harmfulness/Toxicity</li>
                <li>Size of dataset: 9,381</li>
                <li>Percentage abusive: 33.87 (Bias), 57.77 (Toxicity)</li>
                <li>Language: Korean</li>
                <li>Level of annotation: Comments</li>
                <li>Platform: NAVER entertainment news</li>
                <li>Medium: Text</li>
                <li>Reference: Moon, J., Cho, W. I., and Lee, J., 2020. BEEP! Korean Corpus of Online News Comments for
                    Toxic Speech Detection. In: Proceedings of the Eighth International Workshop on Natural Language
                    Processing for Social Media Month: July. Online: Association for Computational Linguistics,
                    pp.25-31.</li>
            </ul>

            <p><a id="Latvian-header"></a></p>
            <h3 id="latvian">Latvian</h3>
            <h4 id="latvian-newspaper-user-comment-dataset">Latvian newspaper user comment dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.hackashop-1.14.pdf">https://aclanthology.org/2021.hackashop-1.14.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://www.clarin.si/repository/xmlui/handle/11356/1407">https://www.clarin.si/repository/xmlui/handle/11356/1407</a>
                </li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content performmed by the real newspaper moderators</li>
                <li>Size of dataset: 12M</li>
                <li>Percentage abusive: ~10%</li>
                <li>Language: Latvian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Newspaper comments</li>
                <li>Medium: Text</li>
                <li>Reference: Senja Pollak, Marko Robnik-≈†ikonja, Matthew Purver, Michele Boggia, Ravi Shekhar, Marko
                    Pranjiƒá, Salla Salmela, Ivar Krustok, Tarmo Paju, Carl-Gustav Linden, Leo Lepp√§nen, Elaine Zosa,
                    Matej Ulƒçar, Linda Freiental, Silver Traat, Luis Adri√°n Cabrera-Diego, Matej Martinc, Nada Lavraƒç,
                    Bla≈æ ≈†krlj, Martin ≈Ωnidar≈°iƒç, Andra≈æ Pelicon, Boshko Koloski, Vid Podeƒçan, Janez Kranjc, Shane
                    Sheehan, Emanuela Boros, Jose Moreno, Antoine Doucet, Hannu Toivonen (2021). EMBEDDIA Tools,
                    Datasets and Challenges: Resources and Hackathon Contributions. Proceedings of the Hackashop on News
                    Media Content Analysis and Automated Report Generation (EACL).</li>
            </ul>

            <p><a id="Italian-header"></a></p>
            <h3 id="italian">Italian</h3>
            <h4 id="an-italian-twitter-corpus-of-hate-speech-against-immigrants">An Italian Twitter Corpus of Hate
                Speech against Immigrants</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/L18-1443">https://www.aclweb.org/anthology/L18-1443</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/msang/hate-speech-corpus">https://github.com/msang/hate-speech-corpus</a>
                </li>
                <li>Task description: Binary (Immigrants/Roma/Muslims, Not), additional categories. Within Hate,
                    Intensity measurement (Aggressiveness: No, Weak, Strong, Offensiveness: No, Weak, Strong, Irony: No,
                    Yes, Stereotype: No, Yes, Incitement degree: 0-4)</li>
                <li>Details of task: Immigrants, Roma and Muslims + numerous sub-categorizations</li>
                <li>Size of dataset: 1,827</li>
                <li>Percentage abusive: 0.13</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Sanguinetti, M., Poletto, F., Bosco, C., Patti, V. and Stranisci, M., 2018. An Italian
                    Twitter Corpus of Hate Speech against Immigrants. In: Proceedings of the Eleventh International
                    Conference on Language Resources and Evaluation (LREC 2018). Miyazaki, Japan: European Language
                    Resources Association (ELRA).</li>
            </ul>

            <h4 id="overview-of-the-evalita-2018-hate-speech-detection-task-facebook">Overview of the EVALITA 2018 Hate
                Speech Detection Task (Facebook)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2263/paper010.pdf">http://ceur-ws.org/Vol-2263/paper010.pdf</a>
                </li>
                <li>Link to data: <a
                        href="http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html">http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html</a>
                </li>
                <li>Task description: Binary (Hate, Not), Within hate for Facebook only, strength (No hate, Weak hate,
                    Strong hate) and theme ((1) religion, (2) physical and/or mental handicap, (3) socio-economic
                    status, (4) politics, (5) race, (6) sex and gender, (7) Other)</li>
                <li>Details of task: Religion, physical and/or mental handicap, socio-economic status, politics, race,
                    sex and gender</li>
                <li>Size of dataset: 4,000</li>
                <li>Percentage abusive: 0.51</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Bosco, C., Dell‚ÄôOrletta, F. and Poletto, F., 2018. Overview of the EVALITA 2018 Hate
                    Speech Detection Task. In: EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and
                    Speech Tools for Italian. CEUR, pp.1-9.</li>
            </ul>

            <h4 id="overview-of-the-evalita-2018-hate-speech-detection-task-twitter">Overview of the EVALITA 2018 Hate
                Speech Detection Task (Twitter)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2263/paper010.pdf">http://ceur-ws.org/Vol-2263/paper010.pdf</a>
                </li>
                <li>Link to data: <a
                        href="http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html">http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html</a>
                </li>
                <li>Task description: Binary (Hate, Not), Within Hate For Twitter only Intensity (1-4 rating),
                    Aggressiveness (No, Weak, Strong), Offensiveness (No, Weak, Strong), Irony (Yes, No)</li>
                <li>Details of task: Group-directed</li>
                <li>Size of dataset: 4,000</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Bosco, C., Dell‚ÄôOrletta, F. and Poletto, F., 2018. Overview of the EVALITA 2018 Hate
                    Speech Detection Task. In: EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and
                    Speech Tools for Italian. CEUR, pp.1-9.</li>
            </ul>

            <h4 id="automatic-misogyny-identification-ami-at-evalita-2020">Automatic Misogyny Identification (AMI) at
                Evalita 2020</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2765/paper161.pdf">http://ceur-ws.org/Vol-2765/paper161.pdf</a>
                </li>
                <li>Link to data: <a href="https://github.com/dnozza/ami2020">https://github.com/dnozza/ami2020</a></li>
                <li>Task description: Binary (misogyny / not), Binary (aggressive / not), Binary on synthetic fairness
                    test (misogyny / not)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 6,000 and 1,961 (synthetic fairness test)</li>
                <li>Percentage abusive: 47% and 50% (synthetic fairness test)</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fersini, E., Nozza, D., and Rosso, P., 2020. AMI @ EVALITA2020: Automatic Misogyny
                    Identification. In: Proceedings of the 7th evaluation campaign of Natural Language Processing and
                    Speech tools for Italian (EVALITA 2020).</li>
            </ul>

            <h4
                id="conan---counter-narratives-through-nichesourcing-a-multilingual-dataset-of-responses-to-fight-online-hate-speech-italian">
                CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online
                Hate Speech (Italian)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/P19-1271.pdf">https://www.aclweb.org/anthology/P19-1271.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/marcoguerini/CONAN">https://github.com/marcoguerini/CONAN</a></li>
                <li>Task description: Binary (Islamophobic, Not), Multi-topic (Culture, Economics, Crimes, Rapism,
                    Terrorism, Women Oppression, History, Other/generic)</li>
                <li>Details of task: Islamophobia</li>
                <li>Size of dataset: 1,071</li>
                <li>Percentage abusive: 1</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Synthetic / Facebook</li>
                <li>Medium: Text</li>
                <li>Reference: Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives
                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:
                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,
                    Italy: Association for Computational Linguistics, pp.2819-2829.</li>
            </ul>

            <h4 id="creating-a-whatsapp-dataset-to-study-pre-teen-cyberbullying">Creating a WhatsApp Dataset to Study
                Pre-teen Cyberbullying</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5107">https://www.aclweb.org/anthology/W18-5107</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/dhfbk/WhatsApp-Dataset">https://github.com/dhfbk/WhatsApp-Dataset</a>
                </li>
                <li>Task description: Binary (Cyberbullying, Not)</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 14,600</li>
                <li>Percentage abusive: 0.08</li>
                <li>Language: Italian</li>
                <li>Level of annotation: Posts, structured into 10 chats, with token level information</li>
                <li>Platform: Synthetic / Whatsapp</li>
                <li>Medium: Text</li>
                <li>Reference: Sprugnoli, R., Menini, S., Tonelli, S., Oncini, F. and Piras, E., 2018. Creating a
                    WhatsApp Dataset to Study Pre-teen Cyberbullying. In: Proceedings of the 2nd Workshop on Abusive
                    Language Online (ALW2) Month: October. Brussels, Belgium: Association for Computational Linguistics,
                    pp.51-59.</li>
            </ul>

            <p><a id="Polish-header"></a></p>
            <h3 id="polish">Polish</h3>
            <h4
                id="results-of-the-poleval-2019-shared-task-6first-dataset-and-open-shared-task-for-automatic-cyberbullying-detection-in-polish-twitter">
                Results of the PolEval 2019 Shared Task 6:First Dataset and Open Shared Task for Automatic Cyberbullying
                Detection in Polish Twitter</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://poleval.pl/files/poleval2019.pdf">http://poleval.pl/files/poleval2019.pdf</a></li>
                <li>Link to data: <a href="http://poleval.pl/tasks/task6">http://poleval.pl/tasks/task6</a></li>
                <li>Task description: Harmfulness score (three values), Multilabel from seven phenomena</li>
                <li>Details of task: Person-directed</li>
                <li>Size of dataset: 10,041</li>
                <li>Percentage abusive: 0.09</li>
                <li>Language: Polish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Ogrodniczuk, M. and Kobyli≈Ñski, L., 2019. Results of the PolEval 2019 Shared Task 6:
                    First Dataset and Open Shared Task for Automatic Cyberbullying Detection in Polish Twitter. In:
                    Proceedings of the PolEval 2019 Workshop. Warszawa: Institute of Computer Science, Polish Academy of
                    Sciences.</li>
            </ul>

            <p><a id="Portuguese-header"></a></p>
            <h3 id="portuguese">Portuguese</h3>

            <h4 id="toxic-language-dataset-for-brazilian-portuguese-told-br">Toxic Language Dataset for Brazilian
                Portuguese (ToLD-Br)</h4>
            <ul>
                <li>Link to publication: https://arxiv.org/abs/2010.04543</li>
                <li>Link to data: https://github.com/JAugusto97/ToLD-Br</li>
                <li>Task description: Multiclass (LGBTQ+phobia, Insult, Xenophobia, Misogyny, Obscene, Racism)</li>
                <li>Details of task: Three annotators per example, demographically diverse selected annotators.</li>
                <li>Size of dataset: 21.000</li>
                <li>Percentage abusive: 44%</li>
                <li>Language: Portuguese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Jo√£o A. Leite, Diego F. Silva, Kalina Bontcheva, Carolina Scarton (2020): Toxic Language
                    Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis.
                    AACL-IJCNLP 2020</li>
            </ul>

            <h4 id="a-hierarchically-labeled-portuguese-hate-speech-dataset">A Hierarchically-Labeled Portuguese Hate
                Speech Dataset</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W19-3510">https://www.aclweb.org/anthology/W19-3510</a>
                </li>
                <li>Link to data: <a
                        href="https://b2share.eudat.eu/records/9005efe2d6be4293b63c3cffd4cf193e">https://b2share.eudat.eu/records/9005efe2d6be4293b63c3cffd4cf193e</a>
                </li>
                <li>Task description: Binary (Hate, Not), Multi-level (81 categories, identified inductively; categories
                    have different granularities and content can be assigned to multiple categories at once)</li>
                <li>Details of task: Multiple identities inductively categorized</li>
                <li>Size of dataset: 3,059</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: Portuguese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fortuna, P., Rocha da Silva, J., Soler-Company, J., Warner, L. and Nunes, S., 2019. A
                    Hierarchically-Labeled Portuguese Hate Speech Dataset. In: Proceedings of the Third Workshop on
                    Abusive Language Online. Florence, Italy: Association for Computational Linguistics, pp.94-104.</li>
            </ul>

            <h4 id="offensive-comments-in-the-brazilian-web-a-dataset-and-baseline-results">Offensive Comments in the
                Brazilian Web: A Dataset and Baseline Results</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://www.each.usp.br/digiampietri/BraSNAM/2017/p04.pdf">http://www.each.usp.br/digiampietri/BraSNAM/2017/p04.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/rogersdepelle/OffComBR">https://github.com/rogersdepelle/OffComBR</a>
                </li>
                <li>Task description: Binary (Offensive, Not), Target (Xenophobia, homophobia, sexism, racism, cursing,
                    religious intolerance)</li>
                <li>Details of task: Religion/creed, Race/ethnicity, Physical/disability, Gender/sexual orientation</li>
                <li>Size of dataset: 1,250</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Portuguese</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: g1.globo.com</li>
                <li>Medium: Text</li>
                <li>Reference: de Pelle, R. and Moreira, V., 2017. Offensive Comments in the Brazilian Web: A Dataset
                    and Baseline Results. In: VI Brazilian Workshop on Social Network Analysis and Mining. SBC.</li>
            </ul>

            <p><a id="Russian-header"></a></p>
            <h3 id="russian">Russian</h3>
            <h4 id="reducing-unintended-identity-bias-in-russian-hate-speech-detection">Reducing Unintended Identity
                Bias in Russian Hate Speech Detection</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2020.alw-1.8.pdf">https://aclanthology.org/2020.alw-1.8.pdf</a>
                </li>
                <li>Link to data: License Required (Last checked 17/01/2022)</li>
                <li>Task description: Binary (Hate, Not)</li>
                <li>Details of task: Toxicity, Harassment, Sexism, Homophobia, Nationalism</li>
                <li>Size of dataset: 100,000</li>
                <li>Percentage abusive: NA</li>
                <li>Language: Russian</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Zueva, Nadezhda, et al, Oct. 2020. Reducing Unintended Identity Bias in Russian Hate
                    Speech Detection. In: Proceedings of the Fourth Workshop on Online Abuse and Harms, pages 65‚Äì69</li>
            </ul>

            <h4 id="detection-of-abusive-speech-for-mixed-sociolects-of-russian-and-ukrainian-languages">Detection of
                Abusive Speech for Mixed Sociolects of Russian and Ukrainian Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf">https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bohdan1/AbusiveLanguageDataset">https://github.com/bohdan1/AbusiveLanguageDataset</a>
                </li>
                <li>Task description: Binary (True == Abusive, False == Not)</li>
                <li>Details of task: Multilingual, Abusive Words, Political</li>
                <li>Size of dataset: 2,000</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Surzhyk (Russian &amp; Ukranian)</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Andrusyak, B., Rimel, M. and Kern, R., 2018. Detection of Abusive Speech for Mixed
                    Sociolects of Russian and Ukrainian Languages. In: Proceedings of Recent Advances in Slavonic
                    Natural Language Processing, RASLAN 2018, pp. 77‚Äì84, 2018.</li>
            </ul>

            <h4 id="russian-south-park">Russian South Park</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://aclanthology.org/2021.bsnlp-1.3/">https://aclanthology.org/2021.bsnlp-1.3/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/Sariellee/Russan-Hate-speech-Recognition">https://github.com/Sariellee/Russan-Hate-speech-Recognition</a>
                </li>
                <li>Task description: Binary (abusive, non-abusive)</li>
                <li>Details of task: Abusive language in Russian South Park scripts</li>
                <li>Size of dataset: 1400</li>
                <li>Percentage abusive: 22.2%</li>
                <li>Language: Russian</li>
                <li>Level of annotation: Sentence</li>
                <li>Platform: TV Subtitles</li>
                <li>Medium: text</li>
                <li>Reference: Saitov &amp; Derczynski, 2021. ‚ÄúAbusive Language Recognition in Russian‚Äù. Proceedings of
                    the 8th BSNLP Workshop on Balto-Slavic Natural Language Processing, ACL</li>
            </ul>

            <p><a id="Slovene-header"></a></p>
            <h3 id="slovene">Slovene</h3>
            <h4 id="datasets-of-slovene-and-croatian-moderated-news-comments-1">Datasets of Slovene and Croatian
                Moderated News Comments</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/W18-5116">https://www.aclweb.org/anthology/W18-5116</a>
                </li>
                <li>Link to data: <a href="http://hdl.handle.net/11356/1201">http://hdl.handle.net/11356/1201</a></li>
                <li>Task description: Binary (Deleted, Not)</li>
                <li>Details of task: Flagged content</li>
                <li>Size of dataset: 7,600,000</li>
                <li>Percentage abusive: 0.08</li>
                <li>Language: Slovene</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: MMC RTV website</li>
                <li>Medium: Text</li>
                <li>Reference: Ljube≈°iƒá, N., Erjavec, T. and Fi≈°er, D., 2018. Datasets of Slovene and Croatian Moderated
                    News Comments. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2). Brussels,
                    Belgium: Association for Computational Linguistics, pp.124-131.</li>
            </ul>

            <p><a id="Spanish-header"></a></p>
            <h3 id="spanish">Spanish</h3>
            <h4
                id="overview-of-mex-a3t-at-ibereval-2018-authorship-and-aggressiveness-analysis-in-mexican-spanish-tweets">
                Overview of MEX-A3T at IberEval 2018: Authorship and Aggressiveness Analysis in Mexican Spanish Tweets
            </h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2150/overview-mex-a3t.pdf">http://ceur-ws.org/Vol-2150/overview-mex-a3t.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://mexa3t.wixsite.com/home/aggressive-detection-track">https://mexa3t.wixsite.com/home/aggressive-detection-track</a>
                </li>
                <li>Task description: Binary (Aggressive, Not)</li>
                <li>Details of task: Group-directed</li>
                <li>Size of dataset: 11,000</li>
                <li>Percentage abusive: 0.32</li>
                <li>Language: Spanish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Alvarez-Carmona, M., Guzman-Falcon, E., Montes-y-Gomez, M., Escalante, H.,
                    Villasenor-Pineda, L., Reyes-Meza, V. and Rico-Sulayes, A., 2018. Overview of MEX-A3T at IberEval
                    2018: Authorship and aggressiveness analysis in Mexican Spanish tweets. In: Proceedings of the Third
                    Workshop on Evaluation of Human Language Technologies for Iberian Languages (IberEval 2018).</li>
            </ul>

            <h4 id="overview-of-the-task-on-automatic-misogyny-identification-at-ibereval-2018-spanish">Overview of the
                Task on Automatic Misogyny Identification at IberEval 2018 (Spanish)</h4>
            <ul>
                <li>Link to publication: <a
                        href="http://ceur-ws.org/Vol-2150/overview-AMI.pdf">http://ceur-ws.org/Vol-2150/overview-AMI.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://amiibereval2018.wordpress.com/important-dates/data/">https://amiibereval2018.wordpress.com/important-dates/data/</a>
                </li>
                <li>Task description: Binary (Misogyny, Not), 5 categories (Stereotype, Dominance, Derailing, Sexual
                    harassment, Discredit), Target of misogyny (Active or Passive)</li>
                <li>Details of task: Sexism</li>
                <li>Size of dataset: 4,138</li>
                <li>Percentage abusive: 0.5</li>
                <li>Language: Spanish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Fersini, E., Rosso, P. and Anzovino, M., 2018. Overview of the Task on Automatic Misogyny
                    Identification at IberEval 2018. In: Proceedings of the Third Workshop on Evaluation of Human
                    Language Technologies for Iberian Languages (IberEval 2018).</li>
            </ul>

            <h4
                id="hateval-semeval-2019-task-5-multilingual-detection-of-hate-speech-against-immigrants-and-women-in-twitter-spanish">
                hatEval, SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in
                Twitter (Spanish)</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/S19-2007">https://www.aclweb.org/anthology/S19-2007</a>
                </li>
                <li>Link to data: <a
                        href="competitions.codalab.org/competitions/19935">competitions.codalab.org/competitions/19935</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),
                    Within Hate (Agressive, Not)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 6,600</li>
                <li>Percentage abusive: 0.4</li>
                <li>Language: Spanish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Pardo, F., Rosso, P. and
                    Sanguinetti, M., 2019. SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants
                    and Women in Twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation.
                    Minneapolis, Minnesota: Association for Computational Linguistics, pp.54-63.</li>
            </ul>

            <p><a id="Turkish-header"></a></p>
            <h3 id="turkish">Turkish</h3>
            <h4 id="a-corpus-of-turkish-offensive-language-on-social-media">A Corpus of Turkish Offensive Language on
                Social Media</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://coltekin.github.io/offensive-turkish/troff.pdf">https://coltekin.github.io/offensive-turkish/troff.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://sites.google.com/site/offensevalsharedtask/home">https://sites.google.com/site/offensevalsharedtask/home</a>
                </li>
                <li>Task description: Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),
                    Within Hate (Agressive, Not)</li>
                <li>Details of task: Group-directed + Person-directed</li>
                <li>Size of dataset: 36232</li>
                <li>Percentage abusive: 0.19</li>
                <li>Language: Turkish</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: √á√∂ltekin, C., 2020. A Corpus of Turkish Offensive Language on Social Media. In:
                    Proceedings of the 12th International Conference on Language Resources and Evaluation.</li>
                <li>Dataset reader: ü§ó <a
                        href="https://huggingface.co/datasets/strombergnlp/offenseval_2020">strombergnlp/offenseval_2020</a>
                </li>
            </ul>

            <p><a id="Ukranian-header"></a></p>
            <h3 id="ukranian">Ukranian</h3>
            <h4 id="detection-of-abusive-speech-for-mixed-sociolects-of-russian-and-ukrainian-languages-1">Detection of
                Abusive Speech for Mixed Sociolects of Russian and Ukrainian Languages</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf">https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/bohdan1/AbusiveLanguageDataset">https://github.com/bohdan1/AbusiveLanguageDataset</a>
                </li>
                <li>Task description: Binary (True == Abusive, False == Not)</li>
                <li>Details of task: Multilingual, Abusive Words, Political</li>
                <li>Size of dataset: 2,000</li>
                <li>Percentage abusive: 0.33</li>
                <li>Language: Surzhyk (Russian &amp; Ukranian)</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Youtube</li>
                <li>Medium: Text</li>
                <li>Reference: Andrusyak, B., Rimel, M. and Kern, R., 2018. Detection of Abusive Speech for Mixed
                    Sociolects of Russian and Ukrainian Languages. In: Proceedings of Recent Advances in Slavonic
                    Natural Language Processing, RASLAN 2018, pp. 77‚Äì84, 2018.</li>
            </ul>

            <p><a id="Urdu-header"></a></p>
            <h3 id="urdu">Urdu</h3>
            <h4 id="hate-speech-and-offensive-language-detection-in-roman-urdu">Hate-Speech and Offensive Language
                Detection in Roman Urdu</h4>
            <ul>
                <li>Link to publication: <a
                        href="https://www.aclweb.org/anthology/2020.emnlp-main.197/">https://www.aclweb.org/anthology/2020.emnlp-main.197/</a>
                </li>
                <li>Link to data: <a
                        href="https://github.com/haroonshakeel/roman_urdu_hate_speech">https://github.com/haroonshakeel/roman_urdu_hate_speech</a>
                </li>
                <li>Task description: There are 2 subtasks, Coarse-grained Classification(Hate-Offensive vs Normal) and
                    Fine-grained classification( Abusive/Offensive, Sexism, Religious Hate, Profane, Normal)</li>
                <li>Details of task: Binary classification + Hate-Offensive label is further broken down into 4
                    fine-grained labels</li>
                <li>Size of dataset: 10041</li>
                <li>Percentage abusive: 0.24%</li>
                <li>Language: Urdu-English</li>
                <li>Level of annotation: Posts</li>
                <li>Platform: Twitter</li>
                <li>Medium: Text</li>
                <li>Reference: Hammad Rizwan, Muhammad Haroon Shakeel, and Asim Karim. 2020. Hate-speech and offensive
                    language detection in Roman Urdu. In Proceedings of the 2020 Conference on Empirical Methods in
                    Natural Language Processing (EMNLP), pages 2512‚Äì2522, Online. Association for Computational
                    Linguistics.</li>
            </ul>