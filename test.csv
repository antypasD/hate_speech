name,pub,data,desc,details,size,percentage,language,annotation,platform,medium,ref
Detecting Abusive Albanian,"Link to publication: https://arxiv.org/abs/2107.13592
"," https://doi.org/10.6084/m9.figshare.19333298.v1
", Hierarchical (offensive/not; untargeted/targeted; person/group/other), Detect and categorise abusive language in social media data,11874, 13.2, Albanian, Posts," Instagram, Youtube", Text," Nurce, E., Keci, J., Derczynski, L., 2021. Detecting Abusive Albanian. arXiv:2107.13592

                "
Are They our Brothers? Analysis and Detection of Religious Hate Speech in the Arabic Twittersphere,"Link to publication: https://ieeexplore.ieee.org/document/8508247
"," https://github.com/nuhaalbadi/Arabic_hatespeech
"," Binary (Hate, Not)", Religious subcategories,6136, 0.45, Arabic, Posts, Twitter, Text," Albadi, N., Kurdi, M. and Mishra, S., 2018. Are they Our Brothers? Analysis and Detection

                    of Religious Hate Speech in the Arabic Twittersphere. In: International Conference on Advances in

                    Social Networks Analysis and Mining. Barcelona, Spain: IEEE, pp.69-76."
Multilingual and Multi-Aspect Hate Speech                  Analysis (Arabic),"Link to publication: https://arxiv.org/abs/1908.11049
"," https://github.com/HKUST-KnowComp/MLMA_hate_speech
"," Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target

                    Attribute, Target Group, How annotators felt on seeing the tweet."," Gender, Sexual orientation, Religion, Disability",3353, 0.64, Arabic, Posts, Twitter, Text," Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and

                    Multi-Aspect Hate Speech Analysis. ArXiv,."
L-HSAB: A Levantine Twitter                  Dataset for Hate Speech and Abusive Language,"Link to publication: https://www.aclweb.org/anthology/W19-3512
"," https://github.com/Hala-Mulki/L-HSAB-First-Arabic-Levantine-HateSpeech-Dataset
"," Ternary (Hate, Abusive, Normal)", Group-directed + Person-directed,5846, 0.38, Arabic, Posts, Twitter, Text," Mulki, H., Haddad, H., Bechikh, C. and Alshabani, H., 2019. L-HSAB: A Levantine Twitter

                    Dataset for Hate Speech and Abusive Language. In: Proceedings of the Third Workshop on Abusive

                    Language Online. Florence, Italy: Association for Computational Linguistics, pp.111-118."
Abusive Language Detection on Arabic                  Social Media (Twitter),"Link to publication: https://www.aclweb.org/anthology/W17-3008
"," http://alt.qcri.org/~hmubarak/offensive/TweetClassification-Summary.xlsx
"," Ternary (Obscene, Offensive but not obscene, Clean)", Incivility,1100, 0.59, Arabic, Posts, Twitter, Text," Mubarak, H., Darwish, K. and Magdy, W., 2017. Abusive Language Detection on Arabic Social

                    Media. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver, Canada:

                    Association for Computational Linguistics, pp.52-56."
Abusive Language Detection on Arabic                  Social Media (Al Jazeera),"Link to publication: https://www.aclweb.org/anthology/W17-3008
"," http://alt.qcri.org/~hmubarak/offensive/AJCommentsClassification-CF.xlsx
"," Ternary (Obscene, Offensive but not obscene, Clean)", Incivility,32000, 0.81, Arabic, Posts, AlJazeera, Text," Mubarak, H., Darwish, K. and Magdy, W., 2017. Abusive Language Detection on Arabic Social

                    Media. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver, Canada:

                    Association for Computational Linguistics, pp.52-56."
Dataset Construction for the Detection of Anti-Social Behaviour in Online Communication in Arabic,"Link to publication: https://www.sciencedirect.com/science/article/pii/S1877050918321756
"," https://onedrive.live.com/?authkey=!ACDXj_ZNcZPqzy0&id=6EF6951FBF8217F9!105&cid=6EF6951FBF8217F9
"," Binary (Offensive, Not)", Incivility,15050, 0.39, Arabic, Posts, YouTube, Text," Alakrot, A., Murray, L. and Nikolov, N., 2018. Dataset Construction for the Detection of

                    Anti-Social Behaviour in Online Communication in Arabic. Procedia Computer Science, 142, pp.174-181.

                "
Hate Speech                  Detection in the Bengali language: A Dataset and its Baseline Evaluation,Link to publication: https://arxiv.org/pdf/2012.09686.pdf," https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset
"," Binary (hateful, not)"," Several categories: sports, entertainment, crime, religion, politics, celebrity and

                    meme",30000, 0.33, Bengali, Posts, Youtube and Facebook, Text," Romim, N., Ahmed, M., Talukder, H., & Islam, M. S. (2021). Hate speech detection in

                    the bengali language: A dataset and its baseline evaluation. In Proceedings of International Joint

                    Conference on Advances in Computational Intelligence (pp. 457-468). Springer, Singapore."
SWSR: A Chinese Dataset and Lexicon                  for Online Sexism Detection,"Link to publication: https://www.sciencedirect.com/science/article/abs/pii/S2468696421000604#fn1
", https://doi.org/10.5281/zenodo.4773875," Binary (Sexist, Non-sexist), Categories of sexism (Stereotype based on Appearance,

                    Stereotype based on Cultural Background, MicroAggression, and Sexual Offense), Target of sexism

                    (Individual or Generic)", Sexism detection on social media in Chinese,8969commentsfrom1527weibos, 34.5, Chinese, Posts, Sina Weibo, Text," Aiqi Jiang, Xiaohan Yang, Yang Liu, Arkaitz Zubiaga, SWSR: A Chinese dataset and lexicon

                    for online sexism detection, Online Social Networks and Media, Volume 27, 2022, 100182, ISSN

                    2468-6964."
Datasets of Slovene and Croatian Moderated                  News Comments,"Link to publication: https://www.aclweb.org/anthology/W18-5116
", http://hdl.handle.net/11356/1202," Binary (Deleted, Not)", Flagged content,17000000, 0.02, Croatian, Posts, 24sata website, Text," Ljubešić, N., Erjavec, T. and Fišer, D., 2018. Datasets of Slovene and Croatian Moderated

                    News Comments. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2). Brussels,

                    Belgium: Association for Computational Linguistics, pp.124-131."
Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian,"Link to publication: https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf
"," https://www.clarin.si/repository/xmlui/handle/11356/1399
", Multi-class based on Different rules, Flagged content performmed by the real newspaper moderators,21M, 7.8, Croatian, Posts, Newspaper comments, Text," Ravi Shekhar, Marko Pranjić, Senja Pollak, Andraž Pelicon, Matthew Purver (2020).

                    Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian.

                    Journal for Language Technology and Computational Linguistics (JLCL)."
Offensive Language and Hate Speech                  Detection for Danish,"Link to publication: http://www.derczynski.com/papers/danish_hsd.pdf
"," https://figshare.com/articles/Danish_Hate_Speech_Abusive_Language_data/12220805
"," Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,

                    Not), Within Target (Individual, Group, Other)", Group-directed + Person-directed,3600, 0.12, Danish, Posts," Twitter, Reddit, newspaper comments", Text," Sigurbergsson, G. and Derczynski, L., 2019. Offensive Language and Hate Speech Detection

                    for Danish. ArXiv."
BAJER: Misogyny in Danish,"Link to publication: https://aclanthology.org/2021.acl-long.247/
"," request

                        here", Hierarchy of abusive content labels including subcategories of misogyny, “Misogyny detection on social media in Danish”,27.9Kcomments," 7% misogynistic, 27% abusive (i.e. 20% abusive but not misogyny)", Danish, Social media post / comment," Twitter, Facebook, Reddit", text," Zeinert, Inie, & Derczynski, 2021. “Annotating Online Misogyny”. Proceedings of the

                    59th Annual Meeting of the Association for Computational Linguistics and the 11th International

                    Joint Conference on Natural Language Processing, ACL"
The Dutch Abusive Language Corpus v1.0 (DALC v1.0),"Link to publication: https://aclanthology.org/2021.woah-1.6.pdf

                    - link to the documentation and/or a data statement about the data"," https://github.com/tommasoc80/DALC
", Multilayered (explicitness and target) for abusive language, Abusive language detection in social media in Dutch,8156tweets, 15.06% explicitly abusive; 8.09% implicitly abusive, Dutch, tweets, Twitter, text," Caselli, T., Schelhaas, A., Weultjes, M., Leistra, F., van der Veen, H., Timmerman, G.,

                    and Nissim, M. 2021. “DALC: the Dutch Abusive Language Corpus”. Proceedings of the 5th Workshop on

                    Online Abuse and Harms (WOAH 2021), ACL."
ConvAbuse,"Link to publication: https://aclanthology.org/2021.emnlp-main.587/
"," https://github.com/amandacurry/convabuse
"," Hierarchical: 1. Abuse binary, Abuse severity 1,0,-1,-2,-3; 2.

                    Directedness explicit, implicit Target group, individual–system,

                    individual–3rd party, Type general, sexist, sexual harassment, homophobic, racist,

                    transphobic, ableist,

                    intellectual", Abuse detection in conversational AI,4185, c. 20, English, utterance (with conversational context), Carbonbot on Facebook Messenger and E.L.I.Z.A. chatbots, text," Curry, A. C., Abercrombie, G., & Rieser, V. 2021. ConvAbuse: Data, Analysis, and

                    Benchmarks for Nuanced Detection in Conversational AI. In Proceedings of the 2021 Conference on

                    Empirical Methods in Natural Language Processing (pp. 7388-7403)."
Measuring Hate Speech,"Link to publication: https://arxiv.org/abs/2009.10277
"," https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech
"," 10 ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status,

                    violence, dehumanization, genocide, attack/defense, hate speech), which are debiased and aggregated

                    into a continuous hate speech severity score (hate_speech_score) that includes a region for

                    counterspeech & supportive speeech. Includes 8 target identity groups (race/ethnicity, religion,

                    national origin/citizenship, gender, sexual orientation, age, disability, political ideology) and 42

                    identity subgroups.", Hate speech measurement on social media in English,"39565commentsannotatedby7912annotatorson10ordinallabelsfor1355560

totallabels."," 25% - however this dichotomization is not in the spirit of the paper/dataset

                ", English, Social media comment," Twitter, Reddit, YouTube", Text," Kennedy, C. J., Bacon, G., Sahn, A., & von Vacano, C. (2020). Constructing interval

                    variables via faceted Rasch measurement and multitask deep learning: a hate speech application.

                    arXiv preprint arXiv:2009.10277."
Learning From the Worst                  (Dynamically generated hate speech dataset),"Link to publication: https://aclanthology.org/2021.acl-long.132/
"," https://github.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset
", Multi-category hate speech detection," Hate detection with fine-grained labels for the type and target of hate. Generated

                    over 4 rounds of human-and-model-in-the-loop adversarial data generation. Collected through Dynabench.",41255, 54, English, posts, Synthetically generated by humans to mimic real-world social media posts, text," Vidgen, B., Thurush, T., Waseem, Z., Kiela, D., 2021. Learning from the worst:

                    dynamically generated datasets to improve online hate detection. In Proceedings of the 59th Meeting

                    of the Association for Computational Lingusitics (pp. 1667-1682)."
"The ‘Call me sexist, but’ sexism dataset","Link to publication: https://ojs.aaai.org/index.php/ICWSM/article/view/18085/17888
", https://doi.org/10.7802/2251, Sexism detection based on content and phrasing," Sexism detection on English social media data informed by survey items measuring

                    sexist attitudes and adversarial examples",6325, 28, English, tweets and survey items," Twitter, Social Psychology scales", text," Samory, M., Sen, I., Kohne, J., Flöck, F. and Wagner, C., 2021, May. Call me sexist,

                    but…: Revisiting sexism detection using psychological scales and adversarial samples. In Intl AAAI

                    Conf. Web and Social Media (pp. 573-584)."
Hate Towards the Political Opponent: A Twitter Corpus Study of the 2020 US Elections on the Basis of                  Offensive Speech and Stance Detection__,"Link to publication: https://aclanthology.org/2021.wassa-1.18/
"," https://www.ims.uni-stuttgart.de/data/stance_hof_us2020
", Hate / Offensive or neither," Data collected to be Twitter by supporters of Trump

                    or Biden",3000, 12, English, Posts, Twitter, Text," Lara Grimminger and Roman Klinger (2020): Hate Towards the Political Opponent: A Twitter

                    Corpus Study of the 2020 US Elections on the Basis of Offensive Speech and Stance Detection. 11th

                    Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis

                    (collocated with EACL 2021)."
AbuseEval v1.0,"Link to publication: http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.760.pdf
", https://github.com/tommasoc80/AbuseEval, Explicitness annotation of offensive and abusive content," Enriched versions of the OffensEval/OLID dataset with the distinction of

                    explicit/implicit offensive messages and the new dimension for abusive messages. Labels for

                    offensive language: EXPLICIT, IMPLICT, NOT; Labels for abusive language: EXPLICIT, IMPLICT, NOTABU

                ",14100, 20.75, English, tweets, Twitter, text," Caselli, T., Basile, V., Jelena, M., Inga, K., and Michael, G. 2020. “I feel offended,

                    don’t be abusive! implicit/explicit messages in offensive and abusive language”. The 12th Language

                    Resources and Evaluation Conference (pp. 6193-6202). European Language Resources Association."
Do You Really Want to                  Hurt Me? Predicting Abusive Swearing in Social Media,"Link to publication: https://www.aclweb.org/anthology/2020.lrec-1.765.pdf
"," https://github.com/dadangewp/SWAD-Repository
"," Binary (abusive swear word, non-abusive swear word)", Abusive swearing,1511swearwords(1675tweets)," 0.41% (word level), 0.51% (post level)", English, Words, Twitter, Text," Pamungkas, E. W., Basile, V., & Patti, V. (2020). Do you really want to hurt me?

                    predicting abusive swearing in social media. In The 12th Language Resources and Evaluation

                    Conference (pp. 6237-6246). European Language Resources Association."
Multimodal                  Meme Dataset (MultiOFF) for Identifying Offensive Content in Image and Text,"Link to publication: https://www.aclweb.org/anthology/2020.trac-1.6.pdf
"," https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text
"," Binary (offensive, non-offensive)", Hate per se (related to 2016 U.S. presidential election),743, 0.41, English, Posts," Kaggle, Reddit, Facebook, Twitter and Instagram", Text and Images/memes," Suryawanshi, S., Chakravarthi, B. R., Arcan, M., & Buitelaar, P. (2020, May).

                    Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text. In

                    Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying (pp. 32-41)."
Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based                  Hate,"Link to publication: https://arxiv.org/abs/2108.05921
", https://github.com/HannahKirk/Hatemoji," Branching structure of tasks: Binary (Hate, Not Hate), Within Hate (Type, Target)

                "," Hate speech detection for text statements including emoji, consisting of a

                    checklist-based test suite (HatemojiCheck) and an adversarially-generated dataset (HatemojiBuild)

                ",HatemojiCheck=3930;HatemojiBuild=5912.," HatemojiCheck = 69%, HatemojiBuild = 50", English, Post, Synthetically-Generated, Text with emoji," Kirk, H. R., Vidgen, B., Röttger, P., Thrush, T., & Hale, S. A. 2021. Hatemoji: A

                    test suite and adversarially-generated dataset for benchmarking and detecting emoji-based hate.

                    arXiv preprint arXiv:2108.05921."
HateCheck: Functional Tests for Hate                  Speech Detection Models,Link to publication: https://arxiv.org/pdf/2012.15606.pdf," https://github.com/paul-rottger/hatecheck-data
"," Binary (Hate, Not Hate), 7 Targets Within Hate (Women, Trans people, Black people,

                    Gay people, Disabled people, Muslims, Immigrants)", A checklist of functional tests to evaluate hate speech detection models.,3728, 68, English, Post, Synthetically-Generated, Text," Röttger, P., Vidgen, B., Nguyen, D., Waseem, Z., Margetts, H. and Pierrehumbert, J.,

                    2020. Hatecheck: Functional tests for hate speech detection models. arXiv preprint arXiv:2012.15606.

                "
Semeval-2021 Task 5: Toxic Spans Detection,"Link to publication: https://aclanthology.org/2021.semeval-1.6.pdf
"," https://github.com/ipavlopoulos/toxic_spans
"," Binary toxic spans (toxic, non-toxic) & reading comprehension"," Predict the spans of toxic posts that were responsible for the toxic label of the

                    posts.",10629, 0.56, English, Posts, Civil Comments, Text," Pavlopoulos, J., Sorensen, J., Laugier, L., & Androutsopoulos, I. (2021, August).

                    Semeval-2021 task 5: Toxic spans detection. In Proceedings of the 15th International Workshop on

                    Semantic Evaluation (SemEval-2021) (pp. 59-69)."
Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate                  Speech,"Link to publication: https://aclanthology.org/2021.acl-long.250.pdf
", https://github.com/marcoguerini/CONAN," Binary (hateful, not)"," race, religion, country of origin, sexual orientation, disability, gender",5003, 1, English, Posts, Semi-synthetic text, Text," Margherita Fanton, Helena Bonaldi, Serra Sinem Tekiroğlu, Marco Guerini Human-in-the-Loop

                    for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech In

                    Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics: Long

                    Papers."
HateXplain: A Benchmark                  Dataset for Explainable Hate Speech Detection,"Link to publication: https://arxiv.org/abs/2012.10289
", https://github.com/punyajoy/HateXplain," Level of hate (hate, offensive or normal), on target groups (race, religion,

                    gender, sexual orientation, miscellaneous), and rationales", Hate per se,20148, 0.57, English," Words, phrases, posts", Twitter and Gab, Text," Mathew, B., Saha, P., Yimam, S. M., Biemann, C., Goyal, P., & Mukherjee, A. (2021,

                    May). HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection. In Proceedings of the

                    AAAI Conference on Artificial Intelligence (Vol. 35, No. 17, pp. 14867-14875)."
ALONE: A Dataset for Toxic Behavior                  among Adolescents on Twitter,Link to publication: https://arxiv.org/pdf/2008.06465.pdf," Data made available upon request, please email Ugur Kursuncu ugur@gsu.edu and

                    thilini@sc.edu thilini@sc.edu."," Binary (Toxic, Non-Toxic)"," Annotates interactions (Tweets and their replies), and assigns keywords describing

                    use of emojis, URL content and images.",688, 0.17, English, Post, Twitter," Multimodal (text, images, emojis, metadata)"," Wijesiriwardene, T., Inan, H., Kursuncu, U., Gaur, M., Shalin, V., Thirunarayan, K.,

                    Sheth, A. and Arpinar, I., 2020, Arxiv."
Towards a                  Comprehensive Taxonomy and Large-Scale Annotated Corpus for Online Slur Usage,"Link to publication: https://www.aclweb.org/anthology/2020.alw-1.17.pdf
"," https://github.com/networkdynamics/slur-corpus
"," 4 primary categories (derogatory, appropriate, non-derogatory/non-appropriate,

                    homonyms, noise)", Hate per se,39811, 0.52, English, Posts, Reddit, Text," Kurrek, J., Saleem, H. M., & Ruths, D. (2020, November). Towards a comprehensive

                    taxonomy and large-scale annotated corpus for online slur usage. In Proceedings of the Fourth

                    Workshop on Online Abuse and Harms (pp. 138-149)."
Multimodal                  Meme Dataset (MultiOFF) for Identifying Offensive Content in Image and Text,"Link to publication: https://www.aclweb.org/anthology/2020.trac-1.6.pdf
"," https://www.aclweb.org/anthology/2020.trac-1.6.pdf
"," Binary (offensive, non-offensive)", Hate per se (related to 2016 U.S. presidential election),743, 0.41, English, Posts," Kaggle, Reddit, Facebook, Twitter and Instagram", Text and Images/memes," Suryawanshi, S., Chakravarthi, B. R., Arcan, M., & Buitelaar, P. (2020, May).

                    Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text. In

                    Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying (pp. 32-41)."
Predicting the Type and Target of                  Offensive Posts in Social Media,Link to publication: https://aclanthology.org/N19-1144.pdf," https://scholar.harvard.edu/malmasi/olid
"," Branching structure of tasks. A: offensive / not, B: targeted insult / untargeted,

                    C: individual, group, other.", Hate per se,14100, 0.33, English, Posts, Twitter, Text," Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., & Kumar, R. (2019,

                    June). Predicting the Type and Target of Offensive Posts in Social Media. In Proceedings of the 2019

                    Conference of the North American Chapter of the Association for Computational Linguistics: Human

                    Language Technologies, Volume 1 (Long and Short Papers) (pp. 1415-1420)."
Nuanced                  metrics for measuring unintended bias with real data for text classification,Link to publication: https://arxiv.org/pdf/1903.04561.pdf," https://www.tensorflow.org/datasets/catalog/civil_comments
"," Toxicity (severe, obscene, threat, insult, identity attack, sexual explicit), and

                    several identity attributes (e.g., gender, religion and race)", Hate per se,1804875, 0.8, English, Comments/posts, Civil Comments, Text," Borkan, D., Dixon, L., Sorensen, J., Thain, N., & Vasserman, L. (2019, May). Nuanced

                    metrics for measuring unintended bias with real data for text classification. In Companion

                    proceedings of the 2019 world wide web conference (pp. 491-500)."
Introducing CAD: the Contextual Abuse Dataset,"Link to publication: https://aclanthology.org/2021.naacl-main.182.pdf
"," https://zenodo.org/record/4881008#.Ye6OwhP7R6o
"," Contextually abusive language, person-directed + group-directed"," Primary categories (secondary categories): Abusive + Identity-directed

                    (derogation/animosity/threatening/glorification/dehumanization), Abusive + Person-directed

                    (derogation/animosity/threatening/glorification/dehumanization), Abusive + Affiliation directed

                    (abuse to them/abuse about them), Counter Speech (against identity-directed abuse/against

                    affiliation-directed abuse/against person-directed abuse), Non-hateful Slurs and Neutral.",25000," Affiliation-directed, 6%; Identity-directed, 13%; Person-directed, 5", English, Conversation thread, Reddit, Text," Vidgen, B., Nguyen, D., Margetts, H., Rossini, P., and Troble, R., Introducing CAD: the

                    Contextual Abuse Dataset, 2021, In: Proceedings of the 2021 Conference of the North American Chapter

                    of the Association for Computational Linguistics: Human Language Technologies, pp.2289–2303"
Automated Hate Speech                  Detection and the Problem of Offensive Language,Link to publication: [https://ojs.aaai.org/index.php/ICWSM/article/view/14955)," https://github.com/t-davidson/hate-speech-and-offensive-language
"," Hierarchy (Hate, Offensive, Neither)", Hate per se,24802, 0.06, English, Posts, Twitter, Text," Davidson, T., Warmsley, D., Macy, M., & Weber, I. 2017. Automated Hate Speech

                    Detection and the Problem of Offensive Language. Proceedings of the International AAAI Conference on

                    Web and Social Media, 11(1), 512-515."
Hate Speech Dataset from a White Supremacy Forum,"Link to publication: https://www.aclweb.org/anthology/W18-5102.pdf
"," https://github.com/Vicomtech/hate-speech-dataset
"," Ternary (Hate, Relation, Not)", Hate per se,9916, 0.11, English, Sentence - with context of the converstaional thread taken into account, Stormfront, Text," de Gibert, O., Perez, N., García-Pablos, A., and Cuadros, M., 2018. Hate Speech Dataset

                    from a White Supremacy Forum. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2).

                    Brussels, Belgium: Association for Computational Linguistics, pp.11-20."
Hateful                  Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter,"Link to publication: https://www.aclweb.org/anthology/N16-2013
", https://github.com/ZeerakW/hatespeech," 3-topic (Sexist, Racist, Not)"," Racism, Sexism",16914, 0.32, English, Posts, Twitter, Text," Waseem, Z. and Horvy, D., 2016. Hateful Symbols or Hateful People? Predictive Features

                    for Hate Speech Detection on Twitter. In: Proceedings of the NAACL Student Research Workshop. San

                    Diego, California: Association for Computational Linguistics, pp.88-93."
Detecting Online Hate Speech Using Context                  Aware Models,Link to publication: https://arxiv.org/pdf/1710.07395.pdf," https://github.com/sjtuprog/fox-news-comments
", Binary (Hate / not), Hate per se,1528, 0.28, English, Posts, Fox News, Text," Gao, L. and Huang, R., 2018. Detecting Online Hate Speech Using Context Aware Models.

                    ArXiv,."
The Gab Hate Corpus: A                  collection of 27k posts annotated for hate speech,Link to publication: https://psyarxiv.com/hqjxn/, https://osf.io/edua3/," Binary (Hate vs. Offensive/Vulgarity), Binary (Assault on human Dignity/Call for

                    Violence – sub task on message delivery, binary: explicit/implicit), Multinomial classification:

                    Identity based hate (race/ethnicity, nationality/regionalism/xenophobia, gender, religion/belief

                    system, sexual orientation, ideology, political identification/party, mental/physical health)", Group-directed + Person-directed,27665," 0.09 Hate, 0.06 Offensive/Vulgar", English, Post, Gab, Text," Kennedy, B., Araria, M., Mostafazadeh Davani, A., Yeh, L., Omrani, A., Kim, Y., Koombs,

                    K., Havaldar, S., Portillo-Wightman, G., Gonzalez, E., Hoover, J., Azatain, A., Hussain, A., Lara,

                    A., Olmos, G., Omary, A., Park, C., Wang, C., Wang, X., Zhang, Y. and Dehghani, M., 2018, The Gab

                    Hate Corpus: A collection of 27k posts annotated for hate speech. PsyArXiv."
Are                  You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter,"Link to publication: https://pdfs.semanticscholar.org/3eeb/b7907a9b94f8d65f969f63b76ff5f643f6d3.pdf
", https://github.com/ZeerakW/hatespeech," Multi-topic (Sexist, Racist, Neither, Both)"," Racism, Sexism",4033, 0.16, English, Posts, Twitter, Text," Waseem, Z., 2016. Are You a Racist or Am I Seeing Things? Annotator Influence on Hate

                    Speech Detection on Twitter. In: Proceedings of 2016 EMNLP Workshop on Natural Language Processing

                    and Computational Social Science. Copenhagen, Denmark: Association for Computational Linguistics,

                    pp.138-142."
When Does a Compliment Become Sexist? Analysis and Classification of Ambivalent Sexism Using Twitter                  Data,"Link to publication: https://pdfs.semanticscholar.org/225f/f8a6a562bbb64b22cebfcd3288c6b930d1ef.pdf
"," https://github.com/AkshitaJha/NLP_CSS_2017
"," Hierarchy of Sexism (Benevolent sexism, Hostile sexism, None)", Sexism,712, 1, English, Posts, Twitter, Text," Jha, A. and Mamidi, R., 2017. When does a Compliment become Sexist? Analysis and

                    Classification of Ambivalent Sexism using Twitter Data. In: Proceedings of the Second Workshop on

                    Natural Language Processing and Computational Social Science. Vancouver, Canada: Association for

                    Computational Linguistics, pp.7-16."
Overview of the                  Task on Automatic Misogyny Identification at IberEval 2018 (English),"Link to publication: http://ceur-ws.org/Vol-2150/overview-AMI.pdf
"," https://amiibereval2018.wordpress.com/im

                        nt-dates/data/"," Binary (misogyny / not), 5 categories (stereotype, dominance, derailing, sexual

                    harassment, discredit), target of misogyny (active or passive)", Sexism,3977, 0.47, English, Posts, Twitter, Text," Fersini, E., Rosso, P. and Anzovino, M., 2018. Overview of the Task on Automatic Misogyny

                    Identification at IberEval 2018. In: Proceedings of the Third Workshop on Evaluation of Human

                    Language Technologies for Iberian Languages (IberEval 2018)."
CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online                  Hate Speech (English),"Link to publication: https://www.aclweb.org/anthology/P19-1271.pdf
", https://github.com/marcoguerini/CONAN," Binary (Islamophobic / not), multi-topic (Culture, Economics, Crimes, Rapism,

                    Terrorism, Women Oppression, History, Other/generic)", Islamophobia,1288, 1, English, Posts, Synthetic / Facebook, Text," Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives

                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:

                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,

                    Italy: Association for Computational Linguistics, pp.2819-2829."
Characterizing and Detecting Hateful Users on                  Twitter,Link to publication: https://arxiv.org/pdf/1803.08977.pdf," https://github.com/manoelhortaribeiro/HatefulUsersTwitter
", Binary (hateful/not), Hate per se,4972, 0.11, English, Users, Twitter, Text," Ribeiro, M., Calais, P., Santos, Y., Almeida, V. and Meira, W., 2018. Characterizing and

                    Detecting Hateful Users on Twitter. ArXiv,."
A Benchmark Dataset for                  Learning to Intervene in Online Hate Speech (Gab),"Link to publication: https://arxiv.org/abs/1909.04251
"," https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech
", Binary (hateful/not), Hate per se,33776, 0.43, English, Posts (in the context of a conversation), Gab, Text," Qian, J., Bethke, A., Belding, E. and Yang Wang, W., 2019. A Benchmark Dataset for

                    Learning to Intervene in Online Hate Speech. ArXiv,."
A Benchmark Dataset for                  Learning to Intervene in Online Hate Speech (Reddit),"Link to publication: https://arxiv.org/abs/1909.04251
"," https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech
", Binary (hateful/not), Hate per se,22324, 0.24, English, Posts (with context of the converstaional thread taken into account), Reddit, Text," Qian, J., Bethke, A., Belding, E. and Yang Wang, W., 2019. A Benchmark Dataset for

                    Learning to Intervene in Online Hate Speech. ArXiv,."
Multilingual and Multi-Aspect Hate                  Speech Analysis (English),"Link to publication: https://arxiv.org/abs/1908.11049
"," https://github.com/HKUST-KnowComp/MLMA_hate_speech
"," Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target

                    attribute and Target group."," Gender, Sexual orientation, Religion, Disability",5647, 0.76, English, Posts, Twitter, Text," Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and

                    Multi-Aspect Hate Speech Analysis. ArXiv,."
Exploring Hate Speech Detection in                  Multimodal Publications,Link to publication: https://arxiv.org/pdf/1910.03814.pdf," https://drive.google.com/file/d/1S9mMhZFkntNnYdO-1dZXwF_8XIiFcmlF/view
"," Multimodal Hate Speech Detection, including six primary categories (No attacks to

                    any community, Racist, Sexist, Homophobic, Religion based attack, Attack to other community)"," Racism, Sexism, Homophobia, Religion-based attack",149823, 0.25, English, Posts, Twitter, Text and Images/Memes," Gomez, R., Gibert, J., Gomez, L. and Karatzas, D., 2020. In Proceedings of the IEEE/CVF

                    winter conference on applications of computer vision (pp. 1470-1478)."
Predicting the Type and Target                  of Offensive Posts in Social Media,Link to publication: https://arxiv.org/pdf/1902.09666.pdf," http://competitions.codalab.org/

                        competitions/20011"," Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,

                    Not), Within Target (Individual, Group, Other)", Group-directed + Person-directed,14100, 0.33, English, Posts, Twitter, Text," Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N. and Kumar, R., 2019.

                    SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval).

                    ArXiv,."
"hatEval, SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in                  Twitter (English)","Link to publication: https://www.aclweb.org/anthology/S19-2007
"," http://competitions.codalab.org/competitions/19935
"," Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),

                    Within Hate (Agressive, Not)", Group-directed + Person-directed,13000, 0.4, English, Posts, Twitter, Text," Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Pardo, F., Rosso, P. and

                    Sanguinetti, M., 2019. SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants

                    and Women in Twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation.

                    Minneapolis, Minnesota: Association for Computational Linguistics, pp.54-63."
Peer to Peer Hate: Hate Speech                  Instigators and Their Targets,"Link to publication: https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17905/16996
"," https://github.com/mayelsherif/hate_speech_icwsm18
"," Binary (Hate/Not), only for tweets which have both a Hate Instigator and Hate

                    Target", Hate per se,27330, 0.98, English, Posts, Twitter, Text," ElSherief, M., Nilizadeh, S., Nguyen, D., Vigna, G. and Belding, E., 2018. Peer to Peer

                    Hate: Hate Speech Instigators and Their Targets. In: Proceedings of the Twelfth International AAAI

                    Conference on Web and Social Media (ICWSM 2018). Santa Barbara, California: University of

                    California, pp.52-61."
Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in                  Indo-European Languages,"Link to publication: https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true
"," https://hasocfire.github.io/hasoc/2019/dataset.html
"," Branching structure of tasks. A: Hate / Offensive or Neither, B: Hatespeech,

                    Offensive, or Profane, C: Targeted or Untargeted", Group-directed + Person-directed,7005, 0.36, English, Posts, Twitter and Facebook, Text," Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.

                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information

                    Retrieval Evaluation,."
Detecting East Asian Prejudice on Social media,"Link to publication: https://www.aclweb.org/anthology/2020.alw-1.19.pdf
", https://zenodo.org/record/3816667," Task 1: Thematic annotation (East Asia/Covid-19) Task 2: Primary category

                    annotation: 1) Hostility against an East Asian (EA) entity 2) Criticism of an East Asian entity 3)

                    Counter speech 5) Discussion of East Asian prejudice 5) Non-related. Task 3: Secondary category

                    annotation (if (1) or (2) - identifying what East Asian entity was targeted + if (1) interpersonal

                    abuse/threatening language/dehumanization).", Detecting East Asian prejudice,20000," 27% (Hostility, 19.5%; Criticism, 7.2%)", English, Post, Twitter, Text," Vidgen, B., Botelho, A., Broniatowski, D., Guest, E., Hall, M., Margetts, H., Tromble,

                    R., Waseem, Z. and Hale, S., Detecting East Asian Prejudice on Social media, 2020, In: Proceedings

                    of the Fourth Workshop on Online Abuse and Harms, pp.162–172"
Large Scale                  Crowdsourcing and Characterization of Twitter Abusive Behavior,Link to publication: https://arxiv.org/pdf/1802.00393.pdf," https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN
"," Multi-thematic (Abusive, Hateful, Normal, Spam)", Hate per se,80000, 0.18, English, Posts, Twitter, Text," Founta, A., Djouvas, C., Chatzakou, D., Leontiadis, I., Blackburn, J., Stringhini, G.,

                    Vakali, A., Sirivianos, M. and Kourtellis, N., 2018. Large Scale Crowdsourcing and Characterization

                    of Twitter Abusive Behavior. ArXiv,."
A Large Labeled Corpus for Online Harassment                  Research,"Link to publication: http://www.cs.umd.edu/~golbeck/papers/trolling.pdf
", jgolbeck@umd.edu," Binary (Harassment, Not)", Person-directed,35000, 0.16, English, Posts, Twitter, Text," Golbeck, J., Ashktorab, Z., Banjo, R., Berlinger, A., Bhagwan, S., Buntain, C.,

                    Cheakalos, P., Geller, A., Gergory, Q., Gnanasekaran, R., Gnanasekaran, R., Hoffman, K., Hottle, J.,

                    Jienjitlert, V., Khare, S., Lau, R., Martindale, M., Naik, S., Nixon, H., Ramachandran, P., Rogers,

                    K., Rogers, L., Sarin, M., Shahane, G., Thanki, J., Vengataraman, P., Wan, Z. and Wu, D., 2017. A

                    Large Labeled Corpus for Online Harassment Research. In: Proceedings of the 2017 ACM on Web Science

                    Conference. New York: Association for Computing Machinery, pp.229-233."
"Ex Machina: Personal Attacks Seen at                  Scale, Personal attacks","Link to publication: https://arxiv.org/pdf/1610.08914
", https://github.com/ewulczyn/wiki-detox," Binary (Personal attack, Not)", Person-directed,115737, 0.12, English, Posts, Wikipedia, Text," Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.

                    ArXiv,."
"Ex Machina: Personal Attacks Seen at Scale,                  Toxicity","Link to publication: https://arxiv.org/pdf/1610.08914
", https://github.com/ewulczyn/wiki-detox," Toxicity/healthiness judgement (-2 == very toxic, 0 == neutral, 2 == very healthy)

                ", Person-directed,100000, NA, English, Posts, Wikipedia, Text," Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.

                    ArXiv,."
Detecting cyberbullying in online                  communities (World of Warcraft),Link to publication: http://aisel.aisnet.org/ecis2016_rp/61/, http://ub-web.de/research/," Binary (Harassment, Not)", Person-directed,16975, 0.01, English, Posts, World of Warcraft, Text," Bretschneider, U. and Peters, R., 2016. Detecting Cyberbullying in Online Communities.

                    Research Papers, 61."
Detecting cyberbullying in online                  communities (League of Legends),Link to publication: http://aisel.aisnet.org/ecis2016_rp/61/, http://ub-web.de/research/," Binary (Harassment, Not)", Person-directed,17354, 0.01, English, Posts, League of Legends, Text," Bretschneider, U. and Peters, R., 2016. Detecting Cyberbullying in Online Communities.

                    Research Papers, 61."
A Quality Type-aware                  Annotated Corpus and Lexicon for Harassment Research,Link to publication: https://arxiv.org/pdf/1802.09416.pdf," https://github.com/Mrezvan94/Harassment-Corpus
", Multi-topic harassment detection," Racism, Sexism, Appearance-related, Intellectual, Political",24189, 0.13, English, Posts, Twitter, Text," Rezvan, M., Shekarpour, S., Balasuriya, L., Thirunarayan, K., Shalin, V. and Sheth, A.,

                    2018. A Quality Type-aware Annotated Corpus and Lexicon for Harassment Research. ArXiv,."
"Ex Machina: Personal Attacks                  Seen at Scale, Aggression and Friendliness","Link to publication: https://arxiv.org/pdf/1610.08914
", https://github.com/ewulczyn/wiki-detox," Aggression/friendliness judgement on a 5 point scale. (-2 == very aggressive, 0 ==

                    neutral, 3 == very friendly).", Person-Directed + Group-Directed,160000, NA, English, Posts, Wikipedia, Text," Wulczyn, E., Thain, N. and Dixon, L., 2017. Ex Machina: Personal Attacks Seen at Scale.

                    ArXiv,."
Are Chess Discussions Racist? An                  Adversarial Hate Speech Data Set,Link to publication: https://arxiv.org/pdf/2011.10280.pdf," https://www.cs.cmu.edu/~akhudabu/Chess.html
", Not Labeled," Racism, Misclassification",1000, 0.0, English, Posts, Youtube, Text," Rupak Sarkar and Ashiqur R. KhudaBukhsh, Nov. 2020. Are Chess Discussions Racist? An

                    Adversarial Hate Speech Data Set. In: The Thirty-Fifth {AAAI} Conference on Artificial Intelligence,

                    {AAAI} 2021"
ETHOS: an Online Hate Speech Detection Dataset                  (Binary),Link to publication: https://arxiv.org/pdf/2006.08328.pdf," https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset
"," Binary (Hate, Not)"," Gender, Race, National Origin, Disability, Religion, Sexual Orientation",998, 0.43, English, Posts," Youtube, Reddit", Text," Mollas, I., Chrysopoulou, Z., Karlos, S., and Tsoumakas, G., 2021. ETHOS: an Online Hate

                    Speech Detection Dataset. Complex & Intelligent Systems, Jan. 2022"
ETHOS: an Online Hate Speech Detection                  Dataset (Multi label),Link to publication: https://arxiv.org/pdf/2006.08328.pdf," https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset
"," 8 Categories (Violence, Directed/Undirected, Gender, Race, National Origin,

                    Disability, Sexual Orientation, Religion)"," Gender, Race, National Origin, Disability, Religion, Sexual Orientation",433, 0.33, English, Posts," Youtube, Reddit", Text," Mollas, I., Chrysopoulou, Z., Karlos, S., and Tsoumakas, G., 2021. ETHOS: an Online Hate

                    Speech Detection Dataset. Complex & Intelligent Systems, Jan. 2022"
Twitter Sentiment Analysis,Link to publication: NA," https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech
"," Binary (Hate, Not)"," Racism, Sexism",31961, 0.07, English, Posts, Twitter, Text," Ali Toosi, Jan 2019. Twitter Sentiment Analysis"
Toxicity Detection: Does Context                  Really Matter? CAT-LARGE (No Context),Link to publication: https://arxiv.org/pdf/2006.00998.pdf," https://github.com/ipavlopoulos/context_toxicity
"," Binary (Toxic, Non-toxic)"," Toxicity, Context",10000, 0.006, English, Post, Wikipedia Talk Pages, Text," Pavlopoulos, J., Sorensen, J., Dixon, L., Thain, N., & Androutsopoulos, I. (2020).

                    Toxicity Detection: Does Context Really Matter? ArXiv:2006.00998 [Cs]."
Toxicity Detection: Does                  Context Really Matter? CAT-LARGE (With Context),Link to publication: https://arxiv.org/pdf/2006.00998.pdf," https://github.com/ipavlopoulos/context_toxicity
"," Binary (Toxic, Non-toxic)"," Toxicity, Context",10000, 0.02, English, Post, Wikipedia Talk Pages, Text," Pavlopoulos, J., Sorensen, J., Dixon, L., Thain, N., & Androutsopoulos, I. (2020).

                    Toxicity Detection: Does Context Really Matter? ArXiv:2006.00998 [Cs]."
Anatomy of Online Hate: Developing a Taxonomy and Machine Learning Models for Identifying and                  Classifying Hate in Online News Media,"Link to publication: https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewFile/17885/17024
"," https://www.dropbox.com/s/21wtzy9arc5skr8/ICWSM18%20-%20SALMINEN%20ET%20AL.xlsx?dl=0
"," Binary (Hate, Not), Multinomial classification (21 categories divided into

                    ‘hateful language’, ‘hate targets’ and ‘hate sub-targets’)", Group-directed + Person-directed,5143, 82, English, Comment, YouTube and Facebook, Text," Salminen, J., Almerekhi, H., Milenković, M., Jung, S., An, J., Kwak, H. and Jansen, B.,

                    2018, Anatomy of Online Hate: Developing a Taxonomy and Machine Learning Models for Identifying and

                    Classifying Hate in Online News Media, In: Proceedings of the Twelfth International AAAI Conference

                    on Web and Social Media (ICWSM 2018), pp.330-339"
Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian,"Link to publication: https://jlcl.org/content/2-allissues/1-heft1-2020/jlcl_2020-1_3.pdf
", http://hdl.handle.net/11356/1401," Binary (Deleted, Not)", Flagged content performmed by the real newspaper moderators,31.5M, 12.5, Estonian (some in Russian also), Posts," Newspaper comments, Eesti Ekspress (www.ekspress.ee) website", Text," Ravi Shekhar, Marko Pranjić, Senja Pollak, Andraž Pelicon, Matthew Purver (2020).

                    Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian.

                    Journal for Language Technology and Computational Linguistics (JLCL)."
HateXplain: A Benchmark                  Dataset for Explainable Hate Speech Detection,Link to publication: https://arxiv.org/pdf/2012.10289.pdf, https://github.com/punyajoy/HateXplain," Binary (Hate, Not) and Three-class (Hate speech, Offensive language, None)"," Hatespeech detection on social media in English, including 10 categories: African,

                    Islam, Jewish, LGBTQ, Women, Refugee, Arab, Caucasian, Hispanic, Asian",20148, 57, English, Posts, Twitter and Gab, Text," Mathew, B., Saha, P., Yimam, S. M., Biemann, C., Goyal, P., & Mukherjee, A. (2020).

                    Hatexplain: A benchmark dataset for explainable hate speech detection. arXiv preprint

                    arXiv:2012.10289."
CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online                  Hate Speech (French),"Link to publication: https://www.aclweb.org/anthology/P19-1271.pdf
", https://github.com/marcoguerini/CONAN," Binary (Islamophobic / not), Multi-topic (Culture, Economics, Crimes, Rapism,

                    Terrorism, Women Oppression, History, Other/generic)", Islamophobia,1719, 1, French, Posts, Synthetic / Facebook, Text," Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives

                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:

                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,

                    Italy: Association for Computational Linguistics, pp.2819-2829."
Multilingual and Multi-Aspect Hate Speech                  Analysis (French),"Link to publication: https://arxiv.org/abs/1908.11049
"," https://github.com/HKUST-KnowComp/MLMA_hate_speech
"," Detailed taxonomy with cross-cutting attributes: Hostility, Directness, Target

                    Attribute, Target Group, How annotators felt on seeing the tweet."," Gender, Sexual orientation, Religion, Disability",4014, 0.72, French, Posts, Twitter, Text," Ousidhoum, N., Lin, Z., Zhang, H., Song, Y. and Yeung, D., 2019. Multilingual and

                    Multi-Aspect Hate Speech Analysis. ArXiv,."
RP-Mod & RP-Crowd:                  Moderator- and Crowd-Annotated German News Comment Datasets,"Link to publication: https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/c9e1074f5b3f9fc8ea15d152add07294-Paper-round2.pdf
"," https://zenodo.org/record/5291339#.Ybr_9VkxkUE
"," Binary (Offensive or Not), Multi-class/-label (sexism, racism, threats, insults,

                    profane language, meta, advertisement)."," The comments originate from a large German newspaper and are annotated by

                    professional moderators (community managers). Additionally, each comment was further annotated by

                    five different crowd-workers.",85000, 8.4, German, Comments, German Newspaper (Rheinische Post), Text," Assenmacher, D., Niemann, M., Müller, K., Seiler, M., Riehle, D. M., & Trautmann, H.

                    (2021). RP-Mod & RP-Crowd: Moderator- and crowd-annotated german news comment datasets. In

                    Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmark."
Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis,Link to publication: https://arxiv.org/pdf/1701.08118.pdf," https://github.com/UCSM-DUE/IWG_hatespeech_public
"," Binary (Anti-refugee hate, None)", Refugees,469, NA, German, Posts, Twitter, Text," Ross, B., Rist, M., Carbonell, G., Cabrera, B., Kurowsky, N. and Wojatzki, M., 2017.

                    Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis.

                    ArXiv,."
Detecting Offensive Statements                  Towards Foreigners in Social Media,"Link to publication: https://pdfs.semanticscholar.org/23dc/df7c7e82807445afd9f19474fc0a3d8169fe.pdf
", http://ub-web.de/research/," Hierarchical (Anti-foreigner prejudice, split into (1) slightly

                    offensive/offensive and (2) explicitly/substantially offensive). 6 targets (Foreigner, Government,

                    Press, Community, Other, Unknown)", Anti-foreigner prejudice,5836, 0.11, German, Posts, Facebook, Text," Bretschneider, U. and Peters, R., 2017. Detecting Offensive Statements towards Foreigners

                    in Social Media. In: Proceedings of the 50th Hawaii International Conference on System Sciences.

                "
GermEval 2018,"Link to publication: https://www.researchgate.net/publication/327914386_Overview_of_the_GermEval_2018_Shared_Task_on_the_Identification_of_Offensive_Language
"," https://github.com/uds-lsv/GermEval-2018-Data
"," Branching structure: Binary (Offense, Other), 3 levels within Offense (Abuse,

                    Insult, Profanity)", Group-directed + Incivility,8541, 0.34, German, Posts, Twitter, Text," Wiegand, M., Siegel, M. and Ruppenhofer, J., 2018. Overview of the GermEval 2018 Shared

                    Task on the Identification of Offensive Language. In: Proceedings of GermEval 2018, 14th Conference

                    on Natural Language Processing (KONVENS 2018). Vienna, Austria: Research Gate."
Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in                  Indo-European Languages,"Link to publication: https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true
"," https://hasocfire.github.io/hasoc/2019/dataset.html
"," A: Hate / Offensive or neither, B: Hatespeech, Offensive, or Profane", Group-directed + Person-directed,4669, 0.24, German, Posts, Twitter and Facebook, Text," Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.

                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information

                    Retrieval Evaluation,."
"Deep Learning for User Comment                  Moderation, Flagged Comments",Link to publication: https://www.aclweb.org/anthology/W17-3004, http://www.straintek.com/data/," Binary (Flagged, Not)", Flagged content,1450000, 0.34, Greek, Posts, Gazetta, text," Pavlopoulos, J., Malakasiotis, P. and Androutsopoulos, I., 2017. Deep Learning for User

                    Comment Moderation. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver,

                    Canada: Association for Computational Linguistics, pp.25-35."
"Deep Learning for User Comment                  Moderation, Moderated Comments","Link to publication: https://www.aclweb.org/anthology/W17-3004
", http://www.straintek.com/data/," Binary (Flagged, Not)", Flagged content,1500, 0.22, Greek, Posts, Gazetta, text," Pavlopoulos, J., Malakasiotis, P. and Androutsopoulos, I., 2017. Deep Learning for User

                    Comment Moderation. In: Proceedings of the First Workshop on Abusive Language Online. Vancouver,

                    Canada: Association for Computational Linguistics, pp.25-35."
Offensive Language Identification in Greek,Link to publication: https://arxiv.org/pdf/2003.07459v1.pdf," https://sites.google.com/site/offensevalsharedtask/home
"," Branching structure of tasks: Binary (Offensive, Not), Within Offensive (Target,

                    Not), Within Target (Individual, Group, Other)", Group-directed + Person-directed,4779, 0.29, Greek, Posts, Twitter, Text," Pitenis, Z., Zampieri, M. and Ranasinghe, T., 2020. Offensive Language Identification in

                    Greek. ArXiv."
Hostility Detection Dataset in Hindi,Link to publication: https://arxiv.org/pdf/2011.03588.pdf," https://competitions.codalab.org/competitions/26654
"," Branching structure of tasks: Binary (Hostile, Not Hostile), Multi-tags within

                    Hostile (Fake News, Hate, Offense, Defame)", Hostility detection,8192, 47, Hindi, Posts," Twitter, Facebook, WhatsApp", Text," Bhardwaj, M., Akhtar, M.S., Ekbal, A., Das, A. and Chakraborty, T., 2020. Hostility

                    detection dataset in hindi. arXiv preprint arXiv:2011.03588."
Aggression-annotated Corpus of                  Hindi-English Code-mixed Data,"Link to publication: https://arxiv.org/pdf/1803.09402
"," https://github.com/kraiyani/Facebook-Post-Aggression-Identification
"," 3 part hierachy for hate (None, Covert Aggression, Overt Aggression), 4 part

                    target categorisation (Physical threat, Sexual threat, Identity threat, Non-threatening aggression),

                    3-part discursive role categorisation (Attack, Defend, Abet)", Numerous sub-categorizations,18000, 0.06, Hindi-English, Posts, Facebook, Text," Kumar, R., Reganti, A., Bhatia, A. and Maheshwari, T., 2018. Aggression-annotated Corpus

                    of Hindi-English Code-mixed Data. ArXiv,."
Aggression-annotated Corpus of                  Hindi-English Code-mixed Data,"Link to publication: https://arxiv.org/pdf/1803.09402
"," https://github.com/kraiyani/Facebook-Post-Aggression-Identification
"," 3 part hierachy for hate (None, Covert Aggression, Overt Aggression), 4 part

                    target categorisation (Physical threat, Sexual threat, Identity threat, Non-threatening aggression),

                    3-part discursive role categorisation (Attack, Defend, Abet)", Numerous sub-categorizations,21000, 0.27, Hindi-English, Posts, Twitter, Text," Kumar, R., Reganti, A., Bhatia, A. and Maheshwari, T., 2018. Aggression-annotated Corpus

                    of Hindi-English Code-mixed Data. ArXiv,."
Did You Offend Me?                  Classification of Offensive Tweets in Hinglish Language,"Link to publication: https://www.aclweb.org/anthology/W18-5118
"," https://github.com/pmathur5k10/Hinglish-Offensive-Text-Classification
"," Hierarchy (Not Offensive, Abusive, Hate)", Sexism,3189, 0.65, Hindi-English, Posts, Twitter, Text," Mathur, P., Sawhney, R., Ayyar, M. and Shah, R., 2018. Did you offend me? Classification

                    of Offensive Tweets in Hinglish Language. In: Proceedings of the 2nd Workshop on Abusive Language

                    Online (ALW2). Brussels, Belgium: Association for Computational Linguistics, pp.138-148."
A Dataset of                  Hindi-English Code-Mixed Social Media Text for Hate Speech Detection,"Link to publication: https://www.aclweb.org/anthology/W18-1105
"," https://github.com/deepanshu1995/HateSpeech-Hindi-English-Code-Mixed-Social-Media-Text
"," Binary (Hate, Not)", Hate per se,4575, 0.36, Hindi-English, Posts, Twitter, Text," Bohra, A., Vijay, D., Singh, V., Sarfaraz Akhtar, S. and Shrivastava, M., 2018. A Dataset

                    of Hindi-English Code-Mixed Social Media Text for Hate Speech Detection. In: Proceedings of the

                    Second Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social

                    Media. New Orleans, Louisiana: Association for Computational Linguistics, pp.36-41."
Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in                  Indo-European Languages,"Link to publication: https://dl.acm.org/doi/pdf/10.1145/3368567.3368584?download=true
"," https://hasocfire.github.io/hasoc/2019/dataset.htm
"," A: Hate, Offensive or Neither, B: Hatespeech, Offensive, or Profane, C: Targeted

                    or Untargeted", Group-directed + Person-directed,5983, 0.51, Hindi, Posts, Twitter and Facebook, Text," Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C. and Patel, A., 2019.

                    Overview of the HASOC track at FIRE 2019. In: Proceedings of the 11th Forum for Information

                    Retrieval Evaluation,."
Hate Speech                  Detection in the Indonesian Language: A Dataset and Preliminary Study,"Link to publication: https://ieeexplore.ieee.org/document/8355039
"," https://github.com/ialfina/id-hatespeech-detection
"," Binary (Hate, Not)", Hate per se,713, 0.36, Indonesian, Posts, Twitter, Text," Alfina, I., Mulia, R., Fanany, M. and Ekanata, Y., 2017. Hate Speech Detection in the

                    Indonesian Language: A Dataset and Preliminary Study. In: International Conference on Advanced

                    Computer Science and Information Systems. pp.233-238."
Multi-Label Hate                  Speech and Abusive Language Detection in Indonesian Twitter,"Link to publication: https://www.aclweb.org/anthology/W19-3506
"," https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection
"," (No hate speech, No hate speech but abusive, Hate speech but no abuse, Hate speech

                    and abuse), within hate, category (Religion/creed, Race/ethnicity, Physical/disability,

                    Gender/sexual orientation, Other invective/slander), within hate, strength (Weak, Moderate and

                    Strong)"," Religion, Race, Disability, Gender",13169, 0.42, Indonesian, Posts, Twitter, Text," Okky Ibrohim, M. and Budi, I., 2019. Multi-label Hate Speech and Abusive Language

                    Detection in Indonesian Twitter. In: Proceedings of the Third Workshop on Abusive Language Online.

                    Florence, Italy: Association for Computational Linguistics, pp.46-57."
A                  Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media,"Link to publication: https://www.sciencedirect.com/science/article/pii/S1877050918314583
"," https://github.com/okkyibrohim/id-abusive-language-detection
"," Hierarchical (Not abusive, Abusive but not offensive, Offensive)", Incivility,2016, 0.54, Indonesian, Posts, Twitter, Text," Ibrohim, M. and Budi, I., 2018. A Dataset and Preliminaries Study for Abusive Language

                    Detection in Indonesian Social Media. Procedia Computer Science, 135, pp.222-229."
BEEP! Korean Corpus of                  Online News Comments for Toxic Speech Detection__,"Link to publication: https://www.aclweb.org/anthology/2020.socialnlp-1.4
"," https://github.com/kocohub/korean-hate-speech
"," Binary (Gender bias, No gender bias), Ternary (Gender bias, Other biases, None),

                    Ternary (Hate, Offensive, None)"," Person/Group-directed, Gender/Sexual orientation, Sexism, Harmfulness/Toxicity",9381," 33.87 (Bias), 57.77 (Toxicity)", Korean, Comments, NAVER entertainment news, Text," Moon, J., Cho, W. I., and Lee, J., 2020. BEEP! Korean Corpus of Online News Comments for

                    Toxic Speech Detection. In: Proceedings of the Eighth International Workshop on Natural Language

                    Processing for Social Media Month: July. Online: Association for Computational Linguistics,

                    pp.25-31."
Latvian newspaper user comment dataset,"Link to publication: https://aclanthology.org/2021.hackashop-1.14.pdf
"," https://www.clarin.si/repository/xmlui/handle/11356/1407
"," Binary (Deleted, Not)", Flagged content performmed by the real newspaper moderators,12M, ~10, Latvian, Posts, Newspaper comments, Text," Senja Pollak, Marko Robnik-Šikonja, Matthew Purver, Michele Boggia, Ravi Shekhar, Marko

                    Pranjić, Salla Salmela, Ivar Krustok, Tarmo Paju, Carl-Gustav Linden, Leo Leppänen, Elaine Zosa,

                    Matej Ulčar, Linda Freiental, Silver Traat, Luis Adrián Cabrera-Diego, Matej Martinc, Nada Lavrač,

                    Blaž Škrlj, Martin Žnidaršič, Andraž Pelicon, Boshko Koloski, Vid Podečan, Janez Kranjc, Shane

                    Sheehan, Emanuela Boros, Jose Moreno, Antoine Doucet, Hannu Toivonen (2021). EMBEDDIA Tools,

                    Datasets and Challenges: Resources and Hackathon Contributions. Proceedings of the Hackashop on News

                    Media Content Analysis and Automated Report Generation (EACL)."
An Italian Twitter Corpus of Hate                  Speech against Immigrants,"Link to publication: https://www.aclweb.org/anthology/L18-1443
"," https://github.com/msang/hate-speech-corpus
"," Binary (Immigrants/Roma/Muslims, Not), additional categories. Within Hate,

                    Intensity measurement (Aggressiveness: No, Weak, Strong, Offensiveness: No, Weak, Strong, Irony: No,

                    Yes, Stereotype: No, Yes, Incitement degree: 0-4)"," Immigrants, Roma and Muslims + numerous sub-categorizations",1827, 0.13, Italian, Posts, Twitter, Text," Sanguinetti, M., Poletto, F., Bosco, C., Patti, V. and Stranisci, M., 2018. An Italian

                    Twitter Corpus of Hate Speech against Immigrants. In: Proceedings of the Eleventh International

                    Conference on Language Resources and Evaluation (LREC 2018). Miyazaki, Japan: European Language

                    Resources Association (ELRA)."
Overview of the EVALITA 2018 Hate                  Speech Detection Task (Facebook),"Link to publication: http://ceur-ws.org/Vol-2263/paper010.pdf
"," http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html
"," Binary (Hate, Not), Within hate for Facebook only, strength (No hate, Weak hate,

                    Strong hate) and theme ((1) religion, (2) physical and/or mental handicap, (3) socio-economic

                    status, (4) politics, (5) race, (6) sex and gender, (7) Other)"," Religion, physical and/or mental handicap, socio-economic status, politics, race,

                    sex and gender",4000, 0.51, Italian, Posts, Facebook, Text," Bosco, C., Dell’Orletta, F. and Poletto, F., 2018. Overview of the EVALITA 2018 Hate

                    Speech Detection Task. In: EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and

                    Speech Tools for Italian. CEUR, pp.1-9."
Overview of the EVALITA 2018 Hate                  Speech Detection Task (Twitter),"Link to publication: http://ceur-ws.org/Vol-2263/paper010.pdf
"," http://www.di.unito.it/~tutreeb/haspeede-evalita18/data.html
"," Binary (Hate, Not), Within Hate For Twitter only Intensity (1-4 rating),

                    Aggressiveness (No, Weak, Strong), Offensiveness (No, Weak, Strong), Irony (Yes, No)", Group-directed,4000, 0.32, Italian, Posts, Twitter, Text," Bosco, C., Dell’Orletta, F. and Poletto, F., 2018. Overview of the EVALITA 2018 Hate

                    Speech Detection Task. In: EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and

                    Speech Tools for Italian. CEUR, pp.1-9."
Automatic Misogyny Identification (AMI) at                  Evalita 2020,"Link to publication: http://ceur-ws.org/Vol-2765/paper161.pdf
", https://github.com/dnozza/ami2020," Binary (misogyny / not), Binary (aggressive / not), Binary on synthetic fairness

                    test (misogyny / not)", Sexism,6000and1961(syntheticfairnesstest), 47% and 50% (synthetic fairness test), Italian, Posts, Twitter, Text," Fersini, E., Nozza, D., and Rosso, P., 2020. AMI @ EVALITA2020: Automatic Misogyny

                    Identification. In: Proceedings of the 7th evaluation campaign of Natural Language Processing and

                    Speech tools for Italian (EVALITA 2020)."
CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online                  Hate Speech (Italian),"Link to publication: https://www.aclweb.org/anthology/P19-1271.pdf
", https://github.com/marcoguerini/CONAN," Binary (Islamophobic, Not), Multi-topic (Culture, Economics, Crimes, Rapism,

                    Terrorism, Women Oppression, History, Other/generic)", Islamophobia,1071, 1, Italian, Posts, Synthetic / Facebook, Text," Chung, Y., Kuzmenko, E., Tekiroglu, S. and Guerini, M., 2019. CONAN - COunter NArratives

                    through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In:

                    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence,

                    Italy: Association for Computational Linguistics, pp.2819-2829."
Creating a WhatsApp Dataset to Study                  Pre-teen Cyberbullying,"Link to publication: https://www.aclweb.org/anthology/W18-5107
"," https://github.com/dhfbk/WhatsApp-Dataset
"," Binary (Cyberbullying, Not)", Person-directed,14600, 0.08, Italian," Posts, structured into 10 chats, with token level information", Synthetic / Whatsapp, Text," Sprugnoli, R., Menini, S., Tonelli, S., Oncini, F. and Piras, E., 2018. Creating a

                    WhatsApp Dataset to Study Pre-teen Cyberbullying. In: Proceedings of the 2nd Workshop on Abusive

                    Language Online (ALW2) Month: October. Brussels, Belgium: Association for Computational Linguistics,

                    pp.51-59."
Results of the PolEval 2019 Shared Task 6:First Dataset and Open Shared Task for Automatic Cyberbullying                  Detection in Polish Twitter,Link to publication: http://poleval.pl/files/poleval2019.pdf, http://poleval.pl/tasks/task6," Harmfulness score (three values), Multilabel from seven phenomena", Person-directed,10041, 0.09, Polish, Posts, Twitter, Text," Ogrodniczuk, M. and Kobyliński, L., 2019. Results of the PolEval 2019 Shared Task 6:

                    First Dataset and Open Shared Task for Automatic Cyberbullying Detection in Polish Twitter. In:

                    Proceedings of the PolEval 2019 Workshop. Warszawa: Institute of Computer Science, Polish Academy of

                    Sciences."
Toxic Language Dataset for Brazilian                  Portuguese (ToLD-Br),Link to publication: https://arxiv.org/abs/2010.04543, https://github.com/JAugusto97/ToLD-Br," Multiclass (LGBTQ+phobia, Insult, Xenophobia, Misogyny, Obscene, Racism)"," Three annotators per example, demographically diverse selected annotators.",21.000, 44, Portuguese, Posts, Twitter, Text," João A. Leite, Diego F. Silva, Kalina Bontcheva, Carolina Scarton (2020): Toxic Language

                    Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis.

                    AACL-IJCNLP 2020"
A Hierarchically-Labeled Portuguese Hate                  Speech Dataset,"Link to publication: https://www.aclweb.org/anthology/W19-3510
"," https://b2share.eudat.eu/records/9005efe2d6be4293b63c3cffd4cf193e
"," Binary (Hate, Not), Multi-level (81 categories, identified inductively; categories

                    have different granularities and content can be assigned to multiple categories at once)", Multiple identities inductively categorized,3059, 0.32, Portuguese, Posts, Twitter, Text," Fortuna, P., Rocha da Silva, J., Soler-Company, J., Warner, L. and Nunes, S., 2019. A

                    Hierarchically-Labeled Portuguese Hate Speech Dataset. In: Proceedings of the Third Workshop on

                    Abusive Language Online. Florence, Italy: Association for Computational Linguistics, pp.94-104."
Offensive Comments in the                  Brazilian Web: A Dataset and Baseline Results,"Link to publication: http://www.each.usp.br/digiampietri/BraSNAM/2017/p04.pdf
"," https://github.com/rogersdepelle/OffComBR
"," Binary (Offensive, Not), Target (Xenophobia, homophobia, sexism, racism, cursing,

                    religious intolerance)"," Religion/creed, Race/ethnicity, Physical/disability, Gender/sexual orientation",1250, 0.33, Portuguese, Posts, g1.globo.com, Text," de Pelle, R. and Moreira, V., 2017. Offensive Comments in the Brazilian Web: A Dataset

                    and Baseline Results. In: VI Brazilian Workshop on Social Network Analysis and Mining. SBC."
Reducing Unintended Identity                  Bias in Russian Hate Speech Detection,"Link to publication: https://aclanthology.org/2020.alw-1.8.pdf
", License Required (Last checked 17/01/2022)," Binary (Hate, Not)"," Toxicity, Harassment, Sexism, Homophobia, Nationalism",100000, NA, Russian, Posts, Youtube, Text," Zueva, Nadezhda, et al, Oct. 2020. Reducing Unintended Identity Bias in Russian Hate

                    Speech Detection. In: Proceedings of the Fourth Workshop on Online Abuse and Harms, pages 65–69"
Detection of                  Abusive Speech for Mixed Sociolects of Russian and Ukrainian Languages,"Link to publication: https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf
"," https://github.com/bohdan1/AbusiveLanguageDataset
"," Binary (True == Abusive, False == Not)"," Multilingual, Abusive Words, Political",2000, 0.33, Surzhyk (Russian & Ukranian), Posts, Youtube, Text," Andrusyak, B., Rimel, M. and Kern, R., 2018. Detection of Abusive Speech for Mixed

                    Sociolects of Russian and Ukrainian Languages. In: Proceedings of Recent Advances in Slavonic

                    Natural Language Processing, RASLAN 2018, pp. 77–84, 2018."
Russian South Park,"Link to publication: https://aclanthology.org/2021.bsnlp-1.3/
"," https://github.com/Sariellee/Russan-Hate-speech-Recognition
"," Binary (abusive, non-abusive)", Abusive language in Russian South Park scripts,1400, 22.2, Russian, Sentence, TV Subtitles, text," Saitov & Derczynski, 2021. “Abusive Language Recognition in Russian”. Proceedings of

                    the 8th BSNLP Workshop on Balto-Slavic Natural Language Processing, ACL"
Datasets of Slovene and Croatian                  Moderated News Comments,"Link to publication: https://www.aclweb.org/anthology/W18-5116
", http://hdl.handle.net/11356/1201," Binary (Deleted, Not)", Flagged content,7600000, 0.08, Slovene, Posts, MMC RTV website, Text," Ljubešić, N., Erjavec, T. and Fišer, D., 2018. Datasets of Slovene and Croatian Moderated

                    News Comments. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2). Brussels,

                    Belgium: Association for Computational Linguistics, pp.124-131."
Overview of MEX-A3T at IberEval 2018: Authorship and Aggressiveness Analysis in Mexican Spanish Tweets,"Link to publication: http://ceur-ws.org/Vol-2150/overview-mex-a3t.pdf
"," https://mexa3t.wixsite.com/home/aggressive-detection-track
"," Binary (Aggressive, Not)", Group-directed,11000, 0.32, Spanish, Posts, Twitter, Text," Alvarez-Carmona, M., Guzman-Falcon, E., Montes-y-Gomez, M., Escalante, H.,

                    Villasenor-Pineda, L., Reyes-Meza, V. and Rico-Sulayes, A., 2018. Overview of MEX-A3T at IberEval

                    2018: Authorship and aggressiveness analysis in Mexican Spanish tweets. In: Proceedings of the Third

                    Workshop on Evaluation of Human Language Technologies for Iberian Languages (IberEval 2018)."
Overview of the                  Task on Automatic Misogyny Identification at IberEval 2018 (Spanish),"Link to publication: http://ceur-ws.org/Vol-2150/overview-AMI.pdf
"," https://amiibereval2018.wordpress.com/important-dates/data/
"," Binary (Misogyny, Not), 5 categories (Stereotype, Dominance, Derailing, Sexual

                    harassment, Discredit), Target of misogyny (Active or Passive)", Sexism,4138, 0.5, Spanish, Posts, Twitter, Text," Fersini, E., Rosso, P. and Anzovino, M., 2018. Overview of the Task on Automatic Misogyny

                    Identification at IberEval 2018. In: Proceedings of the Third Workshop on Evaluation of Human

                    Language Technologies for Iberian Languages (IberEval 2018)."
"hatEval, SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in                  Twitter (Spanish)","Link to publication: https://www.aclweb.org/anthology/S19-2007
"," competitions.codalab.org/competitions/19935
"," Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),

                    Within Hate (Agressive, Not)", Group-directed + Person-directed,6600, 0.4, Spanish, Posts, Twitter, Text," Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Pardo, F., Rosso, P. and

                    Sanguinetti, M., 2019. SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants

                    and Women in Twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation.

                    Minneapolis, Minnesota: Association for Computational Linguistics, pp.54-63."
A Corpus of Turkish Offensive Language on                  Social Media,"Link to publication: https://coltekin.github.io/offensive-turkish/troff.pdf
"," https://sites.google.com/site/offensevalsharedtask/home
"," Branching structure of tasks: Binary (Hate, Not), Within Hate (Group, Individual),

                    Within Hate (Agressive, Not)", Group-directed + Person-directed,36232, 0.19, Turkish, Posts, Twitter, Text," Çöltekin, C., 2020. A Corpus of Turkish Offensive Language on Social Media. In:

                    Proceedings of the 12th International Conference on Language Resources and Evaluation."
Detection of                  Abusive Speech for Mixed Sociolects of Russian and Ukrainian Languages,"Link to publication: https://nlp.fi.muni.cz/raslan/2018/paper04-Andrusyak.pdf
"," https://github.com/bohdan1/AbusiveLanguageDataset
"," Binary (True == Abusive, False == Not)"," Multilingual, Abusive Words, Political",2000, 0.33, Surzhyk (Russian & Ukranian), Posts, Youtube, Text," Andrusyak, B., Rimel, M. and Kern, R., 2018. Detection of Abusive Speech for Mixed

                    Sociolects of Russian and Ukrainian Languages. In: Proceedings of Recent Advances in Slavonic

                    Natural Language Processing, RASLAN 2018, pp. 77–84, 2018."
Hate-Speech and Offensive Language                  Detection in Roman Urdu,"Link to publication: https://www.aclweb.org/anthology/2020.emnlp-main.197/
"," https://github.com/haroonshakeel/roman_urdu_hate_speech
"," There are 2 subtasks, Coarse-grained Classification(Hate-Offensive vs Normal) and

                    Fine-grained classification( Abusive/Offensive, Sexism, Religious Hate, Profane, Normal)"," Binary classification + Hate-Offensive label is further broken down into 4

                    fine-grained labels",10041, 0.24, Urdu-English, Posts, Twitter, Text," Hammad Rizwan, Muhammad Haroon Shakeel, and Asim Karim. 2020. Hate-speech and offensive

                    language detection in Roman Urdu. In Proceedings of the 2020 Conference on Empirical Methods in

                    Natural Language Processing (EMNLP), pages 2512–2522, Online. Association for Computational

                    Linguistics."
